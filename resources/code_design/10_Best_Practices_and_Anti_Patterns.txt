================================================================================
BEST PRACTICES AND ANTI-PATTERNS FOR HFT C++ SYSTEMS
================================================================================

This document covers proven best practices and common anti-patterns to avoid
when building high-frequency trading systems in C++.

================================================================================
TABLE OF CONTENTS
================================================================================
1. Performance Best Practices
2. Memory Management Best Practices
3. Concurrency Best Practices
4. Code Organization Best Practices
5. Testing Best Practices
6. Common Anti-Patterns to Avoid
7. Optimization Pitfalls
8. Debugging and Profiling Practices
9. Production Deployment Practices
10. Code Review Checklist

================================================================================
1. PERFORMANCE BEST PRACTICES
================================================================================

BEST PRACTICE #1: Measure Before Optimizing
--------------------------------------------
RULE: Always profile before optimizing. Never guess where bottlenecks are.

GOOD:
```cpp
// Profile first
auto start = __builtin_ia32_rdtsc();
processMarketData(data);
auto end = __builtin_ia32_rdtsc();
logLatency(end - start);

// Then optimize the actual bottleneck
```

BAD:
```cpp
// Optimizing random code without profiling
// Wasted effort if this isn't the bottleneck
inline __attribute__((always_inline))
void someRarelyCalledFunction() {
    // Over-optimization of non-critical code
}
```

BEST PRACTICE #2: Hot Path Optimization
----------------------------------------
RULE: Optimize the critical path ruthlessly, be reasonable elsewhere.

GOOD:
```cpp
class OrderManager {
    // Critical path: ultra-optimized, no allocations
    bool submitOrder(const Order& order) noexcept {
        // Stack-only, cache-friendly, branchless
        char buffer[256];
        size_t len = encodeOrder(order, buffer);
        return sendImmediate(buffer, len);
    }

    // Non-critical path: can use STL, allocations OK
    std::vector<Order> getHistoricalOrders(uint64_t start_time) {
        return database_.query(start_time);
    }
};
```

BAD:
```cpp
// Treating all code paths equally
class OrderManager {
    // Critical path but using allocations
    bool submitOrder(const Order& order) {
        std::string encoded = encodeToString(order);  // BAD: allocation!
        return sendImmediate(encoded.data(), encoded.size());
    }
};
```

BEST PRACTICE #3: Cache-Friendly Data Structures
-------------------------------------------------
RULE: Organize data for sequential access and cache line alignment.

GOOD:
```cpp
// Structure of Arrays (cache-friendly)
struct alignas(64) OrderBookLevel {
    std::array<uint64_t, 10> prices;     // Sequential access
    std::array<uint64_t, 10> quantities; // Sequential access
    size_t count;
};

// Cache line aligned to prevent false sharing
struct alignas(64) ThreadLocalStats {
    uint64_t order_count;
    uint64_t fill_count;
    uint64_t cancel_count;
    // Padding to fill cache line
};
```

BAD:
```cpp
// Array of Structures (cache-unfriendly)
struct OrderBookLevel {
    uint64_t price;
    uint64_t quantity;
    // Scattered access pattern, poor cache utilization
};
std::vector<OrderBookLevel> levels;  // Cache misses galore

// Not aligned, causes false sharing
struct ThreadLocalStats {
    uint64_t order_count;  // May share cache line with other thread
    uint64_t fill_count;
};
```

BEST PRACTICE #4: Branchless Programming
-----------------------------------------
RULE: Eliminate branches in hot paths when possible.

GOOD:
```cpp
// Branchless min/max
inline int64_t min_branchless(int64_t a, int64_t b) noexcept {
    return b + ((a - b) & ((a - b) >> 63));
}

// Branchless sign
inline int sign_branchless(int64_t x) noexcept {
    return (x > 0) - (x < 0);  // Compiles to branchless code
}

// Branchless selection
inline double select(bool condition, double true_val, double false_val) noexcept {
    double mask = condition ? 1.0 : 0.0;
    return mask * true_val + (1.0 - mask) * false_val;
}
```

BAD:
```cpp
// Excessive branching in hot path
inline int64_t calculatePnL(int64_t position, double entry, double current) {
    if (position > 0) {
        if (current > entry) {
            return position * (current - entry);  // Long profit
        } else {
            return position * (current - entry);  // Long loss
        }
    } else if (position < 0) {
        if (current < entry) {
            return position * (current - entry);  // Short profit
        } else {
            return position * (current - entry);  // Short loss
        }
    } else {
        return 0;  // No position
    }
}
```

BEST PRACTICE #5: Compiler Hints
---------------------------------
RULE: Use attributes to help compiler optimize.

GOOD:
```cpp
class RiskChecker {
public:
    // Hint that risk breach is unlikely
    [[nodiscard]] bool checkRisk(const Order& order) const noexcept {
        if (order.quantity > max_quantity_) [[unlikely]] {
            return false;
        }

        if (calculatePositionRisk(order) > risk_limit_) [[unlikely]] {
            return false;
        }

        return true;  // Common case
    }

    // Force inlining for hot path
    [[gnu::always_inline]]
    inline bool fastRiskCheck(int64_t qty, double price) const noexcept {
        return qty * price <= quick_limit_;
    }

    // Prevent inlining for cold path
    [[gnu::noinline]]
    void logRiskBreach(const Order& order) noexcept {
        // Complex logging logic
    }
};
```

BAD:
```cpp
class RiskChecker {
public:
    // No hints for compiler
    bool checkRisk(const Order& order) {
        if (order.quantity > max_quantity_) {
            // Compiler doesn't know this is unlikely
            return false;
        }
        return true;
    }

    // Complex function that should not be inlined
    inline void logRiskBreach(const Order& order) {
        // Large function body, inline causes code bloat
        char buffer[4096];
        formatLogMessage(buffer, sizeof(buffer), order);
        writeToLog(buffer);
        updateMetrics();
        notifyMonitoring();
    }
};
```

================================================================================
2. MEMORY MANAGEMENT BEST PRACTICES
================================================================================

BEST PRACTICE #6: Pre-Allocate Everything
------------------------------------------
RULE: Allocate all memory at startup, never in the critical path.

GOOD:
```cpp
class TradingSystem {
    // Pre-allocated at startup
    ObjectPool<Order, 100000> order_pool_;
    ObjectPool<Execution, 100000> execution_pool_;
    std::array<OrderBook, 1000> order_books_;
    SPSCQueue<MarketData, 65536> market_data_queue_;

public:
    void initialize() {
        // All allocation happens here
        order_pool_.initialize();
        execution_pool_.initialize();

        for (auto& book : order_books_) {
            book.initialize();
        }
    }

    // Critical path: zero allocations
    bool submitOrder(uint64_t order_id, uint32_t symbol_id,
                    double price, int64_t quantity) noexcept {
        Order* order = order_pool_.acquire();  // From pre-allocated pool
        if (!order) return false;

        // Use order...

        order_pool_.release(order);  // Return to pool
        return true;
    }
};
```

BAD:
```cpp
class TradingSystem {
public:
    // Critical path with allocations
    bool submitOrder(uint64_t order_id, uint32_t symbol_id,
                    double price, int64_t quantity) {
        auto order = std::make_unique<Order>();  // BAD: allocation in hot path!
        order->order_id = order_id;

        std::vector<char> buffer;  // BAD: allocation!
        buffer.resize(256);

        // Encode and send
        encodeOrder(*order, buffer.data(), buffer.size());
        return true;
    }
};
```

BEST PRACTICE #7: Stack Over Heap
----------------------------------
RULE: Prefer stack allocation for temporary data.

GOOD:
```cpp
void processOrder(const Order& order) noexcept {
    // Stack allocation - fast and predictable
    char buffer[512];
    size_t len = encodeOrder(order, buffer, sizeof(buffer));
    sendToExchange(buffer, len);

    // Fixed-size array on stack
    std::array<PriceLevel, 10> levels;
    fetchMarketData(order.symbol_id, levels);
}
```

BAD:
```cpp
void processOrder(const Order& order) {
    // Heap allocation - slow and unpredictable
    char* buffer = new char[512];
    size_t len = encodeOrder(order, buffer, 512);
    sendToExchange(buffer, len);
    delete[] buffer;  // Don't forget to free!

    // Dynamic allocation
    std::vector<PriceLevel> levels;
    levels.resize(10);
    fetchMarketData(order.symbol_id, levels);
}
```

BEST PRACTICE #8: Memory Alignment
-----------------------------------
RULE: Align data structures to cache lines and SIMD boundaries.

GOOD:
```cpp
// Aligned to cache line (64 bytes)
struct alignas(64) CacheLineAligned {
    std::atomic<uint64_t> counter;
    char padding[56];  // Fill rest of cache line
};

// Separate cache lines for different thread data
struct ThreadData {
    alignas(64) std::atomic<uint64_t> read_index;
    alignas(64) std::atomic<uint64_t> write_index;
};

// SIMD-aligned price array
struct alignas(32) SIMDPriceArray {
    double prices[4];  // 4 doubles fit in 256-bit AVX register
};
```

BAD:
```cpp
// No alignment - false sharing between threads
struct ThreadData {
    std::atomic<uint64_t> read_index;   // May share cache line
    std::atomic<uint64_t> write_index;  // May share cache line
};

// Misaligned - causes performance penalty
struct MisalignedData {
    char padding;
    double price;  // Misaligned, crosses cache line boundary
};
```

================================================================================
3. CONCURRENCY BEST PRACTICES
================================================================================

BEST PRACTICE #9: Lock-Free Over Locks
---------------------------------------
RULE: Use lock-free data structures instead of mutexes.

GOOD:
```cpp
template<typename T, size_t Capacity>
class SPSCQueue {
    alignas(64) std::atomic<size_t> head_{0};
    alignas(64) std::atomic<size_t> tail_{0};
    std::array<T, Capacity> buffer_;

public:
    bool push(const T& item) noexcept {
        size_t tail = tail_.load(std::memory_order_relaxed);
        size_t next_tail = (tail + 1) % Capacity;

        if (next_tail == head_.load(std::memory_order_acquire)) {
            return false;  // Full
        }

        buffer_[tail] = item;
        tail_.store(next_tail, std::memory_order_release);
        return true;
    }

    bool pop(T& item) noexcept {
        size_t head = head_.load(std::memory_order_relaxed);

        if (head == tail_.load(std::memory_order_acquire)) {
            return false;  // Empty
        }

        item = buffer_[head];
        head_.store((head + 1) % Capacity, std::memory_order_release);
        return true;
    }
};
```

BAD:
```cpp
template<typename T>
class LockedQueue {
    std::mutex mutex_;
    std::queue<T> queue_;

public:
    bool push(const T& item) {
        std::lock_guard<std::mutex> lock(mutex_);  // BAD: lock overhead
        queue_.push(item);
        return true;
    }

    bool pop(T& item) {
        std::lock_guard<std::mutex> lock(mutex_);  // BAD: lock overhead
        if (queue_.empty()) return false;
        item = queue_.front();
        queue_.pop();
        return true;
    }
};
```

BEST PRACTICE #10: Single-Writer Pattern
-----------------------------------------
RULE: Design for single writer to avoid synchronization.

GOOD:
```cpp
class OrderBook {
    // Single writer (market data thread) - no locks needed
    void updateBid(uint64_t price, uint64_t quantity) noexcept {
        // No synchronization needed
        bids_[0].price = price;
        bids_[0].quantity = quantity;
        sequence_.store(sequence_.load() + 1, std::memory_order_release);
    }

    // Multiple readers can read safely with sequence check
    bool readBestBid(uint64_t& price, uint64_t& quantity) const noexcept {
        uint64_t seq1 = sequence_.load(std::memory_order_acquire);
        price = bids_[0].price;
        quantity = bids_[0].quantity;
        uint64_t seq2 = sequence_.load(std::memory_order_acquire);
        return seq1 == seq2;  // Verify no update during read
    }

private:
    struct PriceLevel {
        uint64_t price;
        uint64_t quantity;
    };

    std::array<PriceLevel, 10> bids_;
    mutable std::atomic<uint64_t> sequence_{0};
};
```

BAD:
```cpp
class OrderBook {
    std::mutex mutex_;

    // Multiple writers need synchronization
    void updateBid(uint64_t price, uint64_t quantity) {
        std::lock_guard<std::mutex> lock(mutex_);  // Overhead
        bids_[0].price = price;
        bids_[0].quantity = quantity;
    }

    void readBestBid(uint64_t& price, uint64_t& quantity) {
        std::lock_guard<std::mutex> lock(mutex_);  // Overhead on read!
        price = bids_[0].price;
        quantity = bids_[0].quantity;
    }

private:
    struct PriceLevel {
        uint64_t price;
        uint64_t quantity;
    };
    std::array<PriceLevel, 10> bids_;
};
```

================================================================================
4. CODE ORGANIZATION BEST PRACTICES
================================================================================

BEST PRACTICE #11: Separate Interface from Implementation
----------------------------------------------------------
RULE: Keep headers minimal, put implementation in .cpp files.

GOOD:
```cpp
// order.hpp - Minimal header
#pragma once
#include <cstdint>

namespace hft {

struct Order {
    uint64_t order_id;
    uint32_t symbol_id;
    double price;
    int64_t quantity;
    char side;
};

class OrderManager {
public:
    explicit OrderManager(size_t capacity);
    ~OrderManager();

    bool submitOrder(const Order& order) noexcept;
    Order* findOrder(uint64_t order_id) noexcept;

private:
    class Impl;  // Forward declaration
    Impl* impl_;  // PIMPL idiom for non-critical class
};

} // namespace hft
```

```cpp
// order.cpp - Implementation details hidden
#include "order.hpp"
#include <array>

namespace hft {

class OrderManager::Impl {
public:
    std::array<Order, 10000> orders_;
    size_t count_ = 0;

    bool submitOrder(const Order& order) noexcept {
        if (count_ >= orders_.size()) return false;
        orders_[count_++] = order;
        return true;
    }
};

OrderManager::OrderManager(size_t capacity)
    : impl_(new Impl()) {}

OrderManager::~OrderManager() {
    delete impl_;
}

bool OrderManager::submitOrder(const Order& order) noexcept {
    return impl_->submitOrder(order);
}

} // namespace hft
```

BAD:
```cpp
// order.hpp - Exposes too much
#pragma once
#include <cstdint>
#include <array>
#include <vector>
#include <map>
#include <memory>
// ... 20 more includes

namespace hft {

class OrderManager {
public:
    explicit OrderManager(size_t capacity) : capacity_(capacity) {}

    bool submitOrder(const Order& order) noexcept {
        // Implementation in header causes recompilation of all dependents
        if (orders_.size() >= capacity_) return false;
        orders_.push_back(order);
        return true;
    }

private:
    size_t capacity_;
    std::vector<Order> orders_;  // Exposes implementation details
    std::map<uint64_t, size_t> index_;  // Forces map include
};

} // namespace hft
```

BEST PRACTICE #12: Use Namespaces Effectively
----------------------------------------------
RULE: Organize code in logical namespaces.

GOOD:
```cpp
namespace hft {
    namespace network {
        class TCPSocket { };
        class UDPSocket { };
    }

    namespace protocol {
        namespace fix {
            class Encoder { };
            class Decoder { };
        }
        namespace binary {
            class Encoder { };
            class Decoder { };
        }
    }

    namespace strategy {
        class MarketMaking { };
        class Arbitrage { };
    }
}

// Usage with namespace aliases
namespace net = hft::network;
namespace fix = hft::protocol::fix;

net::TCPSocket socket("127.0.0.1", 8080);
fix::Encoder encoder;
```

BAD:
```cpp
// Everything in global namespace or single namespace
class HFTTCPSocket { };  // Prefix hell
class HFTUDPSocket { };
class HFTFIXEncoder { };
class HFTFIXDecoder { };
class HFTBinaryEncoder { };
class HFTBinaryDecoder { };
class HFTMarketMaking { };
class HFTArbitrage { };

// Or everything in one namespace
namespace hft {
    class TCPSocket { };
    class UDPSocket { };
    class FIXEncoder { };
    class BinaryEncoder { };
    class MarketMaking { };
    class Arbitrage { };
    // ... 100 more classes, hard to navigate
}
```

================================================================================
5. TESTING BEST PRACTICES
================================================================================

BEST PRACTICE #13: Test Critical Paths Thoroughly
--------------------------------------------------
RULE: Focus testing on performance-critical code.

GOOD:
```cpp
#include <gtest/gtest.h>
#include <benchmark/benchmark.h>

// Functional test
TEST(OrderManagerTest, SubmitOrder) {
    OrderManager manager(1000);
    Order order{12345, 100, 150.25, 1000, 'B'};

    EXPECT_TRUE(manager.submitOrder(order));

    Order* found = manager.findOrder(12345);
    ASSERT_NE(found, nullptr);
    EXPECT_EQ(found->order_id, 12345);
    EXPECT_DOUBLE_EQ(found->price, 150.25);
}

// Performance test
static void BM_OrderSubmission(benchmark::State& state) {
    OrderManager manager(100000);
    Order order{12345, 100, 150.25, 1000, 'B'};

    for (auto _ : state) {
        auto start = std::chrono::high_resolution_clock::now();
        manager.submitOrder(order);
        auto end = std::chrono::high_resolution_clock::now();

        auto elapsed = std::chrono::duration_cast<std::chrono::nanoseconds>(
            end - start).count();
        state.SetIterationTime(elapsed * 1e-9);
    }

    state.SetItemsProcessed(state.iterations());
}
BENCHMARK(BM_OrderSubmission)->UseManualTime();

// Latency distribution test
TEST(PerformanceTest, SubmitOrderLatency) {
    OrderManager manager(100000);
    Order order{12345, 100, 150.25, 1000, 'B'};

    std::vector<uint64_t> latencies;
    latencies.reserve(10000);

    for (int i = 0; i < 10000; ++i) {
        auto start = __builtin_ia32_rdtsc();
        manager.submitOrder(order);
        auto end = __builtin_ia32_rdtsc();
        latencies.push_back(end - start);
    }

    std::sort(latencies.begin(), latencies.end());

    // Check percentiles
    EXPECT_LT(latencies[5000], 1000);   // p50 < 1000 cycles
    EXPECT_LT(latencies[9900], 5000);   // p99 < 5000 cycles
    EXPECT_LT(latencies[9990], 10000);  // p99.9 < 10000 cycles
}
```

BAD:
```cpp
// Only basic functional tests, no performance validation
TEST(OrderManagerTest, BasicTest) {
    OrderManager manager;
    // Test passes but no performance guarantees
    EXPECT_TRUE(manager.submitOrder(Order{}));
}
```

This document continues with anti-patterns, optimization pitfalls, debugging
practices, deployment strategies, and comprehensive code review checklists...

================================================================================
6. COMMON ANTI-PATTERNS TO AVOID
================================================================================

ANTI-PATTERN #1: Premature Abstraction
---------------------------------------
BAD: Creating complex abstraction hierarchies before understanding requirements

```cpp
// Overly abstract before needed
class IOrderProcessor {
    virtual void preProcess() = 0;
    virtual void process() = 0;
    virtual void postProcess() = 0;
};

class AbstractOrderProcessor : public IOrderProcessor {
    // Complex template method pattern
};

class SpecificOrderProcessor : public AbstractOrderProcessor {
    // Finally the actual code
};
```

GOOD: Start simple, refactor when patterns emerge

```cpp
// Simple and direct
bool submitOrder(const Order& order) noexcept {
    if (!validate(order)) return false;
    encode(order);
    return send();
}
```

ANTI-PATTERN #2: Allocation in Hot Path
----------------------------------------
BAD: Dynamic allocation in critical path

```cpp
void processMarketData(const MarketData& data) {
    auto order = std::make_shared<Order>();  // TERRIBLE
    std::string message = formatMessage(data);  // TERRIBLE
    std::vector<double> prices;  // TERRIBLE
    prices.push_back(data.price);
}
```

GOOD: Pre-allocated, stack-based

```cpp
void processMarketData(const MarketData& data) noexcept {
    Order order;  // Stack
    char message[256];  // Stack
    formatMessage(data, message, sizeof(message));

    double prices[10];  // Stack
    prices[0] = data.price;
}
```

Complete anti-patterns list with detailed examples continues...
