================================================================================
              SYSTEM ADMINISTRATOR DAILY CHECKLIST - HFT SYSTEM
                      SYSTEM HEALTH & MAINTENANCE
================================================================================

VERSION: 1.0
CLASSIFICATION: INTERNAL - SYSTEM OPERATIONS
ESTIMATED TIME: 60-90 MINUTES
REQUIRED FREQUENCY: DAILY (Before Market Open)

================================================================================
                            CHECKLIST HEADER
================================================================================

System Administrator Information:
---------------------------------
Name: _______________________________
Employee ID: _______________________________
Date: _______________________________
Start Time (UTC): _______________________________
On-Call Status: [ ] PRIMARY  [ ] BACKUP  [ ] SCHEDULED

System Environment:
------------------
Environment: [ ] PRODUCTION  [ ] UAT  [ ] DEV  [ ] ALL
Data Center: [ ] PRIMARY  [ ] DR  [ ] BOTH
Maintenance Window: [ ] YES [ ] NO  If YES: ________ to ________

Sign-Off Section:
----------------
Sys Admin Sign-Off: _______________________________ Time: ___________
Lead Sys Admin Review: _______________________________ Time: ___________
Overall Status: [ ] PASS  [ ] FAIL  [ ] CONDITIONAL PASS

================================================================================
                            PRE-REQUISITES
================================================================================

Required Access:
---------------
[ ] Root/sudo access to all servers
[ ] BMC/IPMI access (out-of-band management)
[ ] Hypervisor/VM management console
[ ] Storage array management console
[ ] Backup system console
[ ] Monitoring dashboard (Nagios/Zabbix/Prometheus)
[ ] Log aggregation system (ELK/Splunk)
[ ] Configuration management system (Ansible/Puppet)
[ ] Ticketing system

Required Tools:
--------------
[ ] SSH client with keys
[ ] System monitoring utilities (top, htop, iotop, iftop)
[ ] Disk utilities (smartctl, df, du, iostat)
[ ] Network utilities (netstat, ss, tcpdump)
[ ] Performance analysis tools (perf, strace, ltrace)
[ ] Log analysis tools (grep, awk, sed)

Critical Documentation:
----------------------
[ ] Server inventory list
[ ] System architecture diagrams
[ ] Backup and recovery procedures
[ ] Disaster recovery plan
[ ] Escalation procedures
[ ] Vendor support contracts

Dependencies:
------------
Must coordinate with:
[ ] Network team (connectivity issues)
[ ] Development team (application issues)
[ ] Database team (database health)
[ ] Security team (security events)

================================================================================
                  SECTION 1: SERVER HEALTH VALIDATION
                          [TIME: 15-20 MIN]
================================================================================

STEP 1.1: Critical Server Availability
---------------------------------------
Action: Verify all critical servers are online and accessible

Production Servers Status:

Trading Servers:
Server Name              IP Address         Status    Uptime      Issues
-----------              ----------         ------    ------      ------
trading-prod-01          _____________      [ ] UP    ________    _______
trading-prod-02          _____________      [ ] UP    ________    _______
trading-prod-03 (hot)    _____________      [ ] UP    ________    _______
trading-dr-01 (warm)     _____________      [ ] UP    ________    _______

Market Data Servers:
Server Name              IP Address         Status    Uptime      Issues
-----------              ----------         ------    ------      ------
marketdata-prod-01       _____________      [ ] UP    ________    _______
marketdata-prod-02       _____________      [ ] UP    ________    _______

Risk Management Servers:
Server Name              IP Address         Status    Uptime      Issues
-----------              ----------         ------    ------      ------
risk-prod-01             _____________      [ ] UP    ________    _______
risk-prod-02             _____________      [ ] UP    ________    _______

Database Servers:
Server Name              IP Address         Status    Uptime      Issues
-----------              ----------         ------    ------      ------
db-prod-01 (primary)     _____________      [ ] UP    ________    _______
db-prod-02 (replica)     _____________      [ ] UP    ________    _______

Commands:
for host in $(cat /etc/hft/servers.list); do
  ping -c 3 $host && echo "$host: UP" || echo "$host: DOWN"
done

Accessibility Check:
[ ] All servers pingable: [ ] YES [ ] NO
[ ] All servers SSH accessible: [ ] YES [ ] NO
[ ] BMC/IPMI accessible: [ ] YES [ ] NO
[ ] Average response time: _______ ms (expect: <5ms)

Server Count Summary:
[ ] Total production servers: _______
[ ] Servers online: _______
[ ] Servers offline: _______ (expect: 0)
[ ] Servers in maintenance: _______

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify offline servers
2. Check physical connectivity (if co-located)
3. Access via BMC/IPMI if SSH unavailable
4. Review server logs for crash/reboot
5. Attempt remote power cycle if needed
6. Escalate to data center if hardware failure
7. ESCALATE: SEVERITY LEVEL 1 for trading servers

---

STEP 1.2: CPU and Load Monitoring
----------------------------------
Action: Check CPU utilization and system load on all servers

CPU Utilization:

Trading Servers:
Server               CPU %    Load Avg    Cores    Status
------               -----    --------    -----    ------
trading-prod-01      ____%    _.__.__     ___      [ ] OK
trading-prod-02      ____%    _.__.__     ___      [ ] OK
trading-prod-03      ____%    _.__.__     ___      [ ] OK

Commands (run on each server):
uptime
top -bn1 | grep "Cpu(s)"
mpstat 1 5

Expected Result:
- CPU usage <70% (allow headroom for spikes)
- Load average < number of CPU cores
- No CPU throttling

Detailed CPU Analysis (for high utilization):
Server: trading-prod-01
[ ] User CPU: ______% (application workload)
[ ] System CPU: ______% (kernel/IO)
[ ] Iowait: ______% (disk bottleneck if high)
[ ] Idle: ______% (expect: >20%)

Top CPU Consuming Processes:
PID     User      CPU%    Command                           Status
---     ----      ----    -------                           ------
_____   _______   ____%   _______________________           [ ] OK
_____   _______   ____%   _______________________           [ ] OK
_____   _______   ____%   _______________________           [ ] OK

Load Average Trend:
Server               1-min    5-min    15-min    Trend
------               -----    -----    ------    -----
trading-prod-01      ___      ___      ___       [ ] STABLE [ ] RISING [ ] FALLING

CPU Core Affinity (for trading applications):
[ ] Trading app pinned to cores: [ ] YES [ ] NO
[ ] Isolated CPUs for HFT: [ ] YES [ ] NO
[ ] IRQ affinity configured: [ ] YES [ ] NO

Commands:
taskset -cp [PID]
cat /proc/irq/*/smp_affinity

CPU Frequency Scaling:
[ ] Governor: [ ] performance [ ] powersave [ ] ondemand
   (expect: performance for HFT servers)
[ ] CPU frequency: _______ MHz (expect: max frequency)
[ ] Turbo boost: [ ] ENABLED [ ] DISABLED

Commands:
cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
cpupower frequency-info

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify high CPU processes
2. Check if expected (market hours vs off-hours)
3. Investigate runaway processes
4. Verify CPU governor set to performance
5. Check for CPU throttling (thermal issues)
6. Consider load balancing or scaling
7. ESCALATE: SEVERITY LEVEL 2 if CPU >90%

---

STEP 1.3: Memory Utilization
-----------------------------
Action: Check memory usage and identify potential issues

Memory Status:

Trading Servers:
Server               Total    Used     Free     Cached   Available   % Used
------               -----    ----     ----     ------   ---------   ------
trading-prod-01      ___ GB   ___ GB   ___ GB   ___ GB   ___ GB      ____%
trading-prod-02      ___ GB   ___ GB   ___ GB   ___ GB   ___ GB      ____%
trading-prod-03      ___ GB   ___ GB   ___ GB   ___ GB   ___ GB      ____%

Commands:
free -h
vmstat 1 5

Expected Result:
- Memory usage <80%
- Swap usage: 0% (or minimal)
- No OOM killer activations
- Page faults: normal level

Swap Usage:
Server               Swap Total    Swap Used    % Used    Status
------               ----------    ---------    ------    ------
trading-prod-01      ___ GB        ___ GB       ____%     [ ] OK
trading-prod-02      ___ GB        ___ GB       ____%     [ ] OK

[ ] Swap usage: ______% (expect: 0% for production HFT servers)
[ ] Swapping activity: [ ] NONE [ ] MINIMAL [ ] EXCESSIVE

If swapping detected:
Commands:
vmstat 1 10  # Look at si/so columns
swapon -s

Top Memory Consuming Processes:
PID     User      MEM%    RSS       Command                    Status
---     ----      ----    ---       -------                    ------
_____   _______   ____%   ___ MB    ____________________       [ ] OK
_____   _______   ____%   ___ MB    ____________________       [ ] OK
_____   _______   ____%   ___ MB    ____________________       [ ] OK

Commands:
ps aux --sort=-%mem | head -20

Memory Leak Detection:
[ ] Check for growing memory usage over time
[ ] Review application memory trends (past 24 hours)

Application Memory (Trading Engine):
Time         RSS        VSZ        Delta      Status
----         ---        ---        -----      ------
00:00        ___ MB     ___ MB     N/A        [ ] OK
06:00        ___ MB     ___ MB     ___ MB     [ ] OK
12:00        ___ MB     ___ MB     ___ MB     [ ] OK
18:00        ___ MB     ___ MB     ___ MB     [ ] OK

Memory should be stable, not continuously growing

Huge Pages Configuration:
[ ] Huge pages enabled: [ ] YES [ ] NO
[ ] Huge page size: _______ MB
[ ] Total huge pages: _______
[ ] Free huge pages: _______
[ ] Huge pages used by HFT app: [ ] YES [ ] NO

Commands:
cat /proc/meminfo | grep -i huge
grep -i huge /proc/[PID]/numa_maps

OOM Killer Activity:
[ ] OOM kills (last 24 hours): _______ (expect: 0)

Commands:
dmesg | grep -i "out of memory"
grep -i "killed process" /var/log/kern.log

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify memory-hungry processes
2. Check for memory leaks
3. Clear cache if safe (sync; echo 3 > /proc/sys/vm/drop_caches)
4. Investigate OOM killer activations
5. Consider increasing RAM
6. Restart leaky applications during maintenance window
7. ESCALATE: SEVERITY LEVEL 1 if memory exhausted

---

STEP 1.4: Disk Space and I/O
-----------------------------
Action: Monitor disk space and I/O performance

Disk Space:

Trading Servers:
Server: trading-prod-01
Filesystem         Size    Used    Avail   Use%    Mounted on         Status
----------         ----    ----    -----   ----    ----------         ------
/dev/sda1          ___GB   ___GB   ___GB   ___%    /                  [ ] OK
/dev/sdb1          ___GB   ___GB   ___GB   ___%    /opt/hft           [ ] OK
/dev/sdc1          ___GB   ___GB   ___GB   ___%    /var/log           [ ] OK
/dev/sdd1          ___GB   ___GB   ___GB   ___%    /data              [ ] OK

Commands:
df -h
df -i  # Check inode usage

Expected Result:
- All filesystems <80% usage
- Inode usage <80%
- No filesystems full

Critical Directories:
[ ] /opt/hft (application): ______% (threshold: 80%)
[ ] /var/log (logs): ______% (threshold: 80%)
[ ] /data (data storage): ______% (threshold: 85%)
[ ] /tmp (temporary): ______% (threshold: 90%)

Disk Usage Growth Rate:
Filesystem    Yesterday    Today      Growth     Days to Full
----------    ---------    -----      ------     ------------
/opt/hft      ____%        ____%      ____ GB    _________
/var/log      ____%        ____%      ____ GB    _________
/data         ____%        ____%      ____ GB    _________

Large Files (>1GB):
Commands:
find /opt/hft -type f -size +1G -exec ls -lh {} \;
find /var/log -type f -size +1G -exec ls -lh {} \;

File               Size      Age      Action Needed
----               ----      ---      -------------
_____________      ___ GB    ___      [ ] ARCHIVE [ ] DELETE [ ] KEEP
_____________      ___ GB    ___      [ ] ARCHIVE [ ] DELETE [ ] KEEP

Disk I/O Performance:

Commands:
iostat -x 1 5

Device    r/s    w/s    rkB/s    wkB/s    await    %util    Status
------    ---    ---    -----    -----    -----    -----    ------
sda       ___    ___    _____    _____    ___ms    ___%     [ ] OK
sdb       ___    ___    _____    _____    ___ms    ___%     [ ] OK
sdc       ___    ___    _____    _____    ___ms    ___%     [ ] OK

Expected Result:
- I/O wait time <10ms
- Disk utilization <80%
- No I/O errors

Disk I/O Latency:
[ ] Read latency: _______ ms (target: <5ms for SSD)
[ ] Write latency: _______ ms (target: <10ms for SSD)
[ ] I/O queue depth: _______ (should be low)

RAID Status (if applicable):
[ ] RAID controller: _______________________
[ ] RAID level: [ ] RAID 0 [ ] RAID 1 [ ] RAID 5 [ ] RAID 10
[ ] RAID status: [ ] OPTIMAL [ ] DEGRADED [ ] FAILED
[ ] Failed drives: _______ (expect: 0)

Commands:
mdadm --detail /dev/md0  # Software RAID
# Or check hardware RAID (vendor-specific command)

SMART Status:
Commands:
smartctl -a /dev/sda

Device    Health    Errors    Reallocated    Power-On    Status
------    ------    ------    -----------    --------    ------
sda       [ ] OK    _____     _____          _____ hrs   [ ] OK
sdb       [ ] OK    _____     _____          _____ hrs   [ ] OK
sdc       [ ] OK    _____     _____          _____ hrs   [ ] OK

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify full or nearly full filesystems
2. Clean up old logs (use logrotate)
3. Archive or delete unnecessary files
4. Investigate high I/O wait
5. Check RAID status and replace failed drives
6. Monitor SMART status for failing drives
7. ESCALATE: SEVERITY LEVEL 2 if critical partition >90%

================================================================================
                 SECTION 2: APPLICATION HEALTH
                       [TIME: 15-20 MIN]
================================================================================

STEP 2.1: Critical Services Status
-----------------------------------
Action: Verify all critical services are running

Service Status Check:

Trading Application:
Service Name              Server              Status       PID      Uptime
------------              ------              ------       ---      ------
hft-trading-engine        trading-prod-01     [ ] RUNNING  _____    ________
hft-order-router          trading-prod-01     [ ] RUNNING  _____    ________
hft-risk-manager          risk-prod-01        [ ] RUNNING  _____    ________
hft-market-data           marketdata-prod-01  [ ] RUNNING  _____    ________

Commands (on each server):
systemctl status hft-trading-engine
ps aux | grep hft-trading-engine

Expected Result:
- All services: RUNNING (active)
- Uptime > 1 hour (stable)
- Process using expected resources

Service Health Checks:

Trading Engine:
[ ] Process running: [ ] YES [ ] NO
[ ] Listening on correct ports: [ ] YES [ ] NO
[ ] Responding to health checks: [ ] YES [ ] NO
[ ] No errors in recent logs: [ ] YES [ ] NO

Commands:
netstat -tlnp | grep [PORT]
curl http://localhost:[HEALTH_PORT]/health

Expected Response:
{"status": "healthy", "version": "1.0.0", "uptime": "12345"}

Service Restart History (last 24 hours):
Service                   Restarts    Last Restart Time    Reason
-------                   --------    -----------------    ------
hft-trading-engine        _______     _____________        __________
hft-order-router          _______     _____________        __________

[ ] Unexpected restarts: _______ (expect: 0)
[ ] All restarts documented: [ ] YES [ ] NO [ ] N/A

Supporting Services:
Service              Server           Status       Critical?
-------              ------           ------       ---------
postgres             db-prod-01       [ ] RUNNING  [ ] YES
redis                trading-prod-01  [ ] RUNNING  [ ] YES
zookeeper            trading-prod-01  [ ] RUNNING  [ ] YES
kafka                trading-prod-01  [ ] RUNNING  [ ] NO

Database Connectivity:
[ ] Primary database reachable: [ ] YES [ ] NO
[ ] Replica database reachable: [ ] YES [ ] NO
[ ] Connection pool healthy: [ ] YES [ ] NO

Commands:
psql -h db-prod-01 -U hft -c "SELECT 1;"

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify stopped services
2. Review service logs for errors
3. Attempt to start stopped services
4. Check for port conflicts
5. Verify dependencies running
6. Do NOT allow trading if critical services down
7. ESCALATE: SEVERITY LEVEL 1 for critical services

---

STEP 2.2: Application Performance Metrics
------------------------------------------
Action: Check application performance metrics

Trading Engine Metrics:

Response Time:
[ ] Average response time: _______ μs (target: <1000 μs)
[ ] P95 response time: _______ μs (target: <5000 μs)
[ ] P99 response time: _______ μs (target: <10000 μs)

Throughput:
[ ] Orders processed/sec: _______ (expected: _______)
[ ] Market data messages/sec: _______ (expected: _______)
[ ] Peak throughput (24h): _______ ops/sec

Error Rates:
[ ] Application errors (24h): _______ (expect: <10)
[ ] Error rate: _______% (expect: <0.1%)
[ ] Database errors: _______ (expect: 0)
[ ] Network errors: _______ (investigate if >5)

Commands:
curl http://localhost:[METRICS_PORT]/metrics

Sample Metrics Output:
hft_orders_total{status="success"} 123456
hft_orders_total{status="rejected"} 234
hft_latency_microseconds{quantile="0.99"} 8542

Thread/Connection Pools:
[ ] Active trading threads: _______ / _______ (total)
[ ] Database connections: _______ / _______ (pool size)
[ ] Idle connections: _______
[ ] Connection timeouts: _______ (expect: 0)

JVM Metrics (if Java-based):
[ ] Heap usage: _______% (threshold: <80%)
[ ] GC pause time: _______ ms (expect: <100ms)
[ ] GC frequency: _______ times/hour
[ ] Old gen usage: _______% (threshold: <80%)

Commands:
jstat -gc [PID] 1000 10

Cache Performance:
[ ] Cache hit rate: _______% (expect: >90%)
[ ] Cache size: _______ MB / _______ MB (max)
[ ] Cache evictions: _______ (monitor trend)

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Investigate performance degradation
2. Check for resource bottlenecks
3. Review recent code deployments
4. Analyze slow queries/operations
5. Consider application restart during maintenance window
6. ESCALATE: SEVERITY LEVEL 2

---

STEP 2.3: Log Analysis
-----------------------
Action: Review application and system logs for errors and warnings

Application Logs:

Critical Errors (last 24 hours):
Commands:
grep -i "error\|critical\|fatal" /var/log/hft/trading/*.log | tail -100

Log File              Error Count    Critical Count    Last Error Time
--------              -----------    --------------    ---------------
trading.log           _________      _________         _____________
risk.log              _________      _________         _____________
market_data.log       _________      _________         _____________
orders.log            _________      _________         _____________

Recent Critical Errors (last 10):
Timestamp          Severity    Component          Message
---------          --------    ---------          -------
_____________      ________    ____________       _______________________
_____________      ________    ____________       _______________________
_____________      ________    ____________       _______________________

Expected Result:
- Zero CRITICAL errors
- ERROR count < 10 per day
- All errors investigated

System Logs:

Commands:
journalctl -p err -since "24 hours ago"
grep -i "error\|fail\|critical" /var/log/syslog | tail -50

System Error Summary:
Log Type          Error Count    Requires Action?
--------          -----------    ----------------
Kernel errors     _________      [ ] YES [ ] NO
Hardware errors   _________      [ ] YES [ ] NO
Auth failures     _________      [ ] YES [ ] NO
Service failures  _________      [ ] YES [ ] NO

Hardware Errors:
Commands:
dmesg | grep -i "error\|fail"

[ ] Disk errors: _______ (expect: 0)
[ ] Network errors: _______ (expect: 0)
[ ] Memory errors: _______ (expect: 0)
[ ] CPU errors: _______ (expect: 0)

Authentication Failures:
Commands:
grep "Failed password" /var/log/auth.log | tail -20

[ ] Failed SSH attempts: _______ (investigate if >100)
[ ] Failed sudo attempts: _______ (expect: 0 for production)

Log Rotation Status:
[ ] Logrotate configured: [ ] YES [ ] NO
[ ] Log rotation working: [ ] YES [ ] NO
[ ] Old logs compressed: [ ] YES [ ] NO
[ ] Logs archived: [ ] YES [ ] NO

Log Disk Usage:
[ ] /var/log size: _______ GB (threshold: _____ GB)
[ ] Oldest log file: _______ days old
[ ] Log retention: _______ days (policy: _____ days)

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Investigate all critical errors
2. Address recurring errors
3. Fix log rotation if not working
4. Archive old logs if disk space low
5. Document unresolved errors
6. ESCALATE: SEVERITY LEVEL 2 for critical errors

================================================================================
                  SECTION 3: BACKUP & RECOVERY
                       [TIME: 10-15 MIN]
================================================================================

STEP 3.1: Backup Status Verification
-------------------------------------
Action: Verify backups completed successfully

Backup Summary (Last 24 Hours):

Full System Backup:
[ ] Backup type: [ ] FULL [ ] INCREMENTAL [ ] DIFFERENTIAL
[ ] Scheduled time: __________
[ ] Actual completion time: __________
[ ] Status: [ ] SUCCESS [ ] FAILED [ ] RUNNING [ ] NOT STARTED
[ ] Duration: _______ hours (expected: _______ hours)
[ ] Backup size: _______ GB (previous: _______ GB)
[ ] Backup location: _______________________________

Database Backup:
[ ] Backup type: [ ] FULL [ ] INCREMENTAL [ ] TRANSACTION LOG
[ ] Scheduled time: __________
[ ] Actual completion time: __________
[ ] Status: [ ] SUCCESS [ ] FAILED [ ] RUNNING [ ] NOT STARTED
[ ] Duration: _______ minutes (expected: _______ minutes)
[ ] Backup size: _______ GB
[ ] Backup location: _______________________________

Configuration Backup:
[ ] Status: [ ] SUCCESS [ ] FAILED
[ ] Files backed up: _______
[ ] Backup location: _______________________________

Log Files Backup:
[ ] Status: [ ] SUCCESS [ ] FAILED
[ ] Size: _______ GB
[ ] Backup location: _______________________________

Backup Integrity:
[ ] Checksums verified: [ ] YES [ ] NO
[ ] Backup encrypted: [ ] YES [ ] NO
[ ] Backup compressed: [ ] YES [ ] NO
[ ] Off-site copy: [ ] YES [ ] NO

Commands:
cat /var/log/backup/backup.log | tail -100
ls -lh /backup/hft/$(date +%Y%m%d)*

Recent Backup History:
Date          Type      Status    Size      Duration    Issues
----          ----      ------    ----      --------    ------
Today         FULL      [ ] OK    ___ GB    ___ hrs     _______
Yesterday     INCR      [ ] OK    ___ GB    ___ min     _______
2 days ago    INCR      [ ] OK    ___ GB    ___ min     _______

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Identify failed backup job
2. Review backup logs for errors
3. Retry failed backup
4. Verify backup storage space available
5. Test backup restoration (if time permits)
6. Do NOT skip backup validation
7. ESCALATE: SEVERITY LEVEL 2 if backups consistently failing

---

STEP 3.2: Disaster Recovery Readiness
--------------------------------------
Action: Verify DR systems are ready for failover

DR Data Center Status:
[ ] DR site reachable: [ ] YES [ ] NO
[ ] DR servers powered on: [ ] YES [ ] NO
[ ] Data replication current: [ ] YES [ ] NO
[ ] Replication lag: _______ seconds (expect: <60)

DR Servers:
Server Name         Status    Last Sync       Replication Lag
-----------         ------    ---------       ---------------
trading-dr-01       [ ] UP    _________       _____ sec
db-dr-01            [ ] UP    _________       _____ sec

Data Replication:
[ ] Database replication: [ ] ACTIVE [ ] DELAYED [ ] BROKEN
[ ] File replication: [ ] ACTIVE [ ] DELAYED [ ] BROKEN
[ ] Log replication: [ ] ACTIVE [ ] DELAYED [ ] BROKEN

Replication Metrics:
[ ] Replication method: [ ] SYNC [ ] ASYNC
[ ] Data transferred (24h): _______ GB
[ ] Replication errors: _______ (expect: 0)
[ ] Last successful sync: _________

Failover Test:
[ ] Last failover test date: _________
[ ] Test result: [ ] SUCCESS [ ] PARTIAL [ ] FAILED
[ ] Time to failover: _______ minutes (target: <30 min)
[ ] Next scheduled test: _________

Recovery Time Objective (RTO):
[ ] Target RTO: _______ minutes
[ ] Actual RTO (last test): _______ minutes
[ ] RTO met: [ ] YES [ ] NO

Recovery Point Objective (RPO):
[ ] Target RPO: _______ minutes
[ ] Current replication lag: _______ seconds
[ ] RPO met: [ ] YES [ ] NO

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Investigate replication issues
2. Check network connectivity to DR site
3. Verify DR servers operational
4. Fix broken replication immediately
5. Document DR readiness issues
6. ESCALATE: SEVERITY LEVEL 2

================================================================================
                  SECTION 4: SECURITY & COMPLIANCE
                       [TIME: 10-15 MIN]
================================================================================

STEP 4.1: Security Status Check
--------------------------------
Action: Verify system security posture

User Access Audit:
[ ] Active user accounts: _______
[ ] Admin/root access accounts: _______
[ ] Accounts with sudo: _______
[ ] Service accounts: _______

Commands:
cat /etc/passwd | grep -v "nologin"
sudo -l -U [username]

Recent Login Activity:
Commands:
last -20
lastb -20  # Failed logins

Successful Logins (last 24 hours):
User          From                Time           Terminal
----          ----                ----           --------
________      _____________       _________      _______
________      _____________       _________      _______

Failed Login Attempts (last 24 hours):
User          From                Time           Count
----          ----                ----           -----
________      _____________       _________      _____
________      _____________       _________      _____

[ ] Failed login attempts: _______ (investigate if >50)
[ ] Failed logins from external IPs: _______ (investigate if >0)

Security Updates:
[ ] Security patches available: _______
[ ] Critical security updates: _______ (expect: 0)
[ ] Last system update: _________

Commands:
apt list --upgradable | grep -i security  # Debian/Ubuntu
yum list updates --security  # RHEL/CentOS

Critical Updates (if any):
Package          Current Version    New Version    Severity
-------          ---------------    -----------    --------
__________       __________         __________     [ ] CRITICAL
__________       __________         __________     [ ] HIGH

Antivirus/Malware (if applicable):
[ ] AV software: _______________________
[ ] Last scan: _________
[ ] Threats detected: _______ (expect: 0)
[ ] Definitions updated: [ ] YES [ ] NO
[ ] Definition version: _________

File Integrity Monitoring:
[ ] FIM software: [ ] AIDE [ ] Tripwire [ ] OSSEC [ ] Other: _______
[ ] Last scan: _________
[ ] Changes detected: _______
[ ] Unauthorized changes: _______ (expect: 0)

Commands:
aide --check

Open Ports:
Commands:
netstat -tlnp | grep LISTEN
ss -tlnp

Service          Port    Process         Expected?    Status
-------          ----    -------         ---------    ------
SSH              22      sshd            [ ] YES      [ ] OK
Trading          8080    hft-engine      [ ] YES      [ ] OK
Database         5432    postgres        [ ] YES      [ ] OK
________         ____    __________      [ ] YES      [ ] OK

[ ] Unexpected open ports: _______ (investigate)

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Investigate security concerns
2. Disable compromised accounts
3. Apply critical security patches (during maintenance window)
4. Close unnecessary open ports
5. Investigate unauthorized file changes
6. ESCALATE: SEVERITY LEVEL 1 for security breaches

---

STEP 4.2: Compliance and Auditing
----------------------------------
Action: Verify compliance requirements are met

Audit Logging:
[ ] Audit daemon running: [ ] YES [ ] NO
[ ] Audit logs being written: [ ] YES [ ] NO
[ ] Audit log size: _______ MB
[ ] Audit log retention: _______ days (policy: _____ days)

Commands:
systemctl status auditd
auditctl -l

Key Audit Rules:
Rule                                  Status
----                                  ------
Watch /etc/passwd modifications       [ ] ACTIVE
Watch /etc/shadow modifications       [ ] ACTIVE
Watch sudo usage                      [ ] ACTIVE
Watch system calls (trading app)      [ ] ACTIVE

Compliance Requirements:
[ ] Audit logs tamper-proof: [ ] YES [ ] NO
[ ] Logs sent to SIEM: [ ] YES [ ] NO
[ ] User activity logged: [ ] YES [ ] NO
[ ] Privileged actions logged: [ ] YES [ ] NO
[ ] Time synchronization (NTP): [ ] YES [ ] NO

NTP Status:
Commands:
timedatectl status
chronyc tracking  # or ntpq -p

[ ] NTP synchronized: [ ] YES [ ] NO
[ ] Time offset: _______ ms (expect: <100ms)
[ ] NTP servers reachable: [ ] YES [ ] NO

Time Accuracy:
[ ] System time: _________
[ ] NTP time: _________
[ ] Offset: _______ ms
[ ] Accurate: [ ] YES [ ] NO

Regulatory Compliance (HFT specific):
[ ] All trades logged with timestamps: [ ] YES [ ] NO
[ ] Order lifecycle tracked: [ ] YES [ ] NO
[ ] Risk checks logged: [ ] YES [ ] NO
[ ] System changes documented: [ ] YES [ ] NO

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Fix audit logging immediately
2. Synchronize time if out of sync
3. Document compliance gaps
4. Notify compliance team
5. ESCALATE: SEVERITY LEVEL 2

================================================================================
                  SECTION 5: MONITORING & ALERTING
                       [TIME: 5-10 MIN]
================================================================================

STEP 5.1: Monitoring System Health
-----------------------------------
Action: Verify monitoring and alerting systems are operational

Monitoring Platform:
Platform: [ ] Nagios [ ] Zabbix [ ] Prometheus [ ] DataDog [ ] Other: _______

[ ] Monitoring system accessible: [ ] YES [ ] NO
[ ] All servers being monitored: [ ] YES [ ] NO
[ ] Agents responding: _______ / _______ servers
[ ] Data collection current: [ ] YES [ ] NO

Monitored Metrics:
[ ] CPU usage: [ ] MONITORED
[ ] Memory usage: [ ] MONITORED
[ ] Disk space: [ ] MONITORED
[ ] Disk I/O: [ ] MONITORED
[ ] Network traffic: [ ] MONITORED
[ ] Service status: [ ] MONITORED
[ ] Application metrics: [ ] MONITORED

Active Alerts:
[ ] Current alerts: _______
[ ] Critical alerts: _______ (investigate immediately)
[ ] Warning alerts: _______
[ ] Info alerts: _______

Alert List:
Severity    Host               Alert Description                Age
--------    ----               -----------------                ---
________    ____________       _______________________          ________
________    ____________       _______________________          ________

Alert Response Times (last 24 hours):
Alert Type        Avg Response    Max Response    Target
----------        ------------    ------------    ------
Critical          _____ min       _____ min       15 min
Warning           _____ min       _____ min       60 min

Alert Notifications:
[ ] Email notifications working: [ ] YES [ ] NO
[ ] SMS notifications working: [ ] YES [ ] NO
[ ] PagerDuty integration: [ ] YES [ ] NO [ ] N/A
[ ] Slack/Teams integration: [ ] YES [ ] NO [ ] N/A

Dashboard Status:
[ ] Performance dashboard accessible: [ ] YES [ ] NO
[ ] All widgets loading: [ ] YES [ ] NO
[ ] Real-time data updating: [ ] YES [ ] NO

PASS: [ ]  FAIL: [ ]  Time: _________

If FAIL:
1. Fix monitoring system issues
2. Restart monitoring agents
3. Acknowledge and investigate alerts
4. Verify alert delivery
5. Implement manual monitoring if system down
6. ESCALATE: SEVERITY LEVEL 3

================================================================================
                  SECTION 6: FINAL SYSTEM APPROVAL
                       [TIME: 5-10 MIN]
================================================================================

STEP 6.1: System Readiness Summary
-----------------------------------
Action: Make final determination on system readiness

System Health Summary:
---------------------

Server Infrastructure:
[ ] All critical servers online: [ ] YES [ ] NO
[ ] CPU utilization acceptable: [ ] YES [ ] NO
[ ] Memory utilization acceptable: [ ] YES [ ] NO
[ ] Disk space sufficient: [ ] YES [ ] NO
[ ] I/O performance acceptable: [ ] YES [ ] NO

Application Health:
[ ] All services running: [ ] YES [ ] NO
[ ] Application performance good: [ ] YES [ ] NO
[ ] No critical errors: [ ] YES [ ] NO
[ ] Database accessible: [ ] YES [ ] NO

Backup & Recovery:
[ ] Recent backups successful: [ ] YES [ ] NO
[ ] DR systems ready: [ ] YES [ ] NO
[ ] Replication current: [ ] YES [ ] NO

Security:
[ ] No security incidents: [ ] YES [ ] NO
[ ] Security patches current: [ ] YES [ ] NO
[ ] Audit logging operational: [ ] YES [ ] NO

Monitoring:
[ ] Monitoring systems operational: [ ] YES [ ] NO
[ ] Alerts configured: [ ] YES [ ] NO
[ ] No critical alerts: [ ] YES [ ] NO

SYSTEM AUTHORIZATION:
--------------------

[ ] APPROVED - All checks passed, system ready for trading
[ ] APPROVED WITH RESTRICTIONS - System operational with limitations:
    Limitation: _______________________________
    Limitation: _______________________________
[ ] NOT APPROVED - System issues must be resolved:
    Issue: _______________________________
    Issue: _______________________________

If APPROVED WITH RESTRICTIONS:
Enhanced monitoring: [ ] YES - Frequency: every _______ minutes
Expected resolution time: __________
Workaround in place: _______________________________

SYSTEM ADMINISTRATOR CERTIFICATION:
----------------------------------
I certify that:
1. I have completed all checklist items accurately
2. All systems are operational or acceptable alternatives in place
3. Security posture is adequate
4. Backups are current and valid
5. Monitoring and alerting is functional

System Administrator Name: _______________________________
Signature: _______________________________
Date/Time: _______________________________
Employee ID: _______________________________

LEAD SYSTEM ADMINISTRATOR REVIEW:
---------------------------------
Review Required: [ ] YES [ ] NO

If YES:
Issue requiring review: _______________________________
Lead Decision: [ ] APPROVE [ ] APPROVE WITH CONDITIONS [ ] DENY

Lead Name: _______________________________
Signature: _______________________________
Date/Time: _______________________________

Comments/Notes:
_____________________________________________________________________________
_____________________________________________________________________________

CONTINUOUS MONITORING:
---------------------
During Trading Hours:
[ ] Monitor dashboards: [ ] CONTINUOUS
[ ] Review alerts: [ ] CONTINUOUS
[ ] Check resource utilization: Every _____ minutes
[ ] Review application logs: Every _____ minutes

NEXT STEPS:
-----------
[ ] Communicate system status to operations team
[ ] Begin continuous monitoring
[ ] Respond to alerts promptly
[ ] Complete weekly_checks.txt as scheduled
[ ] Document any incidents

================================================================================
                          END OF CHECKLIST
================================================================================

Document saved to: /var/log/hft/checklists/[DATE]/sysadmin_daily_[TIMESTAMP].log

For questions or issues, contact:
System Operations: +1-XXX-XXX-XXXX
Lead System Administrator: +1-XXX-XXX-XXXX
Data Center Support: +1-XXX-XXX-XXXX
