================================================================================
MARKET MAKER OPTIMIZATION AND MACHINE LEARNING
================================================================================

File: 12_mm_optimization.txt
Purpose: Parameter tuning, strategy optimization, ML for market making
Topics: Hyperparameter optimization, RL, feature engineering
Last Updated: 2025-11-26

TABLE OF CONTENTS:
1. Parameter Optimization Overview
2. Grid Search and Bayesian Optimization
3. Walk-Forward Optimization
4. Feature Engineering for ML
5. Supervised Learning Models
6. Reinforcement Learning for Market Making
7. Deep Learning Approaches
8. Online Learning and Adaptation
9. A/B Testing Framework
10. Production Deployment

================================================================================
1. PARAMETER OPTIMIZATION OVERVIEW
================================================================================

KEY PARAMETERS TO OPTIMIZE:
---------------------------

1. Spread Parameters
   - Base spread: 0.01 - 0.10
   - Volatility multiplier: 1.0 - 20.0
   - Inventory sensitivity: 0.0 - 1.0

2. Size Parameters
   - Base size: 100 - 2000 shares
   - Min/max size: 50 - 5000 shares
   - Size scaling factor: 0.5 - 2.0

3. Risk Parameters
   - Max position: 1000 - 10000 shares
   - Position threshold: 0.5 - 0.9 × max
   - Delta threshold: 1000 - 5000 shares

4. Timing Parameters
   - Quote update interval: 1ms - 1000ms
   - Max quote age: 1s - 30s
   - Hedging frequency: 0.5 - 10× per day

5. Strategy Parameters
   - Aggressiveness: 0.0 - 1.0
   - Skew intensity: 0.0 - 1.0
   - Risk aversion: 1e-8 - 1e-6

OPTIMIZATION OBJECTIVE:
-----------------------

Multi-Objective:
1. Maximize Sharpe Ratio
2. Maximize Net P&L
3. Minimize Max Drawdown
4. Maintain Fill Rate in Target Range

Weighted Score:
Score = w1 × Sharpe + w2 × NetPnL - w3 × MaxDD - w4 × |FillRate - Target|²

Typical weights:
w1 = 0.4 (Sharpe most important)
w2 = 0.3 (Net P&L)
w3 = 0.2 (Drawdown control)
w4 = 0.1 (Fill rate consistency)

================================================================================
2. GRID SEARCH AND BAYESIAN OPTIMIZATION
================================================================================

C++ GRID SEARCH:
----------------

class ParameterOptimizer {
private:
    struct ParameterSet {
        double base_spread;
        double vol_multiplier;
        int base_size;
        double skew_intensity;
        int max_position;
    };

    struct PerformanceMetrics {
        double sharpe_ratio;
        double net_pnl;
        double max_drawdown;
        double fill_rate;
        double score;
    };

public:
    ParameterSet gridSearch(
        const std::vector<double>& spread_range,
        const std::vector<double>& vol_mult_range,
        const std::vector<int>& size_range,
        const std::vector<double>& skew_range,
        const std::vector<int>& position_range,
        const std::vector<MarketData>& historical_data) {

        ParameterSet best_params;
        double best_score = -std::numeric_limits<double>::infinity();

        // Iterate through all combinations
        for (double spread : spread_range) {
            for (double vol_mult : vol_mult_range) {
                for (int size : size_range) {
                    for (double skew : skew_range) {
                        for (int pos : position_range) {
                            ParameterSet params{spread, vol_mult, size, skew, pos};

                            // Backtest with these parameters
                            auto metrics = backtest(params, historical_data);

                            // Calculate weighted score
                            double score = calculateScore(metrics);

                            if (score > best_score) {
                                best_score = score;
                                best_params = params;
                            }
                        }
                    }
                }
            }
        }

        return best_params;
    }

private:
    PerformanceMetrics backtest(const ParameterSet& params,
                                const std::vector<MarketData>& data) {
        // Run market maker with given parameters
        // Calculate performance metrics
        PerformanceMetrics metrics;
        // ... implementation
        return metrics;
    }

    double calculateScore(const PerformanceMetrics& metrics) const {
        return 0.4 * metrics.sharpe_ratio +
               0.3 * (metrics.net_pnl / 10000.0) +
               -0.2 * (metrics.max_drawdown / 1000.0) +
               -0.1 * std::pow(metrics.fill_rate - 0.75, 2);
    }
};

BAYESIAN OPTIMIZATION:
----------------------

// Uses Gaussian Process to model objective function
// More efficient than grid search for high-dimensional spaces

class BayesianOptimizer {
private:
    struct Observation {
        std::vector<double> parameters;
        double score;
    };

    std::vector<Observation> observations_;

public:
    std::vector<double> optimize(
        const std::vector<std::pair<double, double>>& bounds,
        int n_iterations) {

        // Initial random samples
        for (int i = 0; i < 10; ++i) {
            auto params = sampleRandom(bounds);
            double score = evaluate(params);
            observations_.push_back({params, score});
        }

        // Bayesian optimization loop
        for (int iter = 0; iter < n_iterations; ++iter) {
            // Fit Gaussian Process
            auto gp = fitGP(observations_);

            // Acquisition function (Expected Improvement)
            auto next_params = maximizeAcquisition(gp, bounds);

            // Evaluate
            double score = evaluate(next_params);
            observations_.push_back({next_params, score});
        }

        // Return best parameters
        auto best = std::max_element(observations_.begin(), observations_.end(),
            [](const Observation& a, const Observation& b) {
                return a.score < b.score;
            });

        return best->parameters;
    }

private:
    std::vector<double> sampleRandom(
        const std::vector<std::pair<double, double>>& bounds) {
        std::vector<double> params;
        std::random_device rd;
        std::mt19937 gen(rd());

        for (const auto& [low, high] : bounds) {
            std::uniform_real_distribution<> dist(low, high);
            params.push_back(dist(gen));
        }

        return params;
    }

    double evaluate(const std::vector<double>& params) {
        // Run backtest and return score
        return 0.0;  // Stub
    }

    void* fitGP(const std::vector<Observation>& obs) {
        // Fit Gaussian Process (simplified - use library in production)
        return nullptr;  // Stub
    }

    std::vector<double> maximizeAcquisition(void* gp,
        const std::vector<std::pair<double, double>>& bounds) {
        // Maximize Expected Improvement
        return std::vector<double>();  // Stub
    }
};

================================================================================
3. WALK-FORWARD OPTIMIZATION
================================================================================

CONCEPT:
--------

Instead of optimizing on all historical data at once:
1. Split data into training and test windows
2. Optimize on training window
3. Test on out-of-sample test window
4. Roll forward and repeat

Example:
Data: 2023-01-01 to 2023-12-31 (12 months)
Window: 3 months train, 1 month test

Iteration 1: Train on Jan-Mar, Test on Apr
Iteration 2: Train on Feb-Apr, Test on May
Iteration 3: Train on Mar-May, Test on Jun
...

This prevents overfitting to historical data.

C++ WALK-FORWARD:
-----------------

class WalkForwardOptimizer {
private:
    int train_window_days_;
    int test_window_days_;

public:
    WalkForwardOptimizer(int train_days, int test_days)
        : train_window_days_(train_days), test_window_days_(test_days) {}

    struct WalkForwardResult {
        std::vector<ParameterSet> optimal_params_per_window;
        std::vector<PerformanceMetrics> test_performance;
        double avg_sharpe;
        double avg_pnl;
    };

    WalkForwardResult optimize(const std::vector<MarketData>& data) {
        WalkForwardResult result;

        int total_days = data.size() / (6.5 * 3600 * 1000);  // Assuming tick data
        int num_iterations = (total_days - train_window_days_) / test_window_days_;

        for (int i = 0; i < num_iterations; ++i) {
            int train_start = i * test_window_days_;
            int train_end = train_start + train_window_days_;
            int test_start = train_end;
            int test_end = test_start + test_window_days_;

            // Extract training data
            auto train_data = extractWindow(data, train_start, train_end);

            // Optimize on training data
            ParameterSet optimal = optimizeWindow(train_data);
            result.optimal_params_per_window.push_back(optimal);

            // Test on out-of-sample data
            auto test_data = extractWindow(data, test_start, test_end);
            auto test_metrics = backtest(optimal, test_data);
            result.test_performance.push_back(test_metrics);
        }

        // Calculate aggregate statistics
        double total_sharpe = 0.0, total_pnl = 0.0;
        for (const auto& metrics : result.test_performance) {
            total_sharpe += metrics.sharpe_ratio;
            total_pnl += metrics.net_pnl;
        }

        result.avg_sharpe = total_sharpe / result.test_performance.size();
        result.avg_pnl = total_pnl;

        return result;
    }

private:
    std::vector<MarketData> extractWindow(const std::vector<MarketData>& data,
                                         int start_day, int end_day) {
        // Extract data for window
        return std::vector<MarketData>();  // Stub
    }

    ParameterSet optimizeWindow(const std::vector<MarketData>& data) {
        // Run grid search or Bayesian optimization
        return ParameterSet{};  // Stub
    }

    PerformanceMetrics backtest(const ParameterSet& params,
                               const std::vector<MarketData>& data) {
        return PerformanceMetrics{};  // Stub
    }
};

================================================================================
4. FEATURE ENGINEERING FOR ML
================================================================================

FEATURES FOR MARKET MAKING:
----------------------------

1. Order Book Features (20 features)
   - Bid/ask prices and sizes (10 levels)
   - Order imbalance (multiple levels)
   - Depth at various price distances
   - Microprice
   - Weighted mid price

2. Trade Features (15 features)
   - Recent trade intensity
   - Buy/sell ratio (1min, 5min, 30min)
   - Average trade size
   - Trade size variance
   - Volume profile

3. Volatility Features (10 features)
   - Realized volatility (1min, 5min, 30min, 1hr)
   - Parkinson volatility
   - Garman-Klass volatility
   - Volatility ratio (recent / historical)
   - Range (high - low)

4. Microstructure Features (15 features)
   - Effective spread
   - Realized spread
   - Price impact
   - Roll measure
   - Quote update frequency
   - Cancellation rate
   - Time since last trade

5. Position Features (5 features)
   - Current position
   - Position as % of limit
   - Time in position
   - Unrealized P&L
   - Position momentum

6. Market Regime Features (10 features)
   - Time of day
   - Day of week
   - Minutes to market close
   - Volatility regime
   - Volume regime
   - Spread regime

7. Historical Performance (10 features)
   - Recent fill rate
   - Recent spread capture
   - Recent adverse selection ratio
   - Recent P&L
   - Recent Sharpe ratio

Total: ~95 features

C++ FEATURE EXTRACTOR:
----------------------

class FeatureExtractor {
private:
    static constexpr int NUM_FEATURES = 95;

public:
    std::array<double, NUM_FEATURES> extractFeatures(
        const OrderBook& book,
        const PositionTracker& position,
        const std::vector<Trade>& recent_trades,
        const PerformanceMetrics& recent_performance,
        uint64_t current_time) const {

        std::array<double, NUM_FEATURES> features;
        int idx = 0;

        // Order book features (20)
        for (int i = 0; i < 5; ++i) {
            features[idx++] = book.bids[i].price;
            features[idx++] = book.bids[i].size;
            features[idx++] = book.asks[i].price;
            features[idx++] = book.asks[i].size;
        }

        // Trade features (15)
        features[idx++] = calculateTradeIntensity(recent_trades, 60);  // 1 min
        features[idx++] = calculateTradeIntensity(recent_trades, 300); // 5 min
        features[idx++] = calculateBuySellRatio(recent_trades, 60);
        // ... more trade features

        // Volatility features (10)
        features[idx++] = calculateRealizedVolatility(recent_trades, 60);
        features[idx++] = calculateRealizedVolatility(recent_trades, 300);
        // ... more volatility features

        // Microstructure features (15)
        features[idx++] = book.getBestAsk() - book.getBestBid();  // Spread
        features[idx++] = calculateEffectiveSpread(recent_trades);
        // ... more microstructure features

        // Position features (5)
        features[idx++] = static_cast<double>(position.getPosition());
        features[idx++] = position.getPosition() / 10000.0;  // Normalized
        features[idx++] = position.getUnrealizedPnL();
        // ... more position features

        // Market regime features (10)
        auto tm = getTimeComponents(current_time);
        features[idx++] = tm.hour / 24.0;  // Normalized hour
        features[idx++] = tm.minute / 60.0;
        features[idx++] = tm.day_of_week / 7.0;
        // ... more regime features

        // Historical performance (10)
        features[idx++] = recent_performance.fill_rate;
        features[idx++] = recent_performance.spread_capture;
        features[idx++] = recent_performance.sharpe_ratio;
        // ... more performance features

        // Normalize features
        normalizeFeatures(features);

        return features;
    }

private:
    double calculateTradeIntensity(const std::vector<Trade>& trades,
                                   int window_seconds) const {
        // Implementation
        return 0.0;
    }

    double calculateBuySellRatio(const std::vector<Trade>& trades,
                                int window_seconds) const {
        // Implementation
        return 0.0;
    }

    double calculateRealizedVolatility(const std::vector<Trade>& trades,
                                      int window_seconds) const {
        // Implementation
        return 0.0;
    }

    double calculateEffectiveSpread(const std::vector<Trade>& trades) const {
        // Implementation
        return 0.0;
    }

    struct TimeComponents {
        int hour, minute, day_of_week;
    };

    TimeComponents getTimeComponents(uint64_t timestamp) const {
        // Extract time components
        return {9, 30, 1};  // Stub
    }

    void normalizeFeatures(std::array<double, NUM_FEATURES>& features) const {
        // Z-score normalization or min-max scaling
        // Use pre-computed statistics from training data
    }
};

================================================================================
5. REINFORCEMENT LEARNING FOR MARKET MAKING
================================================================================

FORMULATION:
------------

State (s): Feature vector from FeatureExtractor
Action (a): {spread_adjustment, size_adjustment, skew_adjustment}
Reward (r): P&L - α × |position| - β × risk

Q-Learning Update:
Q(s,a) ← Q(s,a) + α[r + γ max Q(s',a') - Q(s,a)]

Deep Q-Network (DQN):
Q(s,a) = Neural_Network(s)

Actor-Critic:
Policy: π(a|s) = Actor_Network(s)
Value: V(s) = Critic_Network(s)

C++ RL AGENT (INFERENCE):
--------------------------

class RLMarketMaker {
private:
    struct NeuralNetwork {
        // Simplified neural network for inference
        std::vector<std::vector<double>> weights_layer1;
        std::vector<std::vector<double>> weights_layer2;
        std::vector<double> biases_layer1;
        std::vector<double> biases_layer2;
    };

    NeuralNetwork policy_net_;
    FeatureExtractor feature_extractor_;

public:
    struct Action {
        double spread_multiplier;    // 0.5 - 2.0
        double size_multiplier;      // 0.5 - 2.0
        double skew_adjustment;      // -0.05 to +0.05
    };

    Action selectAction(const MarketState& state) {
        // Extract features
        auto features = feature_extractor_.extractFeatures(
            state.order_book, state.position, state.recent_trades,
            state.performance, state.timestamp
        );

        // Forward pass through network
        auto action_logits = forwardPass(features);

        // Convert to action
        Action action;
        action.spread_multiplier = 0.5 + 1.5 * sigmoid(action_logits[0]);
        action.size_multiplier = 0.5 + 1.5 * sigmoid(action_logits[1]);
        action.skew_adjustment = 0.1 * std::tanh(action_logits[2]);

        return action;
    }

    void loadModel(const std::string& model_path) {
        // Load trained model weights from file
        // Format: binary or JSON
    }

private:
    std::vector<double> forwardPass(const std::array<double, 95>& input) {
        // Layer 1: input (95) -> hidden (64)
        std::vector<double> hidden1(64);
        for (size_t i = 0; i < 64; ++i) {
            double sum = biases_layer1[i];
            for (size_t j = 0; j < 95; ++j) {
                sum += input[j] * policy_net_.weights_layer1[i][j];
            }
            hidden1[i] = relu(sum);
        }

        // Layer 2: hidden (64) -> output (3)
        std::vector<double> output(3);
        for (size_t i = 0; i < 3; ++i) {
            double sum = policy_net_.biases_layer2[i];
            for (size_t j = 0; j < 64; ++j) {
                sum += hidden1[j] * policy_net_.weights_layer2[i][j];
            }
            output[i] = sum;  // No activation on output
        }

        return output;
    }

    static double relu(double x) { return std::max(0.0, x); }
    static double sigmoid(double x) { return 1.0 / (1.0 + std::exp(-x)); }
};

TRAINING (PYTHON):
------------------

```python
import torch
import torch.nn as nn
import torch.optim as optim

class ActorCriticNetwork(nn.Module):
    def __init__(self, state_dim=95, action_dim=3):
        super().__init__()
        self.shared = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU()
        )
        self.actor = nn.Linear(64, action_dim)
        self.critic = nn.Linear(64, 1)

    def forward(self, state):
        shared = self.shared(state)
        action_logits = self.actor(shared)
        value = self.critic(shared)
        return action_logits, value

class PPOTrainer:
    def __init__(self):
        self.policy = ActorCriticNetwork()
        self.optimizer = optim.Adam(self.policy.parameters(), lr=3e-4)

    def train(self, states, actions, rewards, next_states, dones):
        # PPO training loop
        action_logits, values = self.policy(states)

        # Calculate advantages
        next_values = self.policy(next_states)[1]
        td_targets = rewards + 0.99 * next_values * (1 - dones)
        advantages = td_targets - values

        # Actor loss (PPO clip)
        ratio = torch.exp(action_logits - old_log_probs)
        surr1 = ratio * advantages
        surr2 = torch.clamp(ratio, 0.8, 1.2) * advantages
        actor_loss = -torch.min(surr1, surr2).mean()

        # Critic loss
        critic_loss = ((values - td_targets) ** 2).mean()

        # Total loss
        loss = actor_loss + 0.5 * critic_loss

        # Optimize
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()
```

================================================================================
6. A/B TESTING FRAMEWORK
================================================================================

PRODUCTION DEPLOYMENT:
----------------------

Run multiple strategies in parallel with traffic splitting:

Strategy A (Baseline): 50% of capital
Strategy B (New): 30% of capital
Strategy C (Experimental): 20% of capital

Monitor metrics:
- Sharpe ratio
- Net P&L
- Max drawdown
- Fill rate
- Adverse selection

Statistical significance testing:
- T-test for mean P&L difference
- Mann-Whitney U test for distributions
- Bootstrap confidence intervals

Graduate winning strategy to higher allocation

C++ A/B TESTING:
----------------

class ABTestingFramework {
private:
    struct StrategyPerformance {
        std::string strategy_name;
        double capital_allocation;
        double total_pnl;
        double sharpe_ratio;
        int num_trades;
        std::vector<double> daily_pnl;
    };

    std::vector<StrategyPerformance> strategies_;

public:
    void addStrategy(const std::string& name, double allocation) {
        strategies_.push_back({name, allocation, 0.0, 0.0, 0, {}});
    }

    void recordPnL(const std::string& strategy, double pnl) {
        for (auto& strat : strategies_) {
            if (strat.strategy_name == strategy) {
                strat.total_pnl += pnl;
                strat.daily_pnl.push_back(pnl);
                strat.num_trades++;
                strat.sharpe_ratio = calculateSharpe(strat.daily_pnl);
            }
        }
    }

    std::string selectWinningStrategy() const {
        // Simple: highest Sharpe ratio
        auto best = std::max_element(strategies_.begin(), strategies_.end(),
            [](const StrategyPerformance& a, const StrategyPerformance& b) {
                return a.sharpe_ratio < b.sharpe_ratio;
            });

        return best->strategy_name;
    }

    bool isStatisticallySignificant(const std::string& strategy_a,
                                   const std::string& strategy_b,
                                   double alpha = 0.05) const {
        // T-test for difference in means
        // Simplified - use proper library in production
        return false;  // Stub
    }

private:
    double calculateSharpe(const std::vector<double>& returns) const {
        if (returns.size() < 2) return 0.0;
        double mean = std::accumulate(returns.begin(), returns.end(), 0.0) / returns.size();
        double sq_sum = 0.0;
        for (double r : returns) sq_sum += (r - mean) * (r - mean);
        double std_dev = std::sqrt(sq_sum / (returns.size() - 1));
        return (std_dev > 0) ? (mean / std_dev) : 0.0;
    }
};

================================================================================
OPTIMIZATION BEST PRACTICES
================================================================================

1. Start Simple
   - Baseline with fixed parameters
   - Gradually add complexity
   - Measure improvement at each step

2. Avoid Overfitting
   - Use walk-forward optimization
   - Maintain out-of-sample test set
   - Monitor performance degradation

3. Robust Parameter Ranges
   - Test sensitivity to parameters
   - Parameters should work across market regimes
   - Avoid parameters that only work in specific conditions

4. Regular Reoptimization
   - Markets change over time
   - Reoptimize monthly or quarterly
   - Monitor for strategy decay

5. Ensemble Methods
   - Combine multiple models/strategies
   - Reduces overfitting risk
   - More robust to market changes

6. Production Monitoring
   - A/B test new parameters
   - Gradual rollout (10% → 50% → 100%)
   - Quick rollback capability

Performance Targets After Optimization:
- Sharpe ratio improvement: +20-30%
- Fill rate optimization: ±5% toward target
- Adverse selection reduction: -15-25%
- Overall P&L increase: +30-50%

================================================================================
END OF OPTIMIZATION
================================================================================
END OF MARKET MAKING DOCUMENTATION SERIES (FILES 00-12)
================================================================================
