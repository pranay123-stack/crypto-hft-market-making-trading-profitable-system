================================================================================
ADVANCED MEMORY PROFILING FOR HFT C++
================================================================================

THEORY:
-------
Memory profiling in HFT focuses on:
1. Allocation latency (each malloc/new adds microseconds)
2. Memory fragmentation (causes non-deterministic performance)
3. Memory bandwidth (cache-to-RAM transfer rates)
4. Memory footprint (working set size vs. cache sizes)
5. NUMA effects (memory locality in multi-socket systems)

Critical insight: In HFT, memory allocation is often the enemy.
Pre-allocation and memory pools are standard practice.

TOOLS OVERVIEW:
---------------
1. Heaptrack - Heap memory profiler (superior to Massif)
2. Memcheck (Valgrind) - Memory error detection
3. AddressSanitizer (ASan) - Fast memory error detection
4. tcmalloc/jemalloc - Alternative allocators with profiling
5. perf mem - Hardware memory profiling
6. /proc/<pid>/smaps - Process memory maps
7. Intel VTune - Commercial profiler with memory analysis

================================================================================
1. HEAPTRACK - MODERN HEAP PROFILER
================================================================================

THEORY:
Heaptrack is faster than Valgrind Massif with more detailed information.
Tracks:
- Allocations and deallocations
- Memory leaks
- Peak memory usage
- Allocation hotspots
- Temporary allocations

INSTALLATION:
sudo apt-get install heaptrack heaptrack-gui

PROCESS:
--------
# Record heap usage
heaptrack ./your_hft_app [args]

# Analyze with GUI
heaptrack_gui heaptrack.your_hft_app.12345.gz

# Or command line analysis
heaptrack_print heaptrack.your_hft_app.12345.gz

HFT C++ EXAMPLE:
----------------

// memory_pool_vs_heap.cpp
#include <iostream>
#include <vector>
#include <memory>
#include <chrono>

struct Order {
    uint64_t id;
    double price;
    uint64_t quantity;
    char padding[64];  // Ensure cache line size
};

// Version 1: Heap allocation (BAD for HFT)
class HeapOrderManager {
    std::vector<std::unique_ptr<Order>> orders;

public:
    void processOrders(size_t count) {
        for (size_t i = 0; i < count; ++i) {
            auto order = std::make_unique<Order>();  // Heap allocation!
            order->id = i;
            order->price = 100.0 + i * 0.01;
            order->quantity = 100;
            orders.push_back(std::move(order));
        }
    }

    void clearOrders() {
        orders.clear();  // Deallocations
    }
};

// Version 2: Memory pool (GOOD for HFT)
class PoolOrderManager {
    std::vector<Order> pool;  // Pre-allocated
    size_t next_index = 0;

public:
    PoolOrderManager(size_t pool_size) {
        pool.reserve(pool_size);
        pool.resize(pool_size);
    }

    Order* getOrder() {
        if (next_index < pool.size()) {
            return &pool[next_index++];
        }
        return nullptr;  // Pool exhausted
    }

    void processOrders(size_t count) {
        for (size_t i = 0; i < count; ++i) {
            Order* order = getOrder();
            if (order) {
                order->id = i;
                order->price = 100.0 + i * 0.01;
                order->quantity = 100;
            }
        }
    }

    void clearOrders() {
        next_index = 0;  // Reset without deallocation
    }
};

// Benchmark
void benchmarkHeap(size_t iterations, size_t orders_per_iteration) {
    HeapOrderManager manager;

    auto start = std::chrono::high_resolution_clock::now();

    for (size_t i = 0; i < iterations; ++i) {
        manager.processOrders(orders_per_iteration);
        manager.clearOrders();
    }

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);

    std::cout << "Heap allocation: " << duration.count() << " us\n";
}

void benchmarkPool(size_t iterations, size_t orders_per_iteration) {
    PoolOrderManager manager(orders_per_iteration);

    auto start = std::chrono::high_resolution_clock::now();

    for (size_t i = 0; i < iterations; ++i) {
        manager.processOrders(orders_per_iteration);
        manager.clearOrders();
    }

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);

    std::cout << "Pool allocation: " << duration.count() << " us\n";
}

int main() {
    const size_t iterations = 1000;
    const size_t orders = 1000;

    std::cout << "Running benchmarks...\n";

    benchmarkHeap(iterations, orders);
    benchmarkPool(iterations, orders);

    return 0;
}

WORKFLOW:
---------
# Compile
g++ -O2 -g -std=c++17 memory_pool_vs_heap.cpp -o memory_test

# Profile with heaptrack
heaptrack ./memory_test

# Analyze with GUI (shows flamegraph of allocations)
heaptrack_gui heaptrack.memory_test.*.gz

# Or print summary
heaptrack_print heaptrack.memory_test.*.gz | less

KEY METRICS TO OBSERVE:
- Peak memory usage
- Total allocations count
- Temporary allocations (allocated and freed quickly)
- Allocation flamegraph (which code paths allocate most)

EXPECTED RESULTS:
Heap version: Thousands of allocations, higher peak memory, slower
Pool version: Few allocations (during setup), lower peak, much faster

================================================================================
2. ADDRESS SANITIZER (ASan) - FAST MEMORY ERROR DETECTION
================================================================================

THEORY:
ASan is a compiler-based memory error detector (LLVM/GCC).
Much faster than Valgrind (2-3x overhead vs 20x).

Detects:
- Buffer overflows (stack, heap, global)
- Use-after-free
- Use-after-return
- Double-free
- Memory leaks

PROCESS:
--------
# Compile with ASan
g++ -fsanitize=address -fno-omit-frame-pointer -g -O1 \
    your_program.cpp -o your_program

# Run (ASan reports errors immediately)
./your_program

# Set environment for more control
export ASAN_OPTIONS=detect_leaks=1:halt_on_error=0:log_path=asan.log
./your_program

HFT C++ EXAMPLE (Buffer Overflow Detection):
---------------------------------------------

// asan_example.cpp
#include <iostream>
#include <cstring>

struct MarketData {
    char symbol[8];
    double price;
    uint64_t volume;
};

void processSymbol(const char* input) {
    MarketData data;

    // BUG: Buffer overflow if input > 7 chars (no null terminator space)
    strcpy(data.symbol, input);  // ASan will catch this!

    std::cout << "Symbol: " << data.symbol << std::endl;
}

void useAfterFree() {
    int* prices = new int[100];

    delete[] prices;

    // BUG: Use-after-free
    prices[0] = 100;  // ASan will catch this!
}

int main() {
    // This will cause buffer overflow
    processSymbol("VERYLONGSYMBOL");

    useAfterFree();

    return 0;
}

WORKFLOW:
---------
# Compile with ASan
g++ -fsanitize=address -fno-omit-frame-pointer -g -O1 asan_example.cpp -o asan_test

# Run (ASan will report errors with stack traces)
./asan_test

INTERPRETING ASan OUTPUT:
-------------------------
=================================================================
==12345==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60200000eff8
READ of size 1 at 0x60200000eff8 thread T0
    #0 0x... in strcpy
    #1 0x... in processSymbol(char const*) asan_example.cpp:14
    #2 0x... in main asan_example.cpp:29

0x60200000eff8 is located 0 bytes to the right of 8-byte region
allocated by thread T0 here:
    #0 0x... in operator new[](unsigned long)
    #1 0x... in processSymbol(char const*) asan_example.cpp:11

Action: Fix buffer overflow in processSymbol()

ASan OPTIONS:
-------------
ASAN_OPTIONS environment variable:

detect_leaks=1              : Enable leak detection
halt_on_error=0             : Continue after first error
log_path=asan.log           : Write to file instead of stderr
verbosity=1                 : More detailed output
symbolize=1                 : Symbolize stack traces
detect_stack_use_after_return=1  : Detect stack UAF (slower)

Example:
export ASAN_OPTIONS=detect_leaks=1:halt_on_error=0:log_path=asan.log
./your_program

================================================================================
3. PERF MEM - HARDWARE MEMORY PROFILING
================================================================================

THEORY:
Uses CPU performance counters to profile memory access patterns:
- Load/store operations
- Cache hits/misses at all levels
- TLB misses
- Memory bandwidth usage

PROCESS:
--------
# Record memory accesses
sudo perf mem record ./your_hft_app

# Report memory access statistics
sudo perf mem report

# Specific events
sudo perf stat -e mem_load_retired.l1_miss,mem_load_retired.l3_miss ./your_hft_app

HFT C++ EXAMPLE (Cache-Friendly vs Unfriendly):
------------------------------------------------

// cache_friendly.cpp
#include <iostream>
#include <vector>
#include <chrono>

const size_t SIZE = 1024 * 1024;  // 1M elements

// Cache-unfriendly: Random access
void randomAccess(std::vector<int>& data) {
    uint64_t sum = 0;
    for (size_t i = 0; i < SIZE; ++i) {
        size_t index = (i * 7919) % SIZE;  // Pseudo-random
        sum += data[index];
    }
    std::cout << "Sum: " << sum << std::endl;
}

// Cache-friendly: Sequential access
void sequentialAccess(std::vector<int>& data) {
    uint64_t sum = 0;
    for (size_t i = 0; i < SIZE; ++i) {
        sum += data[i];  // Sequential - cache friendly
    }
    std::cout << "Sum: " << sum << std::endl;
}

int main() {
    std::vector<int> data(SIZE, 1);

    std::cout << "Random access:\n";
    auto start = std::chrono::high_resolution_clock::now();
    randomAccess(data);
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << "Time: "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count()
              << " ms\n\n";

    std::cout << "Sequential access:\n";
    start = std::chrono::high_resolution_clock::now();
    sequentialAccess(data);
    end = std::chrono::high_resolution_clock::now();
    std::cout << "Time: "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count()
              << " ms\n";

    return 0;
}

WORKFLOW:
---------
# Compile
g++ -O2 -g -std=c++17 cache_friendly.cpp -o cache_test

# Profile memory accesses
sudo perf mem record -a ./cache_test

# View report
sudo perf mem report

# Or detailed statistics
sudo perf stat -e cache-references,cache-misses,L1-dcache-loads,L1-dcache-load-misses \
    ./cache_test

EXPECTED RESULTS:
Random access: High cache miss rate (>50%)
Sequential access: Low cache miss rate (<5%)

================================================================================
4. MEMORY BANDWIDTH PROFILING
================================================================================

THEORY:
Memory bandwidth is critical in HFT when processing large market data feeds.
Tools to measure:
- Intel MLC (Memory Latency Checker)
- perf with memory bandwidth events
- likwid-bench

USING PERF FOR BANDWIDTH:
-------------------------
# Monitor memory bandwidth
sudo perf stat -e cpu/event=0xb7,umask=0x1,name=offcore_response_demand_data_rd/ \
    ./your_hft_app

# Or use topdown methodology
sudo perf stat -M memory_bandwidth ./your_hft_app

================================================================================
5. NUMA PROFILING
================================================================================

THEORY:
On multi-socket systems, memory access latency depends on which NUMA node
the memory is allocated on. Critical for HFT systems with multiple CPUs.

TOOLS:
- numactl: Control NUMA policy
- numastat: NUMA statistics
- perf c2c: Cache-to-cache transfer profiling

PROCESS:
--------
# Check NUMA topology
numactl --hardware

# Run on specific NUMA node
numactl --cpunodebind=0 --membind=0 ./your_hft_app

# Monitor NUMA statistics
numastat -p $(pidof your_hft_app)

# Profile cache-to-cache transfers (false sharing detection)
sudo perf c2c record ./your_hft_app
sudo perf c2c report

HFT C++ EXAMPLE (NUMA-aware allocation):
-----------------------------------------

// numa_example.cpp
#include <iostream>
#include <vector>
#include <thread>
#include <numa.h>

void processingThread(int node_id, std::vector<double>& data) {
    // Bind thread to specific NUMA node
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(node_id, &cpuset);
    pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);

    // Process data (should be local to this NUMA node)
    double sum = 0;
    for (auto val : data) {
        sum += val;
    }

    std::cout << "Node " << node_id << " sum: " << sum << std::endl;
}

int main() {
    if (numa_available() < 0) {
        std::cerr << "NUMA not available\n";
        return 1;
    }

    const size_t data_size = 1000000;

    // Allocate on NUMA node 0
    numa_set_preferred(0);
    std::vector<double> data0(data_size, 1.0);

    // Allocate on NUMA node 1 (if available)
    if (numa_max_node() > 0) {
        numa_set_preferred(1);
    }
    std::vector<double> data1(data_size, 1.0);

    // Process on respective nodes
    std::thread t0(processingThread, 0, std::ref(data0));
    std::thread t1(processingThread, 1, std::ref(data1));

    t0.join();
    t1.join();

    return 0;
}

COMPILATION:
g++ -O2 -g -std=c++17 numa_example.cpp -o numa_test -lnuma -lpthread

================================================================================
OPTIMIZATION STRATEGIES FOR HFT
================================================================================

1. ELIMINATE ALLOCATIONS IN HOT PATH
   - Pre-allocate all memory during initialization
   - Use memory pools for objects with known lifetime
   - Use stack allocation where possible

2. CACHE-LINE ALIGNMENT
   - Align frequently accessed structures to 64-byte boundaries
   - Avoid false sharing in multi-threaded code
   - Pack related data together

   Example:
   struct alignas(64) OrderBookLevel {
       double price;
       uint64_t quantity;
       // Padding to 64 bytes
       char padding[64 - sizeof(double) - sizeof(uint64_t)];
   };

3. MEMORY POOLING PATTERNS
   - Fixed-size pools for uniform objects
   - Slab allocator for kernel-style allocation
   - Ring buffers for lock-free queues

4. NUMA OPTIMIZATION
   - Pin threads to cores
   - Allocate memory on local NUMA node
   - Minimize cross-node traffic

5. HUGE PAGES
   - Reduce TLB misses
   - Improve memory access latency

   Enable:
   sudo sysctl -w vm.nr_hugepages=1024
   Use mmap with MAP_HUGETLB or libhugetlbfs

BEST PRACTICES:
---------------
1. Profile regularly during development
2. Test with production-like data volumes
3. Measure both throughput and latency
4. Watch for memory fragmentation over time
5. Use ASan in development, disable in production
6. Monitor memory metrics in production (RSS, page faults)
7. Combine multiple tools for complete picture
