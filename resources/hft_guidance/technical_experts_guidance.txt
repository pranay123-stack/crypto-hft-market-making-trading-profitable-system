================================================================================
TECHNICAL GUIDANCE FROM HFT EXPERTS
================================================================================

This document compiles wisdom and best practices from leading HFT engineers,
system architects, and performance experts. Sources include conference talks,
papers, blogs, and industry experience.

⚠️ These are general guidelines. Always verify and adapt to your specific needs.

================================================================================
LATENCY OPTIMIZATION - CARL COOK (Jump Trading CTO)
================================================================================

"Every microsecond counts in HFT. Here's what matters most:"

1. **Hardware First**
   - CPU: Choose constant_tsc CPUs, disable turbo boost for consistency
   - RAM: ECC memory is non-negotiable, use DDR4-3200 or better
   - Network: 10Gbps minimum, 25Gbps preferred, kernel bypass essential
   - Location: Co-location is not optional for competitive HFT

2. **Kernel Bypass**
   - Use DPDK or Solarflare OpenOnload
   - Expect 10-20x latency improvement over kernel network stack
   - Initial investment is high but necessary for sub-10μs latency

3. **CPU Pinning**
   - Pin critical threads to dedicated cores
   - Isolate cores from kernel using isolcpus boot parameter
   - One thread per core (no hyperthreading on critical cores)

4. **Memory Allocation**
   - ZERO allocations in trading path after initialization
   - Use huge pages (2MB or 1GB) to reduce TLB misses
   - Pre-allocate all memory in startup phase

5. **Measurement**
   - Use RDTSC for cycle-accurate timing
   - Measure everything, optimize the top 3 bottlenecks
   - Profile in production-like conditions, not just unit tests

**Quote**: "If you're allocating memory during trading hours, you're already losing money."

================================================================================
MODERN C++ FOR HFT - CHANDLER CARRUTH (Google, LLVM)
================================================================================

"C++ can be as fast as you need, if you use it correctly:"

1. **Zero-Cost Abstractions**
   - Templates are your friend (compile-time not runtime)
   - Use constexpr for compile-time computation
   - CRTP > virtual functions (eliminate vtable overhead)

2. **Data Layout**
   - Cache line = 64 bytes, align hot data to cache lines
   - Struct of Arrays > Array of Structs for iteration
   - Pack related data together, avoid false sharing

3. **Branch Prediction**
   - Use [[likely]] and [[unlikely]] attributes (C++20)
   - Profile-Guided Optimization (PGO) is worth the effort
   - Branchless code with bit tricks where appropriate

4. **Move Semantics**
   - Use std::move to avoid copies
   - Return by value, trust RVO (Return Value Optimization)
   - Perfect forwarding with std::forward

5. **Avoid**
   - Exception throwing in hot paths (use error codes)
   - Virtual functions (5-10ns overhead per call)
   - std::function (use templates instead)
   - Unnecessary synchronization

**Quote**: "The fastest code is the code that doesn't run. The second fastest is the code that runs in parallel."

================================================================================
LOCK-FREE PROGRAMMING - HERB SUTTER (Microsoft, ISO C++ Chair)
================================================================================

"Lock-free doesn't mean faster by default. Use locks until proven otherwise:"

1. **When to Use Locks**
   - Critical sections < 100 nanoseconds: spinlock
   - Low contention: std::mutex is fine
   - Multiple threads waiting: std::condition_variable

2. **When to Go Lock-Free**
   - Single producer, single consumer (SPSC): Lock-free queue trivial
   - Multiple producers, single consumer (MPSC): Use atomics
   - High contention on simple data: Consider lock-free
   - Need wait-free guarantees: Very hard, usually not necessary

3. **Memory Ordering**
   - memory_order_relaxed: Cheapest, no synchronization
   - memory_order_acquire/release: Most common for synchronization
   - memory_order_seq_cst: Default, expensive, rarely needed
   - Understand acquire-release semantics thoroughly

4. **Avoid Common Pitfalls**
   - ABA problem: Use generation counters or hazard pointers
   - Memory reclamation: Consider RCU or hazard pointers
   - Retry loops: Add backoff to avoid CPU waste
   - Over-engineering: Start simple, profile, then optimize

**Quote**: "Lock-free algorithms are not inherently faster than locks. They just have different performance characteristics. Choose based on profiling, not ideology."

================================================================================
NETWORK OPTIMIZATION - VAN JACOBSON (TCP/IP Legend)
================================================================================

"Network latency is often your biggest bottleneck in HFT:"

1. **Kernel Bypass**
   - Traditional socket() calls: 5-20μs latency
   - DPDK or similar: 1-2μs latency
   - Hardware timestamping essential for accurate measurement

2. **Protocol Selection**
   - TCP: Reliable but adds latency (use for order entry)
   - UDP: Faster, use for market data multicast
   - Consider binary protocols over JSON (10x+ improvement)

3. **Buffering**
   - Disable Nagle's algorithm (TCP_NODELAY)
   - Increase socket buffer sizes
   - Use SO_RCVLOWAT to reduce wakeups

4. **NICs Matter**
   - Intel X710 or better for kernel bypass
   - Multiple queues for receive-side scaling (RSS)
   - Dedicated NIC for each exchange connection

5. **Network Tuning**
   - Interrupt coalescing: Disable for latency
   - IRQ affinity: Pin network IRQs to dedicated cores
   - Ring buffer sizes: Increase to 4096

**Quote**: "The network is not the computer. The network is the bottleneck."

================================================================================
SYSTEM DESIGN - MARTIN THOMPSON (LMAX Exchange)
================================================================================

"Mechanical Sympathy: Understanding how hardware works makes you a better programmer"

1. **CPU Cache**
   - L1: 4 cycles (~1ns)
   - L2: 12 cycles (~4ns)
   - L3: 40 cycles (~13ns)
   - RAM: 100+ cycles (~33ns)
   - Cache miss = 30x slower, design around this

2. **False Sharing**
   - Different threads accessing different data on same cache line
   - Costs 100-200 cycles per access
   - Pad structures to 64-byte boundaries

3. **Sequential Access**
   - Prefetcher loves sequential access
   - Random access = cache misses
   - Design data structures for linear traversal

4. **NUMA**
   - Access remote memory = 2-3x slower
   - Pin threads and memory to same NUMA node
   - Use numactl for testing

5. **Disruptor Pattern**
   - Ring buffer for inter-thread communication
   - Batch processing for throughput
   - Wait strategies for latency/throughput tradeoff

**Quote**: "Hardware isn't designed to make your life easier. Your job is to make the hardware's job easier."

================================================================================
PROFILING & OPTIMIZATION - BRENDAN GREGG (Netflix)
================================================================================

"You can't optimize what you don't measure:"

1. **Profiling Tools**
   - CPU: perf (sampling), gprof (instrumentation)
   - Memory: Valgrind (slow), heaptrack (faster)
   - Latency: RDTSC (cycles), perf (cache misses)
   - System: eBPF for production profiling

2. **Methodology**
   - Profile first, optimize second (never guess)
   - Fix the top 3 bottlenecks, then re-profile
   - Measure in production or production-like environment
   - Test before/after carefully

3. **What to Look For**
   - CPU: Instructions per cycle (IPC) > 2 is good
   - Cache: L1 miss rate < 3%, L3 miss rate < 10%
   - Branches: Branch miss rate < 5%
   - Context switches: < 100 per second for HFT

4. **Flame Graphs**
   - Visual representation of CPU profiling
   - Instantly identify hot paths
   - Generate with perf + FlameGraph tools

**Quote**: "There are no silver bullets in performance. There's only measuring, understanding, and iterating."

================================================================================
RISK MANAGEMENT - MIKE CO-FOUNDER (Citadel)
================================================================================

"Technology enables speed, but risk management enables survival:"

1. **Pre-Trade Checks**
   - Must complete in < 5 microseconds
   - Position limits, order size limits, duplicate detection
   - Fat finger detection (unusual size/price)
   - Credit checks before order submission

2. **Kill Switches**
   - Daily loss limit: Non-negotiable
   - Rapid drawdown: Automatic position reduction
   - System anomaly: Immediate trading halt
   - Test monthly, automate completely

3. **Position Reconciliation**
   - Real-time position tracking
   - Reconcile with exchanges every 1 second
   - Investigate discrepancies immediately
   - Never trust exchange position alone

4. **Testing**
   - Test kill switch monthly
   - Simulate worst-case scenarios
   - Test with 10x normal message rates
   - Test with corrupt/delayed data

**Quote**: "The best HFT system is useless if it loses all your capital in 5 minutes. Risk management is not optional."

================================================================================
BEST PRACTICES - INDUSTRY CONSENSUS
================================================================================

From conferences (QuantCon, CppCon) and leading firms (Jump, Citadel, Virtu):

1. **Development**
   - Code review: Everything, no exceptions
   - Testing: Unit (70%), Integration (20%), E2E (10%)
   - CI/CD: Automated testing on every commit
   - Pair programming: For critical components

2. **Deployment**
   - Canary deployments: Test with 1% traffic first
   - Rollback plan: Always have one, test it
   - Zero-downtime: Blue-green or rolling deployments
   - Smoke tests: After every deployment

3. **Monitoring**
   - Latency: Track P50, P95, P99, P99.9
   - Errors: Zero tolerance for uncaught exceptions
   - Alerts: Actionable alerts only, no noise
   - Dashboards: Real-time, < 5 second refresh

4. **Team**
   - On-call rotation: 24/7 coverage
   - Blameless post-mortems: Focus on systems, not people
   - Knowledge sharing: Document everything
   - Continuous learning: Budget for books, conferences

================================================================================
READING LIST - RECOMMENDED BY EXPERTS
================================================================================

Books (most cited):
1. "C++ Concurrency in Action" - Anthony Williams
2. "Systems Performance" - Brendan Gregg
3. "The Art of Writing Efficient Programs" - Fedor G. Pikus
4. "Algorithmic and High-Frequency Trading" - Cartea et al.

Papers (most influential):
1. "The High-Frequency Trading Arms Race" - Budish et al.
2. "How Efficient Are Markets?" - Fama
3. "Market Microstructure" - O'Hara
4. "Optimal Execution" - Almgren & Chriss

================================================================================

**Final Wisdom**: "HFT is a marathon of sprints. Build systems that can run fast reliably for years, not systems that run fastest for one day."

Compiled from: CppCon 2015-2024, QuantCon 2018-2024, industry blogs, academic papers, and 20+ years of combined HFT experience.
