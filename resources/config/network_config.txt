================================================================================
HFT NETWORK CONFIGURATION - NETWORK AND FIREWALL SETTINGS
================================================================================
Version: 1.0.0
Last Updated: 2025-11-25
Description: Network optimization and security configuration
================================================================================

TABLE OF CONTENTS
-----------------
1. Network Architecture
2. TCP/IP Optimization
3. Kernel Bypass Technologies
4. NIC Configuration
5. Multicast Configuration
6. Firewall Rules
7. Network Security
8. VPN and Connectivity
9. Latency Optimization
10. C++ Network Implementation

================================================================================
1. NETWORK ARCHITECTURE
================================================================================

NETWORK TOPOLOGY:
-----------------
```yaml
network_topology:
  mode: "colocation"  # colocation, remote, hybrid

  interfaces:
    # Trading network (low latency)
    trading:
      - name: "eth0"
        ip: "10.0.1.100"
        netmask: "255.255.255.0"
        gateway: "10.0.1.1"
        mtu: 9000  # Jumbo frames
        numa_node: 0
        pci_address: "0000:01:00.0"

    # Market data network
    market_data:
      - name: "eth1"
        ip: "10.0.2.100"
        netmask: "255.255.255.0"
        gateway: "10.0.2.1"
        mtu: 9000
        numa_node: 0
        pci_address: "0000:01:00.1"

    # Management network
    management:
      - name: "eth2"
        ip: "192.168.1.100"
        netmask: "255.255.255.0"
        gateway: "192.168.1.1"
        mtu: 1500
        numa_node: 1
        pci_address: "0000:81:00.0"

  routing:
    # Separate routing tables per interface
    tables:
      - id: 100
        name: "trading"
        default_gateway: "10.0.1.1"

      - id: 101
        name: "market_data"
        default_gateway: "10.0.2.1"

  bonding:
    enabled: false  # Use separate NICs for redundancy
```

CONNECTIVITY:
-------------
```yaml
connectivity:
  exchanges:
    nyse:
      primary:
        host: "nyse-fix-primary.exchange.com"
        ip: "10.100.1.10"
        port: 9876
        interface: "eth0"

      secondary:
        host: "nyse-fix-secondary.exchange.com"
        ip: "10.100.2.10"
        port: 9876
        interface: "eth0"

    nasdaq:
      primary:
        host: "nasdaq-ouch-primary.exchange.com"
        ip: "10.101.1.10"
        port: 9200
        interface: "eth0"

  market_data:
    nyse_pillar:
      channel_a:
        multicast_group: "224.0.150.1"
        port: 20001
        interface: "eth1"

      channel_b:
        multicast_group: "224.0.150.2"
        port: 20001
        interface: "eth1"

  internal:
    database:
      host: "db.internal.local"
      ip: "192.168.1.10"
      port: 5432
      interface: "eth2"

    monitoring:
      host: "monitor.internal.local"
      ip: "192.168.1.20"
      port: 9090
      interface: "eth2"
```

================================================================================
2. TCP/IP OPTIMIZATION
================================================================================

TCP TUNING:
-----------
```yaml
tcp_optimization:
  socket_options:
    # Disable Nagle's algorithm
    tcp_nodelay: true

    # Keep-alive settings
    tcp_keepalive: true
    tcp_keepalive_time: 60
    tcp_keepalive_interval: 10
    tcp_keepalive_probes: 5

    # Socket buffer sizes
    send_buffer_size: 4194304    # 4MB
    receive_buffer_size: 4194304 # 4MB

    # Socket options
    so_reuseaddr: true
    so_reuseport: true
    so_timestamp: true

  kernel_parameters:
    # TCP buffer sizes
    net.ipv4.tcp_rmem: "4096 87380 67108864"  # min default max
    net.ipv4.tcp_wmem: "4096 65536 67108864"  # min default max

    # Core network buffers
    net.core.rmem_max: 134217728     # 128MB
    net.core.wmem_max: 134217728     # 128MB
    net.core.rmem_default: 67108864  # 64MB
    net.core.wmem_default: 67108864  # 64MB

    # TCP settings
    net.ipv4.tcp_congestion_control: "cubic"  # cubic, bbr, htcp
    net.ipv4.tcp_timestamps: 1
    net.ipv4.tcp_sack: 1
    net.ipv4.tcp_window_scaling: 1

    # Fast open
    net.ipv4.tcp_fastopen: 3

    # Connection settings
    net.core.somaxconn: 4096
    net.core.netdev_max_backlog: 250000

    # TCP optimization
    net.ipv4.tcp_max_syn_backlog: 8192
    net.ipv4.tcp_slow_start_after_idle: 0
    net.ipv4.tcp_tw_reuse: 1
    net.ipv4.tcp_fin_timeout: 10

    # Memory
    net.ipv4.tcp_mem: "786432 1048576 26777216"

  low_latency_mode:
    enabled: true

    settings:
      # Disable interrupt coalescing
      interrupt_coalescing: false

      # Busy polling
      net.core.busy_poll: 50  # microseconds
      net.core.busy_read: 50

      # RPS/RFS (Receive Packet Steering)
      rps_enabled: false  # Disable for dedicated cores
      rfs_enabled: false
```

C++ SOCKET CONFIGURATION:
--------------------------
```cpp
class OptimizedSocket {
private:
    int socket_fd_;

public:
    void ConfigureSocket() {
        // TCP_NODELAY - disable Nagle's algorithm
        int flag = 1;
        setsockopt(socket_fd_, IPPROTO_TCP, TCP_NODELAY,
                  &flag, sizeof(flag));

        // SO_REUSEADDR
        flag = 1;
        setsockopt(socket_fd_, SOL_SOCKET, SO_REUSEADDR,
                  &flag, sizeof(flag));

        // SO_REUSEPORT
        flag = 1;
        setsockopt(socket_fd_, SOL_SOCKET, SO_REUSEPORT,
                  &flag, sizeof(flag));

        // Send buffer size
        int send_buf = 4 * 1024 * 1024;  // 4MB
        setsockopt(socket_fd_, SOL_SOCKET, SO_SNDBUF,
                  &send_buf, sizeof(send_buf));

        // Receive buffer size
        int recv_buf = 4 * 1024 * 1024;  // 4MB
        setsockopt(socket_fd_, SOL_SOCKET, SO_RCVBUF,
                  &recv_buf, sizeof(recv_buf));

        // Timestamp packets
        flag = 1;
        setsockopt(socket_fd_, SOL_SOCKET, SO_TIMESTAMP,
                  &flag, sizeof(flag));

        // TCP_QUICKACK - disable delayed ACK
        flag = 1;
        setsockopt(socket_fd_, IPPROTO_TCP, TCP_QUICKACK,
                  &flag, sizeof(flag));

        // TCP Keep-alive
        flag = 1;
        setsockopt(socket_fd_, SOL_SOCKET, SO_KEEPALIVE,
                  &flag, sizeof(flag));

        int keepidle = 60;  // 60 seconds
        setsockopt(socket_fd_, IPPROTO_TCP, TCP_KEEPIDLE,
                  &keepidle, sizeof(keepidle));

        int keepintvl = 10;  // 10 seconds
        setsockopt(socket_fd_, IPPROTO_TCP, TCP_KEEPINTVL,
                  &keepintvl, sizeof(keepintvl));

        int keepcnt = 5;  // 5 probes
        setsockopt(socket_fd_, IPPROTO_TCP, TCP_KEEPCNT,
                  &keepcnt, sizeof(keepcnt));

        // Set socket to non-blocking
        int flags = fcntl(socket_fd_, F_GETFL, 0);
        fcntl(socket_fd_, F_SETFL, flags | O_NONBLOCK);

        LOG_INFO("Socket configured for low latency");
    }

    void BindToInterface(const std::string& interface) {
        // Bind socket to specific network interface
        setsockopt(socket_fd_, SOL_SOCKET, SO_BINDTODEVICE,
                  interface.c_str(), interface.length());

        LOG_INFO("Socket bound to interface: {}", interface);
    }

    void SetCPUAffinity(int cpu_core) {
        // Set CPU affinity for socket processing
        cpu_set_t cpuset;
        CPU_ZERO(&cpuset);
        CPU_SET(cpu_core, &cpuset);

        pthread_t current_thread = pthread_self();
        pthread_setaffinity_np(current_thread,
                              sizeof(cpu_set_t), &cpuset);

        LOG_INFO("Socket thread pinned to CPU core: {}", cpu_core);
    }
};
```

================================================================================
3. KERNEL BYPASS TECHNOLOGIES
================================================================================

DPDK CONFIGURATION:
-------------------
```yaml
dpdk:
  enabled: true
  version: "23.11"

  eal_parameters:
    # Cores for DPDK
    cores: "2,3,4,5"

    # Hugepages
    huge_pages: 2048
    huge_page_size: "2M"

    # Memory channels
    memory_channels: 4

    # PCI devices
    allow_list:
      - "0000:01:00.0"
      - "0000:01:00.1"

    # Additional options
    single_file_segments: true
    no_shconf: true

  ports:
    - port_id: 0
      pci: "0000:01:00.0"
      numa_node: 0
      rx_queues: 4
      tx_queues: 4
      rx_desc: 4096
      tx_desc: 4096

    - port_id: 1
      pci: "0000:01:00.1"
      numa_node: 0
      rx_queues: 4
      tx_queues: 4
      rx_desc: 4096
      tx_desc: 4096

  mempool:
    size: 65536
    cache_size: 512
    element_size: 2048
```

ONLOAD (SOLARFLARE) CONFIGURATION:
-----------------------------------
```yaml
onload:
  enabled: true

  environment:
    EF_POLL_USEC: 100000  # Spinning poll timeout
    EF_INT_DRIVEN: 0      # Disable interrupt-driven mode
    EF_KERNEL_PACKETS_TIMER: 0
    EF_NO_FAIL: 1
    EF_UDP: 1
    EF_TCP: 1

  kernel_bypass:
    mode: "full"  # full, partial
    tcp_acceleration: true
    udp_acceleration: true

  performance:
    spin_poll: true
    busy_wait: true
    packet_buffer_mode: "scalable"
```

================================================================================
4. NIC CONFIGURATION
================================================================================

NIC SETTINGS:
-------------
```yaml
nic_configuration:
  intel_x710:
    # RSS (Receive Side Scaling)
    rss:
      enabled: true
      hash_key: "auto"
      queues: 4

    # Flow Director
    flow_director:
      enabled: true
      mode: "perfect"  # perfect, signature

    # Interrupt moderation
    interrupt_moderation:
      enabled: false  # Disable for low latency

    # Ring buffer sizes
    ring_buffers:
      rx: 4096
      tx: 4096

    # Offloads
    offloads:
      rx_checksum: false
      tx_checksum: false
      tso: false  # TCP Segmentation Offload
      gro: false  # Generic Receive Offload
      lro: false  # Large Receive Offload

    # Coalescing
    coalescing:
      rx_usecs: 0
      tx_usecs: 0
      rx_frames: 0
      tx_frames: 0

  mellanox_connectx6:
    # Similar configuration for Mellanox
    rss:
      enabled: true
      queues: 8

    # Adaptive moderation
    adaptive_moderation:
      enabled: false

    # PFC (Priority Flow Control)
    pfc:
      enabled: false
```

ETHTOOL CONFIGURATION:
----------------------
```bash
# Ring buffer sizes
ethtool -G eth0 rx 4096 tx 4096

# Disable offloads
ethtool -K eth0 gro off
ethtool -K eth0 lro off
ethtool -K eth0 tso off
ethtool -K eth0 gso off

# Disable interrupt coalescing
ethtool -C eth0 rx-usecs 0 tx-usecs 0

# RSS queues
ethtool -L eth0 combined 4

# Flow control (disable)
ethtool -A eth0 rx off tx off

# Display stats
ethtool -S eth0
```

IRQ AFFINITY:
-------------
```yaml
irq_affinity:
  enabled: true

  # Bind NIC interrupts to specific cores
  eth0:
    irqs: [50, 51, 52, 53]
    cores: [0, 1, 0, 1]  # Distribute across cores 0 and 1

  eth1:
    irqs: [60, 61, 62, 63]
    cores: [0, 1, 0, 1]

  # Disable irqbalance daemon
  disable_irqbalance: true
```

================================================================================
5. MULTICAST CONFIGURATION
================================================================================

MULTICAST SETTINGS:
-------------------
```yaml
multicast:
  # Multicast groups
  groups:
    - name: "nyse_pillar_a"
      group: "224.0.150.1"
      port: 20001
      interface: "eth1"
      source: "10.100.150.10"  # SSM source

    - name: "nyse_pillar_b"
      group: "224.0.150.2"
      port: 20001
      interface: "eth1"
      source: "10.100.150.11"

    - name: "nasdaq_totalview"
      group: "233.43.202.1"
      port: 26477
      interface: "eth1"
      source: "10.101.200.10"

  socket_options:
    # Receive buffer size (large for market data)
    receive_buffer_size: 67108864  # 64MB

    # Multicast TTL
    multicast_ttl: 16

    # Multicast loop
    multicast_loop: false

  kernel_settings:
    # Multicast routing
    net.ipv4.conf.all.mc_forwarding: 0

    # IGMP settings
    net.ipv4.igmp_max_memberships: 1000
```

C++ MULTICAST RECEIVER:
-----------------------
```cpp
class MulticastReceiver {
private:
    int socket_fd_;
    std::string multicast_group_;
    uint16_t port_;
    std::string interface_;

public:
    MulticastReceiver(const std::string& group,
                     uint16_t port,
                     const std::string& iface)
        : multicast_group_(group), port_(port), interface_(iface) {}

    void Initialize() {
        // Create UDP socket
        socket_fd_ = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);
        if (socket_fd_ < 0) {
            throw std::runtime_error("Failed to create socket");
        }

        // Reuse address
        int reuse = 1;
        setsockopt(socket_fd_, SOL_SOCKET, SO_REUSEADDR,
                  &reuse, sizeof(reuse));

        // Reuse port (for multiple receivers)
        setsockopt(socket_fd_, SOL_SOCKET, SO_REUSEPORT,
                  &reuse, sizeof(reuse));

        // Bind to multicast port
        sockaddr_in addr{};
        addr.sin_family = AF_INET;
        addr.sin_addr.s_addr = INADDR_ANY;
        addr.sin_port = htons(port_);

        if (bind(socket_fd_, (sockaddr*)&addr, sizeof(addr)) < 0) {
            throw std::runtime_error("Failed to bind socket");
        }

        // Join multicast group
        ip_mreq mreq{};
        inet_pton(AF_INET, multicast_group_.c_str(),
                 &mreq.imr_multiaddr);
        mreq.imr_interface.s_addr = INADDR_ANY;

        setsockopt(socket_fd_, IPPROTO_IP, IP_ADD_MEMBERSHIP,
                  &mreq, sizeof(mreq));

        // Large receive buffer
        int recv_buf = 64 * 1024 * 1024;  // 64MB
        setsockopt(socket_fd_, SOL_SOCKET, SO_RCVBUF,
                  &recv_buf, sizeof(recv_buf));

        // Bind to specific interface
        setsockopt(socket_fd_, SOL_SOCKET, SO_BINDTODEVICE,
                  interface_.c_str(), interface_.length());

        LOG_INFO("Multicast receiver initialized: {}:{}",
                multicast_group_, port_);
    }

    void Receive() {
        alignas(64) char buffer[65536];

        while (true) {
            ssize_t bytes_received = recv(socket_fd_, buffer,
                                         sizeof(buffer), 0);

            if (bytes_received > 0) {
                ProcessPacket(buffer, bytes_received);
            }
        }
    }

private:
    void ProcessPacket(const char* data, size_t length) {
        // Process market data packet
        // High-performance processing here
    }
};
```

================================================================================
6. FIREWALL RULES
================================================================================

IPTABLES CONFIGURATION:
-----------------------
```yaml
firewall:
  default_policy:
    input: "DROP"
    forward: "DROP"
    output: "ACCEPT"

  rules:
    # Allow established connections
    - chain: "INPUT"
      state: "ESTABLISHED,RELATED"
      action: "ACCEPT"

    # Allow loopback
    - chain: "INPUT"
      interface: "lo"
      action: "ACCEPT"

    # Trading interface (eth0)
    - chain: "INPUT"
      interface: "eth0"
      protocol: "tcp"
      source: "10.0.1.0/24"
      dport: 9876
      action: "ACCEPT"

    # Market data interface (eth1)
    - chain: "INPUT"
      interface: "eth1"
      protocol: "udp"
      destination: "224.0.0.0/4"  # Multicast
      action: "ACCEPT"

    # Management interface (eth2)
    - chain: "INPUT"
      interface: "eth2"
      protocol: "tcp"
      source: "192.168.1.0/24"
      dport: 22
      action: "ACCEPT"

    # Rate limiting
    - chain: "INPUT"
      protocol: "tcp"
      dport: 22
      limit: "5/minute"
      action: "ACCEPT"

    # Drop invalid packets
    - chain: "INPUT"
      state: "INVALID"
      action: "DROP"

    # Log dropped packets
    - chain: "INPUT"
      action: "LOG"
      log_prefix: "DROPPED: "
      log_level: 4
```

NFTABLES CONFIGURATION:
-----------------------
```yaml
nftables:
  tables:
    - name: "hft_filter"
      family: "inet"

      chains:
        - name: "input"
          type: "filter"
          hook: "input"
          priority: 0
          policy: "drop"

          rules:
            - "ct state established,related accept"
            - "iif lo accept"
            - "iif eth0 tcp dport 9876 accept"
            - "iif eth1 udp dport 20001 accept"
            - "iif eth2 tcp dport 22 ip saddr 192.168.1.0/24 accept"
```

================================================================================
7. NETWORK SECURITY
================================================================================

SECURITY CONFIGURATION:
-----------------------
```yaml
network_security:
  # IP whitelisting
  ip_whitelist:
    enabled: true
    addresses:
      - "10.0.1.0/24"      # Trading network
      - "10.100.0.0/16"    # Exchange network
      - "192.168.1.0/24"   # Management network

  # MAC address filtering
  mac_filtering:
    enabled: true
    allowed_macs:
      - "00:1A:2B:3C:4D:5E"
      - "00:1A:2B:3C:4D:5F"

  # Port security
  port_security:
    # Allowed inbound ports
    inbound_ports:
      - 9876  # FIX
      - 9200  # OUCH

    # Allowed outbound ports
    outbound_ports:
      - 9876
      - 9200
      - 443   # HTTPS

  # DDoS protection
  ddos_protection:
    enabled: true

    rate_limits:
      packets_per_second: 100000
      connections_per_second: 1000
      syn_per_second: 500

    connection_tracking:
      max_connections: 10000
      timeout_seconds: 300
```

TLS/SSL CONFIGURATION:
----------------------
```yaml
tls_ssl:
  enabled: true

  certificates:
    certificate_file: "/etc/hft/certs/hft.crt"
    private_key_file: "/etc/hft/keys/hft.key"
    ca_certificate_file: "/etc/hft/certs/ca.crt"

  protocols:
    min_version: "TLSv1.2"
    max_version: "TLSv1.3"

  cipher_suites:
    - "ECDHE-RSA-AES256-GCM-SHA384"
    - "ECDHE-RSA-AES128-GCM-SHA256"

  verification:
    verify_peer: true
    verify_hostname: true
```

================================================================================
8. LATENCY OPTIMIZATION
================================================================================

LATENCY REDUCTION TECHNIQUES:
------------------------------
```yaml
latency_optimization:
  # CPU governor
  cpu_governor: "performance"

  # Disable power management
  disable_c_states: true
  disable_p_states: false

  # Disable SMT (Hyper-Threading) on critical cores
  disable_smt: true
  smt_disabled_cores: [2, 3, 4, 5, 6, 7]

  # Isolate cores
  isolcpus: [2, 3, 4, 5, 6, 7, 8, 9, 10]

  # Tickless kernel
  nohz_full: [2, 3, 4, 5, 6, 7, 8, 9, 10]

  # RCU callbacks
  rcu_nocbs: [2, 3, 4, 5, 6, 7, 8, 9, 10]

  # Transparent huge pages
  transparent_hugepages: "never"

  # Network stack tuning
  network_tuning:
    # Busy polling
    busy_poll: 50
    busy_read: 50

    # TCP tuning
    tcp_timestamps: 0  # Disable for minimal overhead
    tcp_low_latency: 1
```

KERNEL BOOT PARAMETERS:
-----------------------
```bash
# /etc/default/grub
GRUB_CMDLINE_LINUX="
  isolcpus=2-10
  nohz_full=2-10
  rcu_nocbs=2-10
  intel_pstate=disable
  processor.max_cstate=1
  intel_idle.max_cstate=0
  nosmt
  transparent_hugepage=never
  tsc=reliable
  clocksource=tsc
  intel_iommu=off
"
```

================================================================================
9. MONITORING AND DIAGNOSTICS
================================================================================

NETWORK MONITORING:
-------------------
```yaml
network_monitoring:
  # Statistics collection
  statistics:
    enabled: true
    interval_seconds: 1

    metrics:
      - "packets_sent"
      - "packets_received"
      - "bytes_sent"
      - "bytes_received"
      - "errors"
      - "drops"
      - "retransmits"

  # Packet capture
  packet_capture:
    enabled: false  # Disable in production
    interface: "eth0"
    filter: "tcp port 9876"
    max_packets: 10000
    output_file: "/var/log/hft/pcap/capture.pcap"

  # Latency monitoring
  latency_monitoring:
    enabled: true
    ping_targets:
      - host: "10.0.1.1"
        interval_ms: 1000
      - host: "nyse-fix-primary.exchange.com"
        interval_ms: 1000
```

C++ NETWORK STATISTICS:
-----------------------
```cpp
class NetworkStatistics {
private:
    struct Stats {
        uint64_t packets_sent{0};
        uint64_t packets_received{0};
        uint64_t bytes_sent{0};
        uint64_t bytes_received{0};
        uint64_t errors{0};
        uint64_t drops{0};
    };

    Stats stats_;
    std::atomic<uint64_t> last_timestamp_{0};

public:
    void UpdateStatistics() {
        // Read /proc/net/dev for interface statistics
        std::ifstream netdev("/proc/net/dev");
        std::string line;

        while (std::getline(netdev, line)) {
            if (line.find("eth0") != std::string::npos) {
                ParseNetDevLine(line);
                break;
            }
        }
    }

    void LogStatistics() {
        LOG_INFO("Network Stats - RX: {} pkts, {} bytes | "
                "TX: {} pkts, {} bytes | Errors: {}, Drops: {}",
                stats_.packets_received, stats_.bytes_received,
                stats_.packets_sent, stats_.bytes_sent,
                stats_.errors, stats_.drops);
    }

private:
    void ParseNetDevLine(const std::string& line) {
        // Parse /proc/net/dev format
        // eth0: bytes packets errs drop ...
    }
};
```

================================================================================
END OF NETWORK CONFIGURATION
================================================================================
