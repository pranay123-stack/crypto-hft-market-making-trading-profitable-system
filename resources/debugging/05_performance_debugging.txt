================================================================================
                    HFT PERFORMANCE DEBUGGING GUIDE
================================================================================

TABLE OF CONTENTS
-----------------
1. Theory and Common Performance Issues in HFT
2. Performance Profiling Tools
3. CPU Bottleneck Detection
4. Cache Optimization
5. Branch Prediction and Pipeline Issues
6. Step-by-Step Debugging Workflows
7. Real HFT C++ Code Examples
8. Debugging Commands and Interpretation
9. Solutions and Fixes
10. Best Practices for HFT Performance

================================================================================
1. THEORY AND COMMON PERFORMANCE ISSUES IN HFT
================================================================================

OVERVIEW
--------
Performance in HFT is about:
- Maximum throughput (messages/second)
- Minimum latency (nanoseconds)
- Consistent performance (low jitter)
- Efficient resource utilization

PERFORMANCE BOTTLENECKS IN HFT
-------------------------------

A) CPU BOTTLENECKS
   - Insufficient compute capacity
   - Inefficient algorithms (O(n²) vs O(log n))
   - Excessive branching
   - Poor instruction-level parallelism

B) MEMORY BOTTLENECKS
   - L1/L2/L3 cache misses
   - TLB misses
   - NUMA remote access
   - Memory bandwidth saturation

C) I/O BOTTLENECKS
   - Network bandwidth limits
   - Storage I/O
   - Excessive system calls

D) SYNCHRONIZATION BOTTLENECKS
   - Lock contention
   - Atomic operation overhead
   - False sharing
   - Memory ordering constraints

MODERN CPU ARCHITECTURE CONSIDERATIONS
---------------------------------------

1. INSTRUCTION PIPELINE
   - Modern CPUs execute multiple instructions simultaneously
   - Pipeline depth: 14-20 stages (Intel/AMD)
   - Branch misprediction penalty: 15-20 cycles
   - Goal: Keep pipeline full

2. OUT-OF-ORDER EXECUTION
   - CPU reorders instructions for efficiency
   - Reorder buffer: ~200 instructions
   - Dependency chains limit parallelism

3. CACHE HIERARCHY
   - L1: 32-64KB, 4 cycles, per-core
   - L2: 256KB-1MB, 12 cycles, per-core
   - L3: 8-32MB, 40-75 cycles, shared
   - RAM: GBs, 200+ cycles

4. SIMD UNITS (AVX/AVX2/AVX-512)
   - Process multiple data elements simultaneously
   - AVX2: 256-bit (4x double, 8x float)
   - AVX-512: 512-bit (8x double, 16x float)

================================================================================
2. PERFORMANCE PROFILING TOOLS
================================================================================

PERF (LINUX PERFORMANCE ANALYZER)
----------------------------------

1. CPU Profiling:
```bash
perf record -g -F 9999 ./trading_engine
perf report --stdio --no-children
```

2. Hardware Events:
```bash
perf stat -e cycles,instructions,cache-references,cache-misses,\
branch-instructions,branch-misses ./trading_engine
```

3. Annotate Source:
```bash
perf record ./trading_engine
perf annotate --stdio function_name
```

INTEL VTUNE
-----------

Commercial profiler with deep Intel CPU integration
- Microarchitecture analysis
- Memory access analysis
- Threading analysis
- Platform analysis

Key metrics:
- CPI (Cycles Per Instruction)
- Frontend bound %
- Backend bound %
- Retiring %
- Bad speculation %

GOOGLE PERFTOOLS (GPERFTOOLS)
------------------------------

CPU and heap profiler

```bash
# Link with profiler
g++ -lprofiler program.cpp

# Run with profiling
CPUPROFILE=/tmp/prof.out ./program

# Generate report
pprof --text ./program /tmp/prof.out
pprof --pdf ./program /tmp/prof.out > profile.pdf
```

CACHEGRIND (VALGRIND)
----------------------

Cache simulation tool

```bash
valgrind --tool=cachegrind ./trading_engine
cg_annotate cachegrind.out.<pid>
```

Output shows:
- L1 instruction cache misses
- L1 data cache misses
- LL (last-level) cache misses

HARDWARE PERFORMANCE COUNTERS
------------------------------

Direct PMU (Performance Monitoring Unit) access

Available counters:
- Cycle count
- Instructions retired
- Cache misses (L1/L2/L3)
- TLB misses
- Branch mispredictions
- Memory loads/stores

================================================================================
3. CPU BOTTLENECK DETECTION
================================================================================

IDENTIFYING CPU BOTTLENECKS
----------------------------

1. HIGH CPU UTILIZATION
```bash
top -p $(pidof trading_engine)
# If CPU% near 100%, may be CPU bound

htop -p $(pidof trading_engine)
# Visual CPU usage per thread
```

2. CYCLES PER INSTRUCTION (CPI)
```bash
perf stat -e cycles,instructions ./trading_engine
```

Output:
```
1,234,567,890  cycles
  987,654,321  instructions  # 0.80 IPC (1.25 CPI)
```

Interpretation:
- IPC < 1.0: Poor instruction-level parallelism
- IPC 1-2: Typical for most code
- IPC 2-4: Well-optimized code
- IPC > 4: SIMD-heavy code

3. FRONTEND VS BACKEND STALLS

Frontend bound (instruction fetch/decode issues):
- I-cache misses
- Branch mispredictions
- Instruction decode bottlenecks

Backend bound (execution issues):
- D-cache misses
- Memory latency
- Execution port saturation

Check with VTune or:
```bash
perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend ./program
```

HOTSPOT IDENTIFICATION
-----------------------

```bash
# Record with call graph
perf record -g -F 9999 ./trading_engine

# Report top functions
perf report --stdio --no-children | head -50
```

Example output:
```
    45.23%  trading_engine  [.] OrderBook::update
    23.45%  trading_engine  [.] Strategy::evaluate
    12.34%  trading_engine  [.] parse_market_data
     8.90%  trading_engine  [.] send_order
```

Focus optimization on top 20% of functions (80/20 rule)

INSTRUCTION-LEVEL PROFILING
----------------------------

```bash
# Record with source annotation
perf record -g ./trading_engine

# Annotate specific function
perf annotate --stdio OrderBook::update
```

Example output:
```
Percent |   Source code & Disassembly
--------|-----------------------------
        | double OrderBook::update(double price, int qty) {
 23.45  |   mov    %rdi,%rax
  0.12  |   mov    0x10(%rdi),%rdx
 45.67  |   mov    (%rdx,%rsi,8),%rcx    <- Cache miss here!
  8.90  |   add    %ecx,%esi
  2.34  |   mov    %esi,(%rdx,%rax,8)
        | }
```

BRANCH MISPREDICTION ANALYSIS
------------------------------

```bash
perf stat -e branch-instructions,branch-misses ./trading_engine
```

Output:
```
   1,234,567,890  branch-instructions
      12,345,678  branch-misses  # 1.0% miss rate
```

Interpretation:
- < 1% miss rate: Good
- 1-5% miss rate: Typical
- > 5% miss rate: Investigate branching patterns

Detailed analysis:
```bash
perf record -e branch-misses -g ./trading_engine
perf report --stdio
```

FUNCTION CALL OVERHEAD
-----------------------

Virtual function calls can be expensive:

```cpp
// Measure virtual call overhead
class Base {
public:
    virtual void process() = 0;
};

class Derived : public Base {
public:
    void process() override {
        // ... work ...
    }
};

// Benchmark
Base* obj = new Derived();
uint64_t start = rdtsc();
for (int i = 0; i < 1000000; ++i) {
    obj->process();  // Virtual call: ~5-10 cycles overhead
}
uint64_t end = rdtsc();
```

Solutions:
- Devirtualization (if compiler can infer type)
- Template-based polymorphism
- Function pointers stored directly

================================================================================
4. CACHE OPTIMIZATION
================================================================================

UNDERSTANDING CACHE BEHAVIOR
-----------------------------

Cache Line Size: 64 bytes (x86/x64)

Key concepts:
- Spatial locality: Access nearby memory
- Temporal locality: Access same memory repeatedly
- Cache associativity: Where data can be cached

DETECTING CACHE MISSES
-----------------------

```bash
perf stat -e L1-dcache-load-misses,L1-dcache-loads,\
            LLC-load-misses,LLC-loads ./trading_engine
```

Output:
```
     123,456,789  L1-dcache-loads
      12,345,678  L1-dcache-load-misses  # 10% miss rate - BAD!
     987,654,321  LLC-loads
       1,234,567  LLC-load-misses        # 0.12% miss rate - OK
```

L1 miss rates:
- < 1%: Excellent
- 1-3%: Good
- 3-10%: Room for improvement
- > 10%: Serious cache issues

LLC miss rates:
- < 1%: Good
- 1-5%: Typical
- > 5%: Memory bound

CACHEGRIND ANALYSIS
-------------------

```bash
valgrind --tool=cachegrind --cachegrind-out-file=cache.out ./trading_engine
cg_annotate cache.out
```

Output:
```
I refs:      1,234,567,890
I1  misses:      1,234,567
LLi misses:        123,456
I1  miss rate:        0.10%
LLi miss rate:        0.01%

D refs:        456,789,012  (345,678,901 rd + 111,110,111 wr)
D1  misses:     45,678,901  ( 34,567,890 rd +  11,110,111 wr)
LLd misses:      4,567,890  (  3,456,789 rd +   1,111,101 wr)
D1  miss rate:       10.0%  (      10.0%   +       10.0%)
LLd miss rate:        1.0%  (       1.0%   +        1.0%)
```

CACHE-FRIENDLY DATA STRUCTURES
-------------------------------

BAD Example: Scattered data
```cpp
struct Order {
    uint64_t id;
    std::string symbol;      // Heap allocation - cache miss!
    double price;
    std::vector<Fill> fills; // Heap allocation - cache miss!
    // ... many fields ...
};

std::vector<Order*> orders;  // Pointer indirection - cache miss!
```

GOOD Example: Cache-friendly layout
```cpp
struct Order {
    // Hot data first (frequently accessed together)
    uint64_t id;
    double price;
    uint32_t quantity;
    char symbol[8];  // Inline - no cache miss

    // Cold data later
    uint64_t timestamp;
    // ... rarely accessed fields ...
} __attribute__((aligned(64)));  // Cache line aligned

std::vector<Order> orders;  // Contiguous - cache friendly!
```

STRUCT PACKING FOR CACHE EFFICIENCY
------------------------------------

```cpp
// Before: 80 bytes (spans 2 cache lines)
struct Trade {
    uint64_t id;          // 8 bytes
    double price;         // 8 bytes
    uint32_t quantity;    // 4 bytes
    uint32_t _pad1;       // 4 bytes padding
    uint64_t timestamp;   // 8 bytes
    char symbol[8];       // 8 bytes
    uint32_t flags;       // 4 bytes
    uint32_t _pad2;       // 4 bytes padding
    void* user_data;      // 8 bytes
    double commission;    // 8 bytes
    uint32_t account;     // 4 bytes
    uint32_t _pad3;       // 4 bytes padding
};  // Total: 80 bytes

// After: 64 bytes (fits in 1 cache line!)
struct Trade {
    // Reorder for tight packing
    uint64_t id;          // 8 bytes
    uint64_t timestamp;   // 8 bytes
    double price;         // 8 bytes
    double commission;    // 8 bytes
    char symbol[8];       // 8 bytes
    uint32_t quantity;    // 4 bytes
    uint32_t flags;       // 4 bytes
    uint32_t account;     // 4 bytes
    uint32_t _reserved;   // 4 bytes (for future use)
} __attribute__((packed, aligned(64)));  // Total: 64 bytes
```

PREFETCHING
-----------

Manual prefetching for predictable access patterns:

```cpp
void process_orders(std::vector<Order>& orders) {
    for (size_t i = 0; i < orders.size(); ++i) {
        // Prefetch next order while processing current
        if (i + 1 < orders.size()) {
            __builtin_prefetch(&orders[i + 1], 0, 3);
            // 0 = read, 1 = write
            // 3 = high temporal locality
        }

        process_order(orders[i]);
    }
}
```

SOFTWARE PREFETCH EXAMPLE
--------------------------

```cpp
#include <xmmintrin.h>  // SSE

void prefetch_load(const void* addr) {
    _mm_prefetch((const char*)addr, _MM_HINT_T0);
    // _MM_HINT_T0: Prefetch to all cache levels
    // _MM_HINT_T1: Prefetch to L2 and L3
    // _MM_HINT_T2: Prefetch to L3 only
    // _MM_HINT_NTA: Non-temporal (bypass cache)
}

class OrderBook {
    std::array<PriceLevel, 1000> bids;

public:
    void prefetch_level(size_t index) {
        if (index < bids.size()) {
            prefetch_load(&bids[index]);
        }
    }

    const PriceLevel& get_level(size_t index) {
        // Prefetch next level
        if (index + 1 < bids.size()) {
            prefetch_load(&bids[index + 1]);
        }
        return bids[index];
    }
};
```

================================================================================
5. BRANCH PREDICTION AND PIPELINE ISSUES
================================================================================

BRANCH PREDICTION BASICS
-------------------------

Modern CPUs predict branch direction to keep pipeline full
- Correct prediction: No penalty
- Misprediction: 15-20 cycle penalty

Types of branches:
1. Conditional branches (if/else)
2. Indirect branches (function pointers, virtual calls)
3. Loop branches

REDUCING BRANCH MISPREDICTIONS
-------------------------------

Technique 1: Eliminate Branches

Before:
```cpp
int calculate(int x) {
    if (x > 0) {
        return x * 2;
    } else {
        return 0;
    }
}
```

After:
```cpp
int calculate(int x) {
    // Branchless using conditional move
    return (x > 0) * (x * 2);

    // Or use ternary (may be optimized to CMOV)
    return (x > 0) ? x * 2 : 0;
}
```

Technique 2: Likely/Unlikely Hints

```cpp
#define likely(x)   __builtin_expect(!!(x), 1)
#define unlikely(x) __builtin_expect(!!(x), 0)

void process_order(const Order& order) {
    if (unlikely(order.quantity == 0)) {
        // Rarely taken branch
        log_error("Invalid order");
        return;
    }

    // Hot path continues here
    execute_order(order);
}
```

Technique 3: Branchless Comparisons

```cpp
// Find minimum without branches
int branchless_min(int a, int b) {
    return a + ((b - a) & ((b - a) >> 31));
}

// Conditional assignment without branches
int conditional_assign(int condition, int true_val, int false_val) {
    return (-condition & true_val) | (~(-condition) & false_val);
}

// Absolute value without branch
int abs_branchless(int x) {
    int mask = x >> 31;
    return (x + mask) ^ mask;
}
```

Technique 4: Lookup Tables

Before:
```cpp
int fee_calculate(OrderType type) {
    if (type == MARKET) {
        return 5;
    } else if (type == LIMIT) {
        return 3;
    } else if (type == STOP) {
        return 4;
    }
    return 0;
}
```

After:
```cpp
static const int FEE_TABLE[] = {0, 5, 3, 4};

int fee_calculate(OrderType type) {
    return FEE_TABLE[type];  // No branches!
}
```

SWITCH OPTIMIZATION
-------------------

```cpp
// Compiler may generate jump table (good) or nested branches (bad)
// Help compiler with dense, sequential case values

// BAD: Sparse cases
switch (message_type) {
    case 100: process_type_100(); break;
    case 500: process_type_500(); break;
    case 1000: process_type_1000(); break;
}

// GOOD: Dense cases (0, 1, 2, 3...)
enum MessageType {
    TYPE_QUOTE = 0,
    TYPE_TRADE = 1,
    TYPE_ORDER = 2,
    TYPE_FILL = 3
};

switch (message_type) {
    case TYPE_QUOTE: process_quote(); break;
    case TYPE_TRADE: process_trade(); break;
    case TYPE_ORDER: process_order(); break;
    case TYPE_FILL: process_fill(); break;
}
```

Or use function pointer table:
```cpp
using ProcessFunc = void (*)();
static const ProcessFunc HANDLERS[] = {
    process_quote,
    process_trade,
    process_order,
    process_fill
};

HANDLERS[message_type]();  // No branches, direct call
```

LOOP OPTIMIZATION
-----------------

Technique 1: Loop Unrolling

```cpp
// Before: Loop overhead every iteration
for (int i = 0; i < 1000; ++i) {
    sum += data[i];
}

// After: Unrolled by 4
for (int i = 0; i < 1000; i += 4) {
    sum += data[i];
    sum += data[i + 1];
    sum += data[i + 2];
    sum += data[i + 3];
}
```

Compiler can auto-unroll with optimization flags:
```bash
g++ -O3 -funroll-loops program.cpp
```

Technique 2: Loop Interchange

```cpp
// Before: Poor cache locality (column-major access)
for (int j = 0; j < N; ++j) {
    for (int i = 0; i < M; ++i) {
        matrix[i][j] = 0;  // Bad access pattern!
    }
}

// After: Good cache locality (row-major access)
for (int i = 0; i < M; ++i) {
    for (int j = 0; j < N; ++j) {
        matrix[i][j] = 0;  // Sequential access
    }
}
```

Technique 3: Loop Fusion

```cpp
// Before: Two passes over data
for (int i = 0; i < N; ++i) {
    a[i] = b[i] + c[i];
}
for (int i = 0; i < N; ++i) {
    d[i] = a[i] * 2;
}

// After: One pass (better cache utilization)
for (int i = 0; i < N; ++i) {
    a[i] = b[i] + c[i];
    d[i] = a[i] * 2;
}
```

================================================================================
6. STEP-BY-STEP DEBUGGING WORKFLOWS
================================================================================

WORKFLOW 1: IDENTIFYING PERFORMANCE BOTTLENECK
-----------------------------------------------

Step 1: Profile with perf
```bash
perf record -g -F 9999 ./trading_engine
perf report --stdio --no-children | head -50
```

Step 2: Identify Hot Functions
Look for functions consuming > 5% of cycles

Step 3: Analyze Hot Function
```bash
perf annotate --stdio hot_function_name
```

Step 4: Check Hardware Events
```bash
perf stat -e cycles,instructions,cache-misses,branch-misses \
    ./trading_engine
```

Step 5: Drill Down Based on Findings
- High cache-miss rate → Optimize data layout
- High branch-miss rate → Reduce branches
- Low IPC → Check for dependencies, try SIMD

Step 6: Optimize and Measure Again
Always benchmark before/after!

WORKFLOW 2: CACHE OPTIMIZATION
-------------------------------

Step 1: Measure Baseline Cache Performance
```bash
perf stat -e L1-dcache-load-misses,L1-dcache-loads,\
    LLC-load-misses,LLC-loads ./trading_engine
```

Step 2: Detailed Cache Analysis with Cachegrind
```bash
valgrind --tool=cachegrind ./trading_engine
cg_annotate cachegrind.out.<pid>
```

Step 3: Identify Cache-Unfriendly Code
Look for:
- Pointer chasing (linked lists)
- Scattered data structures
- Large objects crossing cache lines
- Excessive padding

Step 4: Restructure Data
- Reorder struct fields (hot first)
- Align to cache line boundaries
- Use contiguous containers (vector vs list)
- Pack cold data separately

Step 5: Verify Improvement
```bash
perf stat -e L1-dcache-load-misses,L1-dcache-loads \
    ./trading_engine_optimized
```

WORKFLOW 3: BRANCH OPTIMIZATION
--------------------------------

Step 1: Measure Branch Performance
```bash
perf stat -e branch-instructions,branch-misses \
    ./trading_engine
```

Step 2: Profile Branch-Heavy Functions
```bash
perf record -e branch-misses -g ./trading_engine
perf report --stdio
```

Step 3: Annotate Source
```bash
perf annotate --stdio function_with_misses
```

Step 4: Apply Optimizations
- Add likely/unlikely hints
- Convert to branchless code
- Use lookup tables
- Reorder conditions (most common first)

Step 5: Verify Improvement
```bash
perf stat -e branch-misses ./trading_engine_optimized
```

================================================================================
7. REAL HFT C++ CODE EXAMPLES
================================================================================

EXAMPLE 1: CACHE-OPTIMIZED ORDER BOOK
--------------------------------------

```cpp
#include <array>
#include <cstdint>

// Cache line aligned price level
struct alignas(64) PriceLevel {
    double price;
    uint64_t total_quantity;
    uint32_t order_count;
    uint32_t _pad;

    // Reserve rest of cache line for future use
    char _reserved[64 - sizeof(price) - sizeof(total_quantity) -
                   sizeof(order_count) - sizeof(_pad)];
};

static_assert(sizeof(PriceLevel) == 64, "Must be cache line size");

class CacheOptimizedOrderBook {
    static constexpr size_t MAX_LEVELS = 100;

    // Separate arrays for hot data (better cache locality)
    alignas(64) std::array<double, MAX_LEVELS> bid_prices;
    alignas(64) std::array<uint64_t, MAX_LEVELS> bid_quantities;
    alignas(64) std::array<double, MAX_LEVELS> ask_prices;
    alignas(64) std::array<uint64_t, MAX_LEVELS> ask_quantities;

    size_t bid_count = 0;
    size_t ask_count = 0;

public:
    // Hot path: Get best bid/ask (cache-friendly)
    std::pair<double, uint64_t> get_best_bid() const {
        if (bid_count == 0) return {0, 0};
        return {bid_prices[0], bid_quantities[0]};
    }

    std::pair<double, uint64_t> get_best_ask() const {
        if (ask_count == 0) return {0, 0};
        return {ask_prices[0], ask_quantities[0]};
    }

    // Sequential access - prefetch next level
    double get_mid_price() const {
        __builtin_prefetch(&bid_prices[0], 0, 3);
        __builtin_prefetch(&ask_prices[0], 0, 3);

        if (bid_count == 0 || ask_count == 0) return 0;
        return (bid_prices[0] + ask_prices[0]) / 2.0;
    }
};
```

EXAMPLE 2: BRANCHLESS ORDER VALIDATION
---------------------------------------

```cpp
class BranchlessOrderValidator {
public:
    struct ValidationResult {
        bool valid;
        uint32_t error_code;
    };

    // Branchless validation using bitwise operations
    static ValidationResult validate(const Order& order) {
        // Check multiple conditions without branches
        uint32_t errors = 0;

        // Quantity must be > 0 and <= MAX_QTY
        errors |= (order.quantity == 0) << 0;
        errors |= (order.quantity > MAX_QTY) << 1;

        // Price must be > 0 and <= MAX_PRICE
        errors |= (order.price <= 0.0) << 2;
        errors |= (order.price > MAX_PRICE) << 3;

        // Symbol must be non-empty
        errors |= (order.symbol[0] == '\0') << 4;

        // Side must be valid (0 = BUY, 1 = SELL)
        errors |= (order.side > 1) << 5;

        return {errors == 0, errors};
    }

    // Branchless min/max for price bounds
    static double clamp_price(double price, double min, double max) {
        // Branchless clamp
        double t = price < min ? min : price;
        return t > max ? max : t;
        // Compiler generates conditional moves (CMOV)
    }

private:
    static constexpr uint32_t MAX_QTY = 1000000;
    static constexpr double MAX_PRICE = 1000000.0;
};
```

EXAMPLE 3: SIMD-ACCELERATED PRICE CALCULATION
----------------------------------------------

```cpp
#include <immintrin.h>  // AVX2

class SIMDPriceCalculator {
public:
    // Calculate weighted average of 8 prices simultaneously
    static double calculate_vwap_simd(const double* prices,
                                     const uint64_t* quantities,
                                     size_t count) {
        if (count == 0) return 0.0;

        __m256d sum_pq = _mm256_setzero_pd();  // Sum of price * quantity
        __m256d sum_q = _mm256_setzero_pd();   // Sum of quantity

        size_t i = 0;
        // Process 4 elements at a time (AVX2 = 256 bits = 4x double)
        for (; i + 3 < count; i += 4) {
            __m256d p = _mm256_loadu_pd(&prices[i]);

            // Convert uint64 quantities to double
            __m128i q_int = _mm_loadu_si128((__m128i*)&quantities[i]);
            __m256d q = _mm256_cvtepi32_pd(q_int);

            __m256d pq = _mm256_mul_pd(p, q);
            sum_pq = _mm256_add_pd(sum_pq, pq);
            sum_q = _mm256_add_pd(sum_q, q);
        }

        // Horizontal sum
        double total_pq = horizontal_sum(sum_pq);
        double total_q = horizontal_sum(sum_q);

        // Handle remainder
        for (; i < count; ++i) {
            total_pq += prices[i] * quantities[i];
            total_q += quantities[i];
        }

        return total_q > 0 ? total_pq / total_q : 0.0;
    }

private:
    static double horizontal_sum(__m256d v) {
        __m128d low = _mm256_castpd256_pd128(v);
        __m128d high = _mm256_extractf128_pd(v, 1);
        __m128d sum = _mm_add_pd(low, high);
        __m128d shuf = _mm_shuffle_pd(sum, sum, 1);
        sum = _mm_add_sd(sum, shuf);
        return _mm_cvtsd_f64(sum);
    }
};
```

EXAMPLE 4: LOCK-FREE CIRCULAR BUFFER
-------------------------------------

```cpp
#include <atomic>
#include <array>

template<typename T, size_t Size>
class LockFreeCircularBuffer {
    static_assert((Size & (Size - 1)) == 0, "Size must be power of 2");

    alignas(64) std::array<T, Size> buffer;
    alignas(64) std::atomic<size_t> write_pos{0};
    alignas(64) std::atomic<size_t> read_pos{0};

public:
    bool try_push(const T& item) {
        size_t write = write_pos.load(std::memory_order_relaxed);
        size_t next_write = (write + 1) & (Size - 1);

        if (next_write == read_pos.load(std::memory_order_acquire)) {
            return false;  // Full
        }

        buffer[write] = item;
        write_pos.store(next_write, std::memory_order_release);
        return true;
    }

    bool try_pop(T& item) {
        size_t read = read_pos.load(std::memory_order_relaxed);

        if (read == write_pos.load(std::memory_order_acquire)) {
            return false;  // Empty
        }

        item = buffer[read];
        read_pos.store((read + 1) & (Size - 1), std::memory_order_release);
        return true;
    }

    bool empty() const {
        return read_pos.load(std::memory_order_acquire) ==
               write_pos.load(std::memory_order_acquire);
    }

    size_t size() const {
        size_t write = write_pos.load(std::memory_order_acquire);
        size_t read = read_pos.load(std::memory_order_acquire);
        return (write - read) & (Size - 1);
    }
};
```

EXAMPLE 5: PERFORMANCE BENCHMARK HARNESS
-----------------------------------------

```cpp
#include <chrono>
#include <vector>
#include <algorithm>

class BenchmarkHarness {
public:
    template<typename Func>
    static void benchmark(const std::string& name, Func&& func,
                         size_t iterations = 1000000) {
        std::vector<uint64_t> samples;
        samples.reserve(iterations);

        // Warmup
        for (size_t i = 0; i < 1000; ++i) {
            func();
        }

        // Measure
        for (size_t i = 0; i < iterations; ++i) {
            uint64_t start = __rdtsc();
            func();
            uint64_t end = __rdtsc();
            samples.push_back(end - start);
        }

        // Analyze
        std::sort(samples.begin(), samples.end());

        uint64_t min = samples.front();
        uint64_t p50 = samples[iterations / 2];
        uint64_t p90 = samples[iterations * 90 / 100];
        uint64_t p99 = samples[iterations * 99 / 100];
        uint64_t max = samples.back();

        uint64_t sum = 0;
        for (uint64_t s : samples) sum += s;
        double mean = (double)sum / iterations;

        std::cout << "Benchmark: " << name << "\n"
                  << "  Iterations: " << iterations << "\n"
                  << "  Min:  " << min << " cycles\n"
                  << "  Mean: " << (uint64_t)mean << " cycles\n"
                  << "  P50:  " << p50 << " cycles\n"
                  << "  P90:  " << p90 << " cycles\n"
                  << "  P99:  " << p99 << " cycles\n"
                  << "  Max:  " << max << " cycles\n\n";
    }
};

// Usage
void benchmark_order_validation() {
    Order order = {/* ... */};

    BenchmarkHarness::benchmark("OrderValidation", [&]() {
        BranchlessOrderValidator::validate(order);
    });
}
```

================================================================================
8. DEBUGGING COMMANDS AND INTERPRETATION
================================================================================

PERF STAT COMMANDS
------------------

Basic performance counters:
```bash
perf stat ./program
```

Detailed counters:
```bash
perf stat -e cycles,instructions,cache-references,cache-misses,\
           branches,branch-misses,L1-dcache-loads,L1-dcache-load-misses,\
           LLC-loads,LLC-load-misses,dTLB-loads,dTLB-load-misses \
           ./program
```

Per-core statistics:
```bash
perf stat -a -A -e cycles,instructions -- sleep 10
```

PERF RECORD COMMANDS
--------------------

Record with call graph:
```bash
perf record -g -F 9999 ./program
```

Record specific events:
```bash
perf record -e cache-misses -g ./program
```

Record all CPUs:
```bash
perf record -a -g ./program
```

PERF REPORT COMMANDS
--------------------

Text report:
```bash
perf report --stdio --no-children
```

Show source annotations:
```bash
perf annotate --stdio function_name
```

Show caller/callee:
```bash
perf report --stdio -g caller  # Or -g callee
```

PERF TOP COMMAND
----------------

Live profiling:
```bash
perf top -g
```

Monitor specific process:
```bash
perf top -p $(pidof trading_engine)
```

COMPILATION FLAGS FOR DEBUGGING
--------------------------------

Debug symbols:
```bash
g++ -g program.cpp
```

Optimization with debug info:
```bash
g++ -O3 -g -fno-omit-frame-pointer program.cpp
```

Assembly output:
```bash
g++ -S -O3 program.cpp -o program.s
```

Vectorization report:
```bash
g++ -O3 -ftree-vectorize -fopt-info-vec program.cpp
```

================================================================================
9. SOLUTIONS AND FIXES
================================================================================

SOLUTION 1: FIX CACHE THRASHING
--------------------------------

Problem: Frequent cache misses due to poor data layout

Before:
```cpp
struct Order {
    std::string symbol;  // Heap allocation
    uint64_t id;
    double price;
    std::vector<uint32_t> fills;  // Heap allocation
    uint32_t quantity;
};
```

After:
```cpp
struct Order {
    // Hot data first, cache-aligned
    uint64_t id;
    double price;
    uint32_t quantity;
    char symbol[8];  // Inline

    // Cold data can go on separate cache line
    alignas(64) uint64_t timestamp;
    // ... other cold fields ...
} __attribute__((aligned(64)));
```

SOLUTION 2: FIX BRANCH MISPREDICTIONS
--------------------------------------

Problem: Unpredictable branches in hot path

Before:
```cpp
double calculate_fee(OrderType type, uint32_t quantity) {
    if (type == MARKET) {
        if (quantity < 100) {
            return quantity * 0.001;
        } else {
            return quantity * 0.0008;
        }
    } else if (type == LIMIT) {
        if (quantity < 100) {
            return quantity * 0.0005;
        } else {
            return quantity * 0.0004;
        }
    }
    return 0;
}
```

After:
```cpp
static const double FEE_TABLE[2][2] = {
    {0.001, 0.0008},   // MARKET
    {0.0005, 0.0004}   // LIMIT
};

double calculate_fee(OrderType type, uint32_t quantity) {
    int qty_bracket = (quantity >= 100);
    return quantity * FEE_TABLE[type][qty_bracket];
}
```

SOLUTION 3: FIX LOW IPC (DEPENDENCY CHAINS)
--------------------------------------------

Problem: Serial dependencies prevent parallelism

Before:
```cpp
double sum = 0;
for (int i = 0; i < N; ++i) {
    sum += data[i];  // Dependency chain
}
```

After:
```cpp
// Unroll with multiple accumulators
double sum0 = 0, sum1 = 0, sum2 = 0, sum3 = 0;
for (int i = 0; i < N; i += 4) {
    sum0 += data[i];
    sum1 += data[i + 1];
    sum2 += data[i + 2];
    sum3 += data[i + 3];
}
double sum = sum0 + sum1 + sum2 + sum3;
```

SOLUTION 4: OPTIMIZE VIRTUAL CALLS
-----------------------------------

Problem: Virtual function call overhead

Before:
```cpp
class Handler {
public:
    virtual void process(const Message& msg) = 0;
};

Handler* handler = get_handler();
handler->process(msg);  // Virtual call overhead
```

After (Template-based):
```cpp
template<typename HandlerT>
void process_with_handler(HandlerT& handler, const Message& msg) {
    handler.process(msg);  // Direct call, can be inlined
}
```

After (Function pointer table):
```cpp
using ProcessFunc = void (*)(const Message&);
ProcessFunc handlers[NUM_MESSAGE_TYPES] = {
    process_quote,
    process_trade,
    // ...
};

handlers[msg.type](msg);  // Direct call, no virtual dispatch
```

================================================================================
10. BEST PRACTICES FOR HFT PERFORMANCE
================================================================================

1. MEASURE BEFORE OPTIMIZING
   - Profile to find actual bottlenecks
   - Don't guess, measure
   - Focus on hot paths (80/20 rule)

2. OPTIMIZE DATA LAYOUT
   - Align to cache lines (64 bytes)
   - Keep hot data together
   - Separate hot and cold data
   - Use contiguous containers

3. MINIMIZE BRANCHES
   - Use lookup tables
   - Branchless algorithms
   - likely/unlikely hints
   - Reorder conditions (common cases first)

4. MAXIMIZE CACHE EFFICIENCY
   - Sequential memory access
   - Prefetch predictable accesses
   - Avoid pointer chasing
   - Reduce working set size

5. ENABLE COMPILER OPTIMIZATIONS
   ```bash
   g++ -O3 -march=native -mtune=native -flto \
       -ffast-math -funroll-loops \
       -fomit-frame-pointer program.cpp
   ```

6. USE SIMD WHEN APPLICABLE
   - Batch operations
   - Parallel calculations
   - AVX/AVX2/AVX-512 intrinsics

7. REDUCE FUNCTION CALL OVERHEAD
   - Inline small functions
   - Avoid virtual calls in hot path
   - Use templates for compile-time polymorphism

8. CONTINUOUS BENCHMARKING
   - Automated performance regression tests
   - Track key metrics over time
   - Alert on degradation

9. PROFILE REGULARLY
   - Weekly perf analysis
   - Compare against baseline
   - Look for new hotspots

10. DOCUMENT OPTIMIZATIONS
    - Explain non-obvious optimizations
    - Record benchmark results
    - Note tradeoffs made

================================================================================
END OF PERFORMANCE DEBUGGING GUIDE
================================================================================
