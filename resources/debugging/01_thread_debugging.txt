================================================================================
                    HFT THREAD DEBUGGING GUIDE
================================================================================

TABLE OF CONTENTS
-----------------
1. Theory and Common Issues in HFT Threading
2. Thread Debugging Tools
3. Race Condition Detection
4. Deadlock Detection and Prevention
5. Thread Synchronization Issues
6. Step-by-Step Debugging Workflows
7. Real HFT C++ Code Examples
8. Debugging Commands and Interpretation
9. Solutions and Fixes
10. Best Practices for HFT Threading

================================================================================
1. THEORY AND COMMON ISSUES IN HFT THREADING
================================================================================

OVERVIEW
--------
In HFT systems, threading issues can cause:
- Non-deterministic behavior in order execution
- Sporadic crashes that are hard to reproduce
- Data corruption leading to incorrect trading decisions
- Performance degradation due to contention
- Missed market opportunities due to deadlocks

COMMON THREADING ISSUES IN HFT
-------------------------------

A) Race Conditions
   - Multiple threads accessing shared order book data
   - Concurrent updates to position tracking
   - Signal generation vs order execution race
   - Market data updates vs pricing calculations

B) Deadlocks
   - Lock ordering issues in multi-asset trading
   - Circular dependencies in risk management
   - Thread waiting on its own lock (recursive deadlock)
   - Resource starvation in priority-based systems

C) Thread Synchronization
   - Lost updates in shared state
   - ABA problems in lock-free structures
   - Memory ordering issues on weak architectures
   - Cache coherency delays

D) Priority Inversion
   - Low priority thread holding lock needed by high priority thread
   - Bounded priority inversion in real-time systems
   - Unbounded priority inversion causing latency spikes

================================================================================
2. THREAD DEBUGGING TOOLS
================================================================================

ESSENTIAL TOOLS FOR HFT THREAD DEBUGGING
-----------------------------------------

1. HELGRIND (Valgrind Thread Checker)
   Purpose: Detect race conditions and lock ordering issues
   Command: valgrind --tool=helgrind ./trading_engine

   Pros:
   - Detects potential race conditions
   - Identifies lock ordering problems
   - No code modification needed

   Cons:
   - Extreme slowdown (100-200x)
   - Not suitable for production
   - May produce false positives

2. DRD (Data Race Detector)
   Purpose: Lighter alternative to Helgrind
   Command: valgrind --tool=drd ./trading_engine

   Pros:
   - Less memory overhead than Helgrind
   - Better performance
   - Fewer false positives

   Cons:
   - Still too slow for HFT performance testing
   - Cannot detect all race conditions

3. ThreadSanitizer (TSan)
   Purpose: Fast race detection with compiler integration
   Compile: g++ -g -fsanitize=thread -fPIE -pie program.cpp

   Pros:
   - Much faster than Valgrind tools (2-20x slowdown)
   - Excellent accuracy
   - Integrates with GCC/Clang

   Cons:
   - Requires recompilation
   - Memory overhead
   - Cannot use with other sanitizers

4. GDB with Thread Support
   Purpose: Interactive debugging of thread issues
   Commands:
   - info threads
   - thread <n>
   - thread apply all bt
   - set scheduler-locking on/off

5. Intel Inspector
   Purpose: Commercial thread analysis tool
   Better performance than open-source alternatives
   GUI interface for visualization

6. perf with Thread Analysis
   Command: perf record -e sched:* ./trading_engine
   Purpose: Analyze thread scheduling and context switches

================================================================================
3. RACE CONDITION DETECTION
================================================================================

TYPES OF RACE CONDITIONS IN HFT
--------------------------------

A) DATA RACE
   Two threads access same memory, at least one writes, no synchronization

B) ORDER RACE
   Execution order affects correctness (even with synchronization)

C) READ-MODIFY-WRITE RACE
   Non-atomic compound operations

DETECTION TECHNIQUES
--------------------

1. STATIC ANALYSIS
   Tools: Clang Static Analyzer, Coverity

   Command:
   clang++ --analyze -Xanalyzer -analyzer-output=text program.cpp

2. DYNAMIC ANALYSIS WITH TSAN

   Example Code with Race:
   ```cpp
   // order_manager.cpp - BUGGY CODE
   class OrderManager {
       int64_t order_count = 0;  // RACE CONDITION!

   public:
       void submit_order() {
           order_count++;  // NOT ATOMIC
       }

       int64_t get_count() {
           return order_count;  // RACE
       }
   };
   ```

   Compile and Run:
   g++ -g -fsanitize=thread -fPIE -pie order_manager.cpp -o order_mgr
   ./order_mgr

   TSan Output:
   ==================
   WARNING: ThreadSanitizer: data race (pid=12345)
     Write of size 8 at 0x7b0000000000 by thread T1:
       #0 OrderManager::submit_order() order_manager.cpp:7

     Previous read of size 8 at 0x7b0000000000 by thread T2:
       #0 OrderManager::get_count() order_manager.cpp:11

   SUMMARY: ThreadSanitizer: data race order_manager.cpp:7
   ==================

3. RUNTIME ASSERTIONS

   Example:
   ```cpp
   #include <mutex>
   #include <cassert>

   class SafeOrderManager {
       std::mutex mtx;
       int64_t order_count = 0;

   public:
       void submit_order() {
           std::lock_guard<std::mutex> lock(mtx);
           order_count++;
       }

       int64_t get_count() {
           std::lock_guard<std::mutex> lock(mtx);
           return order_count;
       }

       // Debug assertion - check invariants
       void verify_invariants() {
           assert(order_count >= 0);
           assert(mtx.try_lock() == false);  // Should be locked
       }
   };
   ```

================================================================================
4. DEADLOCK DETECTION AND PREVENTION
================================================================================

COMMON DEADLOCK SCENARIOS IN HFT
---------------------------------

Scenario 1: Lock Ordering Deadlock
```cpp
// BUGGY CODE - Deadlock possible
class TradingSystem {
    std::mutex order_mutex;
    std::mutex position_mutex;

    void update_order_and_position() {
        std::lock_guard<std::mutex> lock1(order_mutex);
        // ... process order ...
        std::lock_guard<std::mutex> lock2(position_mutex);
        // ... update position ...
    }

    void update_position_and_order() {
        std::lock_guard<std::mutex> lock1(position_mutex);  // WRONG ORDER!
        // ... process position ...
        std::lock_guard<std::mutex> lock2(order_mutex);
        // ... update order ...
    }
};
```

GDB DEADLOCK DETECTION
-----------------------

Commands:
1. Attach to hung process:
   gdb -p <pid>

2. List all threads:
   (gdb) info threads

   Output:
   * 1    Thread 0x7f1234 (LWP 12345) 0x00007f in __lll_lock_wait()
     2    Thread 0x7f5678 (LWP 12346) 0x00007f in __lll_lock_wait()

3. Get all thread backtraces:
   (gdb) thread apply all bt

   Thread 1 (Thread 0x7f1234):
   #0  __lll_lock_wait() at lowlevellock.S:135
   #1  pthread_mutex_lock() at pthread_mutex_lock.c:80
   #2  update_order_and_position() at trading.cpp:45

   Thread 2 (Thread 0x7f5678):
   #0  __lll_lock_wait() at lowlevellock.S:135
   #1  pthread_mutex_lock() at pthread_mutex_lock.c:80
   #2  update_position_and_order() at trading.cpp:55

4. Examine mutex state:
   (gdb) p order_mutex
   (gdb) p position_mutex

DEADLOCK PREVENTION TECHNIQUES
-------------------------------

1. LOCK ORDERING (std::scoped_lock in C++17)
```cpp
class TradingSystem {
    std::mutex order_mutex;
    std::mutex position_mutex;

    void safe_update() {
        // Locks both in consistent order
        std::scoped_lock lock(order_mutex, position_mutex);
        // ... safe operations ...
    }
};
```

2. TRY-LOCK PATTERN
```cpp
void try_lock_update() {
    std::unique_lock<std::mutex> lock1(order_mutex, std::defer_lock);
    std::unique_lock<std::mutex> lock2(position_mutex, std::defer_lock);

    if (std::try_lock(lock1, lock2) == -1) {
        // Successfully locked both
        // ... perform update ...
    } else {
        // Could not acquire locks, retry or fail gracefully
    }
}
```

3. TIMEOUT-BASED LOCKING
```cpp
bool timed_update() {
    std::unique_lock<std::timed_mutex> lock1(order_mutex, std::defer_lock);
    std::unique_lock<std::timed_mutex> lock2(position_mutex, std::defer_lock);

    if (std::try_lock(lock1, lock2) == -1) {
        return true;
    }

    // Timeout after 100 microseconds
    auto timeout = std::chrono::microseconds(100);
    if (lock1.try_lock_for(timeout) && lock2.try_lock_for(timeout)) {
        return true;
    }
    return false;
}
```

HELGRIND DEADLOCK DETECTION
----------------------------

Command:
valgrind --tool=helgrind --trace-children=yes ./trading_engine

Output:
Thread #1: lock order "0x602080 before 0x602100" violated
Thread #2: lock order "0x602100 before 0x602080" violated
   Possible deadlock detected

================================================================================
5. THREAD SYNCHRONIZATION ISSUES
================================================================================

MEMORY ORDERING PROBLEMS
-------------------------

Problem: Weak memory models allow reordering

Example - BUGGY CODE:
```cpp
// Producer-Consumer without proper synchronization
class MarketDataQueue {
    std::array<Quote, 1000> buffer;
    int write_pos = 0;
    bool data_ready = false;  // NO SYNCHRONIZATION!

    // Producer thread
    void produce(const Quote& q) {
        buffer[write_pos] = q;
        write_pos++;
        data_ready = true;  // May be reordered!
    }

    // Consumer thread
    Quote consume() {
        while (!data_ready) {}  // Spin wait - BUGGY!
        return buffer[write_pos - 1];
    }
};
```

CORRECT IMPLEMENTATION - ATOMIC OPERATIONS
-------------------------------------------

```cpp
#include <atomic>
#include <array>

class MarketDataQueue {
    std::array<Quote, 1000> buffer;
    std::atomic<int> write_pos{0};
    std::atomic<bool> data_ready{false};

    // Producer thread
    void produce(const Quote& q) {
        int pos = write_pos.load(std::memory_order_acquire);
        buffer[pos] = q;
        write_pos.store(pos + 1, std::memory_order_release);
        data_ready.store(true, std::memory_order_release);
    }

    // Consumer thread
    Quote consume() {
        while (!data_ready.load(std::memory_order_acquire)) {
            _mm_pause();  // CPU hint for spin-wait
        }
        int pos = write_pos.load(std::memory_order_acquire);
        return buffer[pos - 1];
    }
};
```

LOCK-FREE QUEUE - PRODUCTION HFT EXAMPLE
-----------------------------------------

```cpp
#include <atomic>
#include <array>

template<typename T, size_t Size>
class SPSCQueue {  // Single Producer Single Consumer
    std::array<T, Size> buffer;
    alignas(64) std::atomic<size_t> write_pos{0};
    alignas(64) std::atomic<size_t> read_pos{0};

public:
    bool try_push(const T& item) {
        size_t current_write = write_pos.load(std::memory_order_relaxed);
        size_t next_write = (current_write + 1) % Size;

        if (next_write == read_pos.load(std::memory_order_acquire)) {
            return false;  // Queue full
        }

        buffer[current_write] = item;
        write_pos.store(next_write, std::memory_order_release);
        return true;
    }

    bool try_pop(T& item) {
        size_t current_read = read_pos.load(std::memory_order_relaxed);

        if (current_read == write_pos.load(std::memory_order_acquire)) {
            return false;  // Queue empty
        }

        item = buffer[current_read];
        read_pos.store((current_read + 1) % Size, std::memory_order_release);
        return true;
    }
};
```

DEBUGGING MEMORY ORDERING ISSUES
---------------------------------

1. Use TSan with memory ordering checks:
   g++ -g -fsanitize=thread -fPIE -pie -O2 queue.cpp

2. Enable strict memory ordering (debug only):
   Add memory fences: std::atomic_thread_fence(std::memory_order_seq_cst);

3. Use hardware performance counters:
   perf stat -e cpu/event=0x05,umask=0x01/ ./program  # Memory ordering violations

================================================================================
6. STEP-BY-STEP DEBUGGING WORKFLOWS
================================================================================

WORKFLOW 1: INVESTIGATING SPORADIC CRASHES
-------------------------------------------

Step 1: Enable Core Dumps
ulimit -c unlimited
echo "/tmp/cores/core.%e.%p.%t" | sudo tee /proc/sys/kernel/core_pattern

Step 2: Run with TSan
g++ -g -fsanitize=thread -fPIE -pie trading_system.cpp -o trading_system
./trading_system

Step 3: Analyze TSan Output
Look for:
- Data race warnings
- Lock order inversions
- Mutex usage issues

Step 4: Reproduce with GDB
gdb ./trading_system
(gdb) set scheduler-locking off
(gdb) break suspicious_function
(gdb) run
(gdb) thread apply all bt

Step 5: Add Instrumentation
```cpp
#define DEBUG_THREAD 1

#ifdef DEBUG_THREAD
#include <sstream>
#include <iostream>
#include <thread>

#define LOG_THREAD(msg) do { \
    std::ostringstream oss; \
    oss << "[Thread " << std::this_thread::get_id() << "] " << msg << "\n"; \
    std::cout << oss.str(); \
} while(0)
#else
#define LOG_THREAD(msg)
#endif

void critical_section() {
    LOG_THREAD("Entering critical section");
    // ... operations ...
    LOG_THREAD("Exiting critical section");
}
```

WORKFLOW 2: DEADLOCK INVESTIGATION
-----------------------------------

Step 1: Identify Hang
ps aux | grep trading_engine
top -H -p <pid>  # Check if threads are stuck

Step 2: Attach Debugger
gdb -p <pid>

Step 3: Examine All Threads
(gdb) info threads
(gdb) thread apply all bt full

Step 4: Identify Locks
(gdb) thread 1
(gdb) frame 2
(gdb) info locals
(gdb) p mutex_variable

Step 5: Check Lock Ownership
Use pstack or gdb to see which thread holds which lock

Step 6: Generate Deadlock Graph
Document lock acquisition order from backtraces

WORKFLOW 3: RACE CONDITION HUNT
--------------------------------

Step 1: Run Stress Test
```cpp
// stress_test.cpp
for (int i = 0; i < 1000000; ++i) {
    // Perform racy operation
}
```

Step 2: Run with Helgrind/TSan
valgrind --tool=helgrind --log-file=helgrind.log ./stress_test

Step 3: Analyze Results
grep "Possible data race" helgrind.log
grep "WARNING: ThreadSanitizer" tsan.log

Step 4: Add Assertions
```cpp
std::atomic<int> debug_lock_count{0};

void lock_function() {
    debug_lock_count++;
    assert(debug_lock_count == 1);  // Only one thread should be here
    // ... critical section ...
    debug_lock_count--;
}
```

Step 5: Use Hardware Watchpoints
(gdb) watch shared_variable
(gdb) continue

================================================================================
7. REAL HFT C++ CODE EXAMPLES
================================================================================

EXAMPLE 1: ORDER BOOK WITH THREAD-SAFE UPDATES
-----------------------------------------------

```cpp
#include <mutex>
#include <shared_mutex>
#include <map>
#include <atomic>

struct PriceLevel {
    double price;
    uint64_t quantity;
    uint32_t order_count;
};

class OrderBook {
    // Separate locks for bids and asks to reduce contention
    mutable std::shared_mutex bid_mutex;
    mutable std::shared_mutex ask_mutex;

    std::map<double, PriceLevel> bids;  // Price -> Level
    std::map<double, PriceLevel> asks;

    std::atomic<uint64_t> update_sequence{0};

public:
    // Writer - exclusive lock
    void add_bid(double price, uint64_t qty) {
        std::unique_lock<std::shared_mutex> lock(bid_mutex);

        auto& level = bids[price];
        level.price = price;
        level.quantity += qty;
        level.order_count++;

        update_sequence.fetch_add(1, std::memory_order_release);
    }

    // Reader - shared lock (multiple readers allowed)
    std::optional<PriceLevel> get_best_bid() const {
        std::shared_lock<std::shared_mutex> lock(bid_mutex);

        if (bids.empty()) return std::nullopt;
        return bids.rbegin()->second;  // Highest bid
    }

    // Lock-free sequence number for fast checking
    uint64_t get_sequence() const {
        return update_sequence.load(std::memory_order_acquire);
    }

    // Multiple locks - use std::scoped_lock to prevent deadlock
    double get_spread() const {
        std::scoped_lock lock(bid_mutex, ask_mutex);

        if (bids.empty() || asks.empty()) return 0.0;

        double best_bid = bids.rbegin()->first;
        double best_ask = asks.begin()->first;
        return best_ask - best_bid;
    }
};
```

EXAMPLE 2: THREAD-SAFE RISK MANAGER
------------------------------------

```cpp
#include <atomic>
#include <mutex>
#include <unordered_map>

class RiskManager {
    struct SymbolRisk {
        std::atomic<int64_t> position{0};
        std::atomic<double> unrealized_pnl{0.0};
        int64_t max_position;
        double max_loss;
    };

    std::unordered_map<std::string, SymbolRisk> risks;
    mutable std::shared_mutex risk_mutex;

public:
    bool check_and_update_position(const std::string& symbol,
                                   int64_t delta) {
        // Read lock first for check
        {
            std::shared_lock<std::shared_mutex> lock(risk_mutex);
            auto it = risks.find(symbol);
            if (it == risks.end()) return false;

            int64_t current = it->second.position.load(std::memory_order_acquire);
            int64_t new_pos = current + delta;

            // Fast path - no violation
            if (std::abs(new_pos) <= it->second.max_position) {
                // Atomic update without write lock
                it->second.position.fetch_add(delta, std::memory_order_release);
                return true;
            }
        }

        // Slow path - need write lock for violation handling
        std::unique_lock<std::shared_mutex> lock(risk_mutex);
        return false;  // Reject trade
    }

    void update_pnl(const std::string& symbol, double pnl_delta) {
        std::shared_lock<std::shared_mutex> lock(risk_mutex);
        auto it = risks.find(symbol);
        if (it != risks.end()) {
            // Lock-free atomic update
            double current = it->second.unrealized_pnl.load(std::memory_order_relaxed);
            double new_pnl = current + pnl_delta;
            it->second.unrealized_pnl.store(new_pnl, std::memory_order_release);
        }
    }
};
```

EXAMPLE 3: LOCK-FREE MARKET DATA HANDLER
-----------------------------------------

```cpp
#include <atomic>
#include <array>

struct MarketDataUpdate {
    uint64_t timestamp;
    char symbol[8];
    double bid;
    double ask;
    uint32_t bid_size;
    uint32_t ask_size;
};

class MarketDataHandler {
    static constexpr size_t QUEUE_SIZE = 65536;  // Power of 2

    std::array<MarketDataUpdate, QUEUE_SIZE> buffer;

    // Cache line aligned atomics to prevent false sharing
    alignas(64) std::atomic<uint64_t> write_index{0};
    alignas(64) std::atomic<uint64_t> read_index{0};

public:
    // Producer (market data thread)
    bool push(const MarketDataUpdate& update) {
        uint64_t current_write = write_index.load(std::memory_order_relaxed);
        uint64_t next_write = current_write + 1;

        // Check if queue is full
        uint64_t current_read = read_index.load(std::memory_order_acquire);
        if (next_write - current_read >= QUEUE_SIZE) {
            return false;  // Queue full - DROP or handle
        }

        // Write data
        buffer[current_write & (QUEUE_SIZE - 1)] = update;

        // Publish write
        write_index.store(next_write, std::memory_order_release);
        return true;
    }

    // Consumer (strategy thread)
    bool pop(MarketDataUpdate& update) {
        uint64_t current_read = read_index.load(std::memory_order_relaxed);

        // Check if queue is empty
        uint64_t current_write = write_index.load(std::memory_order_acquire);
        if (current_read == current_write) {
            return false;  // Queue empty
        }

        // Read data
        update = buffer[current_read & (QUEUE_SIZE - 1)];

        // Publish read
        read_index.store(current_read + 1, std::memory_order_release);
        return true;
    }

    size_t size() const {
        uint64_t w = write_index.load(std::memory_order_acquire);
        uint64_t r = read_index.load(std::memory_order_acquire);
        return w - r;
    }
};
```

================================================================================
8. DEBUGGING COMMANDS AND INTERPRETATION
================================================================================

GDB THREAD DEBUGGING COMMANDS
------------------------------

1. List Threads:
   (gdb) info threads

   Output:
   * 1    Thread 0x7ffff7fc0740 (LWP 12345) "trading_engine"
     2    Thread 0x7ffff6fbf700 (LWP 12346) "md_handler"
     3    Thread 0x7ffff67be700 (LWP 12347) "order_gateway"

   * indicates current thread

2. Switch Thread:
   (gdb) thread 2
   [Switching to thread 2 (Thread 0x7ffff6fbf700)]

3. Apply Command to All Threads:
   (gdb) thread apply all bt
   (gdb) thread apply all info registers
   (gdb) thread apply 1-3 print variable

4. Thread-Specific Breakpoints:
   (gdb) break trading.cpp:100 thread 2
   (gdb) break trading.cpp:200 if thread_id == 3

5. Scheduler Locking:
   (gdb) set scheduler-locking on    # Only current thread runs
   (gdb) set scheduler-locking off   # All threads run
   (gdb) set scheduler-locking step  # Only current thread steps

PERF THREAD ANALYSIS COMMANDS
------------------------------

1. Record Thread Context Switches:
   perf record -e sched:sched_switch -g -p <pid>
   perf script | head -100

2. Analyze Lock Contention:
   perf record -e syscalls:sys_enter_futex -ag -p <pid>
   perf report

3. Monitor Thread Migration:
   perf stat -e migrations -p <pid> sleep 10

STRACE THREAD TRACKING
-----------------------

Command:
strace -f -e trace=futex,clone -p <pid> 2>&1 | grep -E "(futex|clone)"

Output Analysis:
[pid 12345] futex(0x7f1234, FUTEX_WAIT_PRIVATE, 2, NULL) = 0
[pid 12346] futex(0x7f1234, FUTEX_WAKE_PRIVATE, 1) = 1

PSTACK COMMAND
--------------

Command: pstack <pid>

Output:
Thread 3 (Thread 0x7f1234):
#0  0x00007f in __lll_lock_wait ()
#1  0x00007f in pthread_mutex_lock ()
#2  0x000001 in OrderBook::add_order() at orderbook.cpp:45

================================================================================
9. SOLUTIONS AND FIXES
================================================================================

SOLUTION 1: FIX RACE CONDITION IN ORDER COUNTER
------------------------------------------------

BEFORE (BUGGY):
```cpp
class OrderManager {
    uint64_t order_count = 0;

    uint64_t get_next_id() {
        return order_count++;  // RACE!
    }
};
```

AFTER (FIXED):
```cpp
class OrderManager {
    std::atomic<uint64_t> order_count{0};

    uint64_t get_next_id() {
        return order_count.fetch_add(1, std::memory_order_relaxed);
    }
};
```

SOLUTION 2: FIX DEADLOCK IN MULTI-ASSET TRADING
------------------------------------------------

BEFORE (BUGGY):
```cpp
void transfer(Account& from, Account& to, double amount) {
    std::lock_guard<std::mutex> lock1(from.mutex);
    std::lock_guard<std::mutex> lock2(to.mutex);  // May deadlock
    from.balance -= amount;
    to.balance += amount;
}
```

AFTER (FIXED):
```cpp
void transfer(Account& from, Account& to, double amount) {
    // Lock in consistent order based on address
    if (&from < &to) {
        std::scoped_lock lock(from.mutex, to.mutex);
        from.balance -= amount;
        to.balance += amount;
    } else {
        std::scoped_lock lock(to.mutex, from.mutex);
        from.balance -= amount;
        to.balance += amount;
    }
}
```

SOLUTION 3: FIX MEMORY ORDERING IN LOCK-FREE CODE
--------------------------------------------------

BEFORE (BUGGY):
```cpp
std::atomic<bool> ready{false};
int data;

// Thread 1
void producer() {
    data = 42;
    ready = true;  // Wrong memory order
}

// Thread 2
void consumer() {
    while (!ready) {}
    std::cout << data;  // May print garbage
}
```

AFTER (FIXED):
```cpp
std::atomic<bool> ready{false};
int data;

// Thread 1
void producer() {
    data = 42;
    ready.store(true, std::memory_order_release);  // Ensure data write visible
}

// Thread 2
void consumer() {
    while (!ready.load(std::memory_order_acquire)) {
        _mm_pause();
    }
    std::cout << data;  // Guaranteed to see 42
}
```

SOLUTION 4: FIX FALSE SHARING
------------------------------

BEFORE (BUGGY):
```cpp
struct ThreadData {
    std::atomic<uint64_t> counter1{0};  // Cache line shared!
    std::atomic<uint64_t> counter2{0};
};
```

AFTER (FIXED):
```cpp
struct alignas(64) ThreadData {
    std::atomic<uint64_t> counter1{0};
    char padding1[56];  // Pad to 64 bytes
    std::atomic<uint64_t> counter2{0};
    char padding2[56];
};

// Or use alignas on members
struct ThreadData {
    alignas(64) std::atomic<uint64_t> counter1{0};
    alignas(64) std::atomic<uint64_t> counter2{0};
};
```

================================================================================
10. BEST PRACTICES FOR HFT THREADING
================================================================================

1. MINIMIZE LOCK SCOPE
   Bad:
   ```cpp
   std::lock_guard<std::mutex> lock(mtx);
   auto data = fetch_data();  // Long operation
   process(data);
   ```

   Good:
   ```cpp
   auto data = fetch_data();  // Outside lock
   {
       std::lock_guard<std::mutex> lock(mtx);
       process(data);  // Only locked operation
   }
   ```

2. USE LOCK-FREE STRUCTURES WHERE POSSIBLE
   - Single Producer Single Consumer queues
   - Atomic counters and flags
   - RCU (Read-Copy-Update) for read-heavy workloads

3. AVOID LOCKS IN HOT PATH
   - Pre-allocate resources
   - Use thread-local storage
   - Employ wait-free algorithms for critical paths

4. PIN THREADS TO CORES
   ```cpp
   void pin_thread_to_core(int core_id) {
       cpu_set_t cpuset;
       CPU_ZERO(&cpuset);
       CPU_SET(core_id, &cpuset);
       pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);
   }
   ```

5. USE PROPER MEMORY ORDERING
   - relaxed: No synchronization (counters)
   - acquire/release: Synchronization without seq_cst cost
   - seq_cst: Only when necessary (rare in HFT)

6. PREVENT FALSE SHARING
   - Align shared atomics to cache line (64 bytes)
   - Keep thread-local data separate
   - Use padding between frequently written variables

7. MONITOR THREAD PERFORMANCE
   ```cpp
   // Instrument context switches
   auto start = std::chrono::high_resolution_clock::now();
   // ... operation ...
   auto end = std::chrono::high_resolution_clock::now();
   auto duration = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start);

   if (duration.count() > EXPECTED_NS) {
       // Log potential context switch or contention
   }
   ```

8. TEST UNDER STRESS
   - Run with more threads than cores
   - Simulate production load patterns
   - Use chaos engineering techniques

9. DOCUMENT LOCK ORDERING
   ```cpp
   // Lock order: position_mutex -> order_mutex -> market_data_mutex
   // NEVER acquire in different order
   ```

10. USE RAII FOR LOCK MANAGEMENT
    Always use std::lock_guard, std::unique_lock, std::scoped_lock
    Never call lock()/unlock() directly

================================================================================
END OF THREAD DEBUGGING GUIDE
================================================================================
