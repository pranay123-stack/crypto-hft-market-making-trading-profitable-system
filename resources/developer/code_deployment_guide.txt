================================================================================
                      CODE DEPLOYMENT GUIDE
================================================================================
Version: 3.2.1
Last Updated: 2025-11-25
Owner: DevOps Team
Maintainers: Bob Johnson, DevOps Engineers

================================================================================
SECTION 1: OVERVIEW
================================================================================

This guide provides step-by-step instructions for deploying code to various
environments. Follow these procedures for safe, reliable deployments.

DEPLOYMENT TYPES:
1. Development Deployment: Developer workstations and shared dev servers
2. Staging Deployment: Pre-production testing environment
3. Production Deployment: Live trading systems
4. Hotfix Deployment: Emergency production fixes

DEPLOYMENT FREQUENCY:
- Development: Continuous (multiple times daily)
- Staging: Daily (after CI passes)
- Production: Weekly (Tuesdays or Thursdays)
- Hotfix: As needed (emergency only)

ENVIRONMENTS:
Development:
    - Purpose: Feature development and initial testing
    - Stability: Unstable, frequent changes
    - Data: Synthetic/test data
    - Monitoring: Basic

Staging:
    - Purpose: Pre-production testing and validation
    - Stability: Stable, mirrors production
    - Data: Anonymized production data
    - Monitoring: Full monitoring stack

Production:
    - Purpose: Live trading
    - Stability: Highly stable, change-controlled
    - Data: Real trading data
    - Monitoring: 24/7 monitoring

================================================================================
SECTION 2: PREREQUISITES
================================================================================

REQUIRED ACCESS:
------------------------------------------------------------
Development Deployment:
    - SSH access to dev servers
    - Git repository access
    - Docker access (local or dev servers)

Staging Deployment:
    - SSH access to staging servers
    - Jenkins access
    - Artifactory access
    - Staging database access (read-only)

Production Deployment:
    - VPN + MFA authentication
    - Production bastion host access
    - Change management approval
    - Two-person authorization for critical changes

REQUIRED TOOLS:
------------------------------------------------------------
Local Development:
    $ git --version          # Git 2.40+
    $ docker --version       # Docker 24+
    $ kubectl version        # kubectl 1.28+
    $ ansible --version      # Ansible 2.15+

Command Line Tools:
    $ ssh-keygen            # SSH key management
    $ curl or wget          # HTTP clients
    $ jq                    # JSON processor
    $ psql                  # PostgreSQL client

ENVIRONMENT VERIFICATION:
------------------------------------------------------------
Before any deployment, verify:
    [ ] Latest code pulled from repository
    [ ] All tests passing locally
    [ ] No uncommitted changes
    [ ] SSH keys configured
    [ ] VPN connected (for prod/staging)
    [ ] Required credentials available

Quick verification script:
    $ ./scripts/verify_deployment_env.sh

Expected output:
    [OK] Git repository clean
    [OK] SSH keys configured
    [OK] VPN connected
    [OK] Required tools installed
    [OK] Docker daemon running

================================================================================
SECTION 3: DEVELOPMENT DEPLOYMENT
================================================================================

LOCAL DEVELOPMENT DEPLOYMENT:
------------------------------------------------------------
Purpose: Test changes on local workstation

Step 1: Build Local Images
    $ cd ~/workspace/hft/trading-system
    $ docker-compose -f docker/dev/docker-compose.yml build

Step 2: Start Services Locally
    $ docker-compose -f docker/dev/docker-compose.yml up -d

    Services started:
    - PostgreSQL (port 5432)
    - Redis (port 6379)
    - Trading Engine (port 8080)
    - Market Data Simulator (port 8081)
    - Risk Engine (port 8082)

Step 3: Verify Services Running
    $ docker-compose -f docker/dev/docker-compose.yml ps

    Expected: All services show "Up"

Step 4: Run Smoke Tests
    $ ./scripts/smoke_tests.sh --environment local

Step 5: View Logs
    $ docker-compose -f docker/dev/docker-compose.yml logs -f [service_name]

Step 6: Stop Services (When Done)
    $ docker-compose -f docker/dev/docker-compose.yml down


SHARED DEVELOPMENT SERVER DEPLOYMENT:
------------------------------------------------------------
Purpose: Deploy to shared dev environment for team testing

Step 1: Commit and Push Changes
    $ git add .
    $ git commit -m "[TICKET-###] Description of changes"
    $ git push origin feature/TICKET-###-description

Step 2: Build on CI (Automatic)
    Jenkins automatically builds all feature branches
    Monitor: https://jenkins.hftsystem.local/

Step 3: Deploy to Dev Server (Manual Trigger)
    Navigate to Jenkins job: deploy-to-dev
    Click "Build with Parameters"
    Parameters:
    - BRANCH: feature/TICKET-###-description
    - TARGET_SERVER: dev-shared-01 (or choose specific server)

    Click "Build"

Step 4: Monitor Deployment
    Watch Jenkins console output
    Expected duration: 5-10 minutes

Step 5: Verify Deployment
    $ ssh dev-shared-01
    $ systemctl status hft-trading-engine
    $ tail -f /var/log/hft/trading.log

Step 6: Run Tests on Dev Server
    $ ssh dev-shared-01
    $ cd /opt/hft
    $ ./scripts/smoke_tests.sh

DEPLOYING SPECIFIC COMPONENTS:
------------------------------------------------------------
Deploy Only Trading Engine:
    $ ssh dev-shared-01
    $ cd /opt/hft
    $ sudo systemctl stop hft-trading-engine
    $ sudo docker pull registry.hftsystem.local/hft/trading-engine:dev-latest
    $ sudo systemctl start hft-trading-engine

Deploy Only Market Data Handler:
    $ ssh dev-shared-01
    $ cd /opt/hft
    $ sudo systemctl stop hft-marketdata
    $ sudo docker pull registry.hftsystem.local/hft/marketdata:dev-latest
    $ sudo systemctl start hft-marketdata

Deploy Only Risk Engine:
    $ ssh dev-shared-01
    $ cd /opt/hft
    $ sudo systemctl stop hft-risk-engine
    $ sudo docker pull registry.hftsystem.local/hft/risk-engine:dev-latest
    $ sudo systemctl start hft-risk-engine

ROLLBACK IN DEVELOPMENT:
------------------------------------------------------------
If deployment fails:
    $ ssh dev-shared-01
    $ cd /opt/hft
    $ ./scripts/rollback.sh --environment dev --previous-version

Or manually:
    $ sudo systemctl stop hft-*
    $ sudo docker pull registry.hftsystem.local/hft/trading-system:dev-previous
    $ sudo systemctl start hft-*

================================================================================
SECTION 4: STAGING DEPLOYMENT
================================================================================

AUTOMATIC STAGING DEPLOYMENT:
------------------------------------------------------------
Trigger: Merge to develop branch
Process: Fully automated via Jenkins

What Happens Automatically:
1. Code merged to develop branch
2. Jenkins detects commit
3. Full build process runs
   - Compile all code
   - Run unit tests
   - Run integration tests
   - Build Docker images
   - Push images to registry
4. Deploy to staging
   - Stop staging services
   - Pull new images
   - Update configurations
   - Start services
   - Run smoke tests
5. Notify team (Slack + Email)

Monitor Progress:
    Jenkins: https://jenkins.hftsystem.local/job/deploy-staging/
    Slack: #deployments channel

Expected Duration: 20-30 minutes


MANUAL STAGING DEPLOYMENT:
------------------------------------------------------------
Use Case: Deploy specific branch for testing

Step 1: Navigate to Jenkins
    URL: https://jenkins.hftsystem.local/
    Job: deploy-to-staging-manual

Step 2: Build with Parameters
    Click "Build with Parameters"

    Parameters:
    - BRANCH: [branch-name] (default: develop)
    - SKIP_TESTS: false (usually keep false)
    - NOTIFY_TEAM: true

    Click "Build"

Step 3: Monitor Deployment
    Watch console output in Jenkins
    Check Slack #deployments for updates

Step 4: Verify Staging Deployment
    $ ssh bastion.staging.hftsystem.local
    $ ssh stage-trade-01

    Check service status:
    $ ansible staging_servers -m shell -a "systemctl status hft-*"

    Check application logs:
    $ ssh stage-trade-01 "tail -100 /var/log/hft/trading.log"

Step 5: Run Staging Tests
    Automated smoke tests run automatically

    Run additional tests manually:
    $ ssh stage-trade-01
    $ cd /opt/hft
    $ ./scripts/integration_tests.sh

Step 6: Verify Staging Health
    Navigate to: https://grafana.staging.hftsystem.local/
    Check dashboards:
    - System Health
    - Trading Performance
    - Market Data Health


STAGING DATABASE MIGRATION:
------------------------------------------------------------
If deployment includes database changes:

Step 1: Backup Staging Database
    $ ssh stage-db-01
    $ pg_dump -h localhost -U hft_admin -d trading_db \
      -F c -f /backups/pre_deploy_$(date +%Y%m%d_%H%M%S).dump

Step 2: Run Migration (Automatic in Deployment)
    Migrations run automatically via Flyway or Liquibase
    Location: src/main/resources/db/migration/

Step 3: Verify Migration
    $ ssh stage-db-01
    $ psql -h localhost -U hft_admin -d trading_db

    postgres=# SELECT version FROM schema_version ORDER BY installed_on DESC LIMIT 1;

    Should show latest version number

Step 4: Verify Data Integrity
    $ ssh stage-db-01
    $ cd /opt/hft
    $ ./scripts/verify_database_integrity.sh

Step 5: Performance Check
    $ ssh stage-db-01
    $ cd /opt/hft
    $ ./scripts/db_performance_check.sh


STAGING ROLLBACK:
------------------------------------------------------------
If issues found in staging:

Automated Rollback (Via Jenkins):
    Navigate to: https://jenkins.hftsystem.local/job/rollback-staging/
    Click "Build Now"
    Confirm rollback

Manual Rollback:
    $ ssh bastion.staging.hftsystem.local
    $ ansible-playbook /opt/hft/playbooks/rollback.yml \
      -e "environment=staging" \
      -e "target_version=3.2.1"

Database Rollback (If Needed):
    $ ssh stage-db-01
    $ /opt/hft/scripts/db_rollback.sh --to-version 3.2.1


STAGING ENVIRONMENT REFRESH:
------------------------------------------------------------
Purpose: Sync staging with production data (anonymized)

Frequency: Weekly (Saturdays)

Process:
    $ ssh bastion.staging.hftsystem.local
    $ cd /opt/hft
    $ sudo ./scripts/refresh_staging_environment.sh

    This script:
    1. Stops staging services
    2. Backs up staging database
    3. Restores anonymized production data
    4. Restarts services
    5. Runs smoke tests
    6. Sends notification

Expected Duration: 1-2 hours

================================================================================
SECTION 5: PRODUCTION DEPLOYMENT
================================================================================

PRODUCTION DEPLOYMENT OVERVIEW:
------------------------------------------------------------
CRITICAL: Production deployments require:
- Change management approval
- Two reviewers' approval
- Pre-deployment checklist completed
- Scheduled deployment window
- Rollback plan documented
- Team coordination

Never deploy to production:
- Without approval
- On Fridays or before long weekends
- During high volatility periods
- When key personnel unavailable

PRE-DEPLOYMENT CHECKLIST:
------------------------------------------------------------
See: deployment_checklist.txt for complete checklist

Essential items:
    [ ] All tests passing in staging
    [ ] Performance benchmarks acceptable
    [ ] Security scan clean
    [ ] Change management ticket approved
    [ ] Deployment team assembled
    [ ] Rollback plan ready
    [ ] Backup completed
    [ ] Stakeholders notified


PRODUCTION DEPLOYMENT PROCEDURE:
------------------------------------------------------------

PHASE 1: PREPARATION (T-1 hour)
------------------------------------------------------------
Step 1: Team Assembly
    Assemble deployment team on video call:
    - Deployment Lead
    - Technical Lead
    - QA Lead
    - Risk Manager
    - Operations

    War room: Zoom link in #deployments

Step 2: Final Go/No-Go Decision
    Poll each team member: GO or NO-GO
    Proceed only if all votes are GO

Step 3: Enable Maintenance Mode (If Downtime Required)
    $ ssh bastion.prod.hftsystem.local
    $ /opt/hft/scripts/maintenance_mode.sh --enable

    This will:
    - Display maintenance page
    - Stop accepting new orders
    - Complete in-flight orders
    - Stop trading strategies

Step 4: Final Production Backup
    $ ssh prod-db-primary
    $ pg_dump -h localhost -U hft_admin -d trading_db \
      -F c -f /backups/pre_deploy_$(date +%Y%m%d_%H%M%S).dump

    Verify backup:
    $ ls -lh /backups/pre_deploy_*.dump

Step 5: Snapshot Production State
    $ ssh bastion.prod.hftsystem.local
    $ /opt/hft/scripts/snapshot_production_state.sh

    Saves:
    - Current service versions
    - Configuration files
    - Database schema version
    - Running processes


PHASE 2: DEPLOYMENT EXECUTION (T+0 to T+45 minutes)
------------------------------------------------------------

OPTION A: Zero-Downtime Deployment (Preferred)
------------------------------------------------------------
Using Blue-Green Deployment:

Step 1: Deploy to Green Environment
    $ ssh bastion.prod.hftsystem.local
    $ ansible-playbook /opt/hft/playbooks/deploy_green.yml \
      -e "version=3.2.2"

    This deploys to inactive (green) servers:
    - prod-trade-green-01 through 08
    - prod-risk-green-01 through 04
    - prod-data-green-01 through 06

Step 2: Verify Green Environment
    $ /opt/hft/scripts/verify_green_environment.sh

    Checks:
    - All services running
    - Health checks passing
    - Connected to staging data feeds (not production yet)
    - Smoke tests passing

Step 3: Warm Up Green Environment
    $ /opt/hft/scripts/warmup_green_environment.sh

    - Load data caches
    - Establish connections
    - Pre-compile JIT code
    - Run test orders (staging)

Step 4: Switch Traffic to Green (Cutover)
    $ /opt/hft/scripts/cutover_to_green.sh

    This script:
    1. Stops new orders on blue
    2. Completes in-flight orders on blue
    3. Switches load balancer to green
    4. Connects green to production feeds
    5. Activates trading on green
    6. Monitors for 5 minutes
    7. Returns success/failure

    Expected downtime: < 30 seconds

Step 5: Monitor Green Environment (15 minutes)
    Watch dashboards closely:
    - https://grafana.hftsystem.local/d/trading-overview
    - All metrics should be normal
    - No errors in logs

Step 6: Decommission Blue (If Green is Stable)
    $ /opt/hft/scripts/shutdown_blue_environment.sh

    Blue servers kept available for quick rollback (1 hour)


OPTION B: Traditional Deployment (With Downtime)
------------------------------------------------------------
Use when zero-downtime not possible (e.g., database migration)

Step 1: Stop All Production Services
    $ ssh bastion.prod.hftsystem.local
    $ ansible production_servers -m shell -a "systemctl stop hft-*"

    Verify all stopped:
    $ ansible production_servers -m shell -a "ps aux | grep hft"

Step 2: Database Migration (If Applicable)
    $ ssh prod-db-primary
    $ /opt/hft/scripts/db_migrate.sh --environment production --version 3.2.2

    Monitor migration progress
    Verify success before proceeding

Step 3: Deploy New Version
    $ ssh bastion.prod.hftsystem.local
    $ ansible-playbook /opt/hft/playbooks/deploy.yml \
      -e "version=3.2.2" \
      -e "environment=production"

    This will:
    - Pull new Docker images
    - Update configuration files
    - Deploy binaries
    - Update service definitions

    Expected duration: 15-20 minutes

Step 4: Start Services (In Order)
    Critical: Start in correct order!

    1. Database
       $ ansible db_servers -m shell -a "systemctl start postgresql"

    2. Risk Engine
       $ ansible risk_servers -m shell -a "systemctl start hft-risk-engine"

    3. Market Data
       $ ansible marketdata_servers -m shell -a "systemctl start hft-marketdata"

    4. Order Management
       $ ansible trading_servers -m shell -a "systemctl start hft-oms"

    5. Trading Engine
       $ ansible trading_servers -m shell -a "systemctl start hft-trading-engine"

    6. Web Services
       $ ansible web_servers -m shell -a "systemctl start hft-web"

Step 5: Verify All Services Started
    $ ansible production_servers -m shell -a "systemctl status hft-*"

    All should show "active (running)"

Step 6: Disable Maintenance Mode
    $ /opt/hft/scripts/maintenance_mode.sh --disable


PHASE 3: POST-DEPLOYMENT VERIFICATION (T+45 to T+90)
------------------------------------------------------------
Step 1: System Health Checks
    $ /opt/hft/scripts/post_deployment_health_check.sh

    Verifies:
    - All services running
    - All health endpoints responding
    - No errors in logs
    - Metrics flowing to Grafana

Step 2: Smoke Tests
    $ /opt/hft/scripts/smoke_tests.sh --environment production

    Tests:
    - Order submission (test account)
    - Market data flow
    - Risk checks
    - Position updates
    - P&L calculation
    - Web interface

Step 3: Verify Market Data
    $ /opt/hft/scripts/verify_marketdata.sh --production

    Checks:
    - All feeds connected
    - Message rates normal
    - Latency acceptable
    - No stale data

Step 4: Verify Order Routing
    $ /opt/hft/scripts/verify_order_routing.sh --production

    Submits test orders (test account):
    - Limit orders
    - Market orders
    - Cancel orders
    - Verifies fills

Step 5: Verify Risk Checks
    $ /opt/hft/scripts/verify_risk_checks.sh --production

    Tests:
    - Position limits enforced
    - Loss limits checked
    - Invalid orders rejected

Step 6: Performance Validation
    $ /opt/hft/scripts/measure_latency.sh --production

    Measures:
    - Order processing latency
    - Market data latency
    - Risk check latency

    Compare with baseline (should be within 10%)

Step 7: Database Verification
    $ ssh prod-db-primary
    $ /opt/hft/scripts/verify_database_integrity.sh

    Checks:
    - Schema version correct
    - Data integrity
    - Replication working
    - Performance acceptable

Step 8: Check Grafana Dashboards
    Navigate to: https://grafana.hftsystem.local/

    Review dashboards:
    - Trading Overview
    - System Health
    - Market Data Health
    - Risk Monitoring

    All metrics should be green/normal


PHASE 4: ENABLE TRADING (T+90 to T+105)
------------------------------------------------------------
Step 1: Staged Strategy Activation
    Do NOT enable all strategies at once!

    Start with lowest risk:
    $ /opt/hft/bin/strategy_manager activate MM_EQ_001 --size 10%

    Wait 5 minutes, monitor closely

    If stable, increase:
    $ /opt/hft/bin/strategy_manager set_size MM_EQ_001 --size 50%

    Wait 5 minutes

    If stable, full size:
    $ /opt/hft/bin/strategy_manager set_size MM_EQ_001 --size 100%

Step 2: Activate Remaining Strategies
    Activate one at a time, 5 minutes apart:
    $ /opt/hft/bin/strategy_manager activate STAT_ARB_PAIRS_001

    Wait 5 minutes, monitor

    $ /opt/hft/bin/strategy_manager activate MOMENTUM_ST_001

    And so on...

Step 3: Monitor Initial Trading (15 minutes)
    Watch closely:
    - P&L trending positive
    - Fill rates normal
    - No risk alerts
    - Latency normal
    - No errors

Step 4: Validate Against Baseline
    $ /opt/hft/scripts/compare_metrics.sh \
      --baseline yesterday \
      --current today \
      --duration 15m

    Key metrics should be similar


PHASE 5: POST-DEPLOYMENT MONITORING (T+2 hours to T+24 hours)
------------------------------------------------------------
Immediate (2-4 hours):
    - Deployment Lead actively monitors
    - Check dashboards every 10 minutes
    - Review logs every 30 minutes
    - Trading desk feedback

Extended (4-24 hours):
    - Check dashboards every 30 minutes
    - Review metrics every hour
    - Monitor P&L progression
    - Watch for any anomalies

Day 1 Report:
    $ /opt/hft/scripts/generate_deployment_report.sh --deployment v3.2.2

    Review:
    - Performance vs baseline
    - Any issues encountered
    - Resolutions applied
    - Recommendations


PRODUCTION DEPLOYMENT ROLLBACK:
------------------------------------------------------------
Decision: If critical issues detected

OPTION A: Blue-Green Rollback (Fast)
------------------------------------------------------------
If using blue-green and blue still available:

$ /opt/hft/scripts/rollback_to_blue.sh

This script:
1. Stops trading on green
2. Switches load balancer to blue
3. Reactivates blue environment
4. Monitors blue for 5 minutes
5. Shuts down green

Expected rollback time: 2-3 minutes

OPTION B: Traditional Rollback
------------------------------------------------------------
$ ssh bastion.prod.hftsystem.local
$ ansible-playbook /opt/hft/playbooks/rollback.yml \
  -e "environment=production" \
  -e "target_version=3.2.1"

This will:
1. Stop all services
2. Rollback database (if needed)
3. Deploy previous version
4. Start services
5. Run verification

Expected rollback time: 15-20 minutes

Post-Rollback:
    - Verify system stability
    - Monitor for 1 hour
    - Notify stakeholders
    - Document rollback reason
    - Plan corrective action


EMERGENCY ROLLBACK (CRITICAL FAILURE):
------------------------------------------------------------
$ ssh bastion.prod.hftsystem.local
$ /opt/hft/scripts/emergency_rollback.sh --to-version 3.2.1

This is fastest possible rollback:
- Bypasses some safety checks
- Uses cached images
- Parallel execution
- Target time: < 5 minutes

Use only when:
- Production completely broken
- Significant financial loss occurring
- Data integrity at risk

================================================================================
SECTION 6: HOTFIX DEPLOYMENT
================================================================================

HOTFIX OVERVIEW:
------------------------------------------------------------
Purpose: Emergency production fixes
Use only for: Critical bugs, security issues, regulatory requirements

Hotfix process is expedited but still requires:
- Minimal code changes
- Fast-track code review
- Testing (even if abbreviated)
- Documentation

HOTFIX PROCEDURE:
------------------------------------------------------------

Step 1: Create Hotfix Branch
    $ git checkout main
    $ git pull origin main
    $ git checkout -b hotfix/TICKET-9999-critical-bug
    $ git push -u origin hotfix/TICKET-9999-critical-bug

Step 2: Implement Fix (Minimal Changes Only)
    - Fix ONLY the critical issue
    - No refactoring
    - No feature additions
    - Keep changes minimal and isolated

Step 3: Testing
    Run critical tests:
    $ ./scripts/run_critical_tests.sh

    Deploy to staging:
    $ ssh bastion.staging
    $ ansible-playbook /opt/hft/playbooks/deploy.yml \
      -e "branch=hotfix/TICKET-9999-critical-bug"

    Test in staging:
    $ ./scripts/verify_hotfix.sh

Step 4: Code Review (Expedited)
    Create PR with "HOTFIX" label
    Get approval from:
    - Minimum 1 senior developer
    - Risk manager (if risk-related)
    - CTO or VP Engineering

    Typical review time: 15-30 minutes

Step 5: Deploy to Production
    Follow production deployment procedure
    But with expedited timeline

    Can deploy during market hours if critical

Step 6: Monitor Closely
    Watch system for 1 hour minimum
    Verify fix resolves issue
    Ensure no side effects

Step 7: Merge Hotfix
    Merge to main:
    $ git checkout main
    $ git merge --no-ff hotfix/TICKET-9999-critical-bug
    $ git tag -a v3.2.2 -m "Hotfix: Critical bug fix"
    $ git push origin main --tags

    Back-merge to develop:
    $ git checkout develop
    $ git merge --no-ff hotfix/TICKET-9999-critical-bug
    $ git push origin develop

Step 8: Post-Mortem
    Schedule post-mortem within 24 hours
    Document:
    - Root cause
    - Why not caught earlier
    - Preventive measures
    - Process improvements

================================================================================
SECTION 7: DATABASE DEPLOYMENTS
================================================================================

DATABASE MIGRATION BEST PRACTICES:
------------------------------------------------------------
1. Always test in staging first
2. Migrations should be:
   - Backward compatible
   - Idempotent (can run multiple times)
   - Reversible
3. Large migrations during off-hours
4. Monitor performance during migration

MIGRATION TOOLS:
------------------------------------------------------------
Flyway (Preferred for Java projects):
    Location: src/main/resources/db/migration/
    Naming: V{version}__{description}.sql
    Example: V3.2.2__add_risk_limits_table.sql

Liquibase (Alternative):
    Location: src/main/resources/db/changelog/
    Format: XML or YAML

Custom Scripts:
    Location: scripts/db/migrations/
    Naming: {version}_{description}.sql


DEPLOYING DATABASE CHANGES:
------------------------------------------------------------

Step 1: Create Migration Script
    Create file: V3.2.2__description.sql

    Example migration:
    ```sql
    -- Create new table
    CREATE TABLE risk_limits (
        id SERIAL PRIMARY KEY,
        strategy_name VARCHAR(100) NOT NULL,
        limit_type VARCHAR(50) NOT NULL,
        limit_value DECIMAL(15,2) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    -- Create index
    CREATE INDEX idx_risk_limits_strategy
    ON risk_limits(strategy_name);

    -- Add column to existing table
    ALTER TABLE positions
    ADD COLUMN last_risk_check TIMESTAMP;

    -- Update existing data (if needed)
    UPDATE positions
    SET last_risk_check = CURRENT_TIMESTAMP
    WHERE last_risk_check IS NULL;
    ```

Step 2: Test Migration Locally
    $ docker-compose -f docker/dev/docker-compose.yml up -d postgres
    $ psql -h localhost -U hft_dev -d trading_db < V3.2.2__description.sql

    Verify:
    $ psql -h localhost -U hft_dev -d trading_db
    postgres=# \dt
    postgres=# SELECT * FROM risk_limits;

Step 3: Test in Staging
    Push to develop branch
    Migration runs automatically in staging deployment

    Verify:
    $ ssh stage-db-01
    $ psql -h localhost -U hft_admin -d trading_db
    postgres=# SELECT version FROM schema_version ORDER BY installed_on DESC LIMIT 1;

Step 4: Performance Test Migration
    $ ssh stage-db-01
    $ /opt/hft/scripts/test_migration_performance.sh

    Check:
    - Migration time
    - Lock duration
    - Impact on queries

Step 5: Deploy to Production
    Included in production deployment
    Or run manually:

    $ ssh prod-db-primary
    $ cd /opt/hft/scripts/db
    $ ./run_migration.sh --version 3.2.2

    Monitor:
    $ tail -f /var/log/postgresql/postgresql.log

Step 6: Verify Production Migration
    $ ssh prod-db-primary
    $ psql -h localhost -U hft_admin -d trading_db

    postgres=# SELECT version FROM schema_version ORDER BY installed_on DESC LIMIT 1;
    postgres=# \d risk_limits
    postgres=# SELECT COUNT(*) FROM risk_limits;

Step 7: Verify Application Works
    $ /opt/hft/scripts/smoke_tests.sh --database-focused


ROLLING BACK DATABASE MIGRATIONS:
------------------------------------------------------------
Create Rollback Script:
    File: V3.2.2__description_rollback.sql

    Example:
    ```sql
    -- Remove column
    ALTER TABLE positions DROP COLUMN last_risk_check;

    -- Drop index
    DROP INDEX idx_risk_limits_strategy;

    -- Drop table
    DROP TABLE risk_limits;
    ```

Execute Rollback:
    $ ssh prod-db-primary
    $ psql -h localhost -U hft_admin -d trading_db < V3.2.2__description_rollback.sql


LARGE TABLE MIGRATIONS:
------------------------------------------------------------
For tables with millions of rows:

Strategy 1: Online Schema Change (pt-online-schema-change)
    $ pt-online-schema-change \
      --alter "ADD COLUMN new_column VARCHAR(50)" \
      D=trading_db,t=large_table \
      --execute

Strategy 2: Batch Updates
    ```sql
    -- Update in batches
    DO $$
    DECLARE
        batch_size INTEGER := 10000;
        offset_val INTEGER := 0;
    BEGIN
        LOOP
            UPDATE large_table
            SET new_column = 'default_value'
            WHERE id IN (
                SELECT id FROM large_table
                WHERE new_column IS NULL
                LIMIT batch_size
            );

            EXIT WHEN NOT FOUND;

            offset_val := offset_val + batch_size;
            COMMIT;
            PERFORM pg_sleep(0.1); -- Prevent overload
        END LOOP;
    END $$;
    ```

Strategy 3: Shadow Table
    1. Create new table with desired schema
    2. Copy data (in batches)
    3. Keep new table in sync (triggers)
    4. Switch tables (rename)
    5. Drop old table

================================================================================
SECTION 8: CONFIGURATION DEPLOYMENTS
================================================================================

CONFIGURATION MANAGEMENT:
------------------------------------------------------------
Configuration files stored in:
    Repository: config/
    Deployed to: /opt/hft/config/

Configuration types:
    - Application config (YAML, JSON)
    - Strategy parameters
    - Risk limits
    - Database connections
    - API endpoints

DEPLOYING CONFIGURATION CHANGES:
------------------------------------------------------------

Step 1: Update Configuration File
    Edit: config/production/risk_limits.yaml

    Example:
    ```yaml
    risk_limits:
      MM_EQ_001:
        max_position_size: 15000  # Increased from 10000
        max_loss_per_day: 550000  # Increased from 500000
    ```

Step 2: Validate Configuration
    $ ./scripts/validate_config.sh config/production/risk_limits.yaml

    Checks:
    - YAML/JSON syntax
    - Required fields present
    - Values within acceptable ranges

Step 3: Test in Staging
    $ ssh bastion.staging
    $ cd /opt/hft/config
    $ sudo cp ~/risk_limits.yaml production/
    $ sudo systemctl restart hft-risk-engine
    $ /opt/hft/scripts/verify_config_loaded.sh

Step 4: Commit Configuration
    $ git add config/production/risk_limits.yaml
    $ git commit -m "[CONFIG] Update risk limits for MM_EQ_001"
    $ git push

Step 5: Deploy to Production
    $ ssh bastion.prod
    $ cd /opt/hft
    $ git pull origin main
    $ sudo cp config/production/risk_limits.yaml /opt/hft/config/

    Reload configuration (no restart required):
    $ /opt/hft/bin/risk_client reload_config

    Or restart service (if reload not supported):
    $ sudo systemctl restart hft-risk-engine

Step 6: Verify Configuration Applied
    $ /opt/hft/bin/risk_client show_limits

    Should show new limits

DYNAMIC CONFIGURATION UPDATES:
------------------------------------------------------------
Some configurations can be updated without restart:

Using Configuration API:
    $ curl -X POST https://risk.hftsystem.local/api/config/reload \
      -H "Authorization: Bearer $TOKEN" \
      -H "Content-Type: application/json" \
      -d '{"component": "risk_limits"}'

Using Command-Line Tool:
    $ /opt/hft/bin/config_manager update risk_limits \
      --file /opt/hft/config/risk_limits.yaml

Using Admin Interface:
    Navigate to: https://admin.hftsystem.local/config
    Upload new configuration file
    Click "Apply"

================================================================================
SECTION 9: MONITORING DEPLOYMENTS
================================================================================

METRICS TO MONITOR:
------------------------------------------------------------
Deployment Metrics:
    - Deployment duration
    - Success/failure rate
    - Rollback frequency
    - Time to rollback

Application Metrics (Post-Deployment):
    - Error rate (should not increase)
    - Latency (should not increase > 10%)
    - Throughput (should remain stable)
    - Resource utilization

Business Metrics:
    - Trading volume
    - P&L
    - Fill rates
    - Strategy performance

DEPLOYMENT DASHBOARD:
------------------------------------------------------------
URL: https://grafana.hftsystem.local/d/deployment-monitoring

Panels:
    - Deployment Timeline
    - Error Rate (before/after)
    - Latency Comparison
    - Resource Utilization
    - Application Health
    - Recent Deployments

ALERTING:
------------------------------------------------------------
Post-Deployment Alerts:
    - Error rate spike (> 2x baseline)
    - Latency spike (> 50% increase)
    - Service failure
    - Health check failure

Alert Channels:
    - PagerDuty (critical)
    - Slack #deployments (all)
    - Email (deployment team)

LOGGING:
------------------------------------------------------------
Deployment Logs:
    Jenkins: https://jenkins.hftsystem.local/
    Application: /var/log/hft/
    System: /var/log/syslog
    Centralized: Kibana

Search Deployment Logs:
    Navigate to: https://kibana.hftsystem.local/
    Filter: deployment_id: "v3.2.2"
    Time range: Last deployment

================================================================================
SECTION 10: TROUBLESHOOTING DEPLOYMENTS
================================================================================

COMMON DEPLOYMENT ISSUES:
------------------------------------------------------------

Issue 1: Deployment Fails During Build
    Symptoms:
    - Jenkins build fails
    - Compilation errors
    - Test failures

    Solution:
    1. Check Jenkins console output
    2. Identify failing test or compilation error
    3. Fix code locally
    4. Commit and push
    5. Retry deployment

Issue 2: Services Won't Start After Deployment
    Symptoms:
    - systemctl status shows "failed"
    - Services crash immediately
    - Error in logs

    Diagnosis:
    $ ssh [server]
    $ systemctl status hft-[service]
    $ journalctl -u hft-[service] -n 100

    Common causes:
    - Configuration error
    - Missing dependency
    - Port already in use
    - Database connection failure

    Solution:
    1. Fix configuration
    2. Ensure dependencies available
    3. Kill process on port
    4. Verify database accessible

Issue 3: Database Migration Fails
    Symptoms:
    - Migration script errors
    - Schema version mismatch
    - Data integrity issues

    Diagnosis:
    $ ssh prod-db-primary
    $ tail -100 /var/log/postgresql/postgresql.log

    Solution:
    1. Identify failing SQL statement
    2. Check for missing prerequisites
    3. Verify data constraints
    4. Fix migration script
    5. Rollback and retry

Issue 4: Performance Degradation After Deployment
    Symptoms:
    - Latency increased
    - Throughput decreased
    - High CPU/memory usage

    Diagnosis:
    $ /opt/hft/scripts/measure_latency.sh
    $ /opt/hft/scripts/compare_metrics.sh --baseline yesterday --current today

    Solution:
    1. Profile application
    2. Identify bottleneck
    3. Decide: Fix forward or rollback
    4. If rollback: Execute immediately
    5. If fix forward: Implement optimization

Issue 5: Configuration Not Applied
    Symptoms:
    - Application using old configuration
    - Changes not taking effect

    Diagnosis:
    $ /opt/hft/bin/[service]_client show_config

    Solution:
    1. Verify configuration file updated
    2. Verify file permissions
    3. Restart service
    4. Check for configuration caching

EMERGENCY PROCEDURES:
------------------------------------------------------------

Total Deployment Failure:
    1. Execute emergency rollback
       $ /opt/hft/scripts/emergency_rollback.sh

    2. Stop all trading
       $ /opt/hft/bin/emergency_stop.sh

    3. Notify all stakeholders

    4. Assess situation

    5. Plan recovery

Partial Deployment (Some Servers Failed):
    1. Assess which servers affected

    2. Route traffic away from failed servers
       $ /opt/hft/scripts/isolate_server.sh [server-name]

    3. Fix failed servers individually

    4. Verify fixes

    5. Return to service

Configuration Corruption:
    1. Restore from backup
       $ cp /opt/hft/config/backup/[file] /opt/hft/config/

    2. Reload configuration

    3. Verify applied

================================================================================
SECTION 11: DEPLOYMENT BEST PRACTICES
================================================================================

GENERAL BEST PRACTICES:
------------------------------------------------------------
1. Always test in staging first
2. Deploy during low-traffic windows
3. Have rollback plan ready
4. Monitor closely after deployment
5. Document everything
6. Communicate with stakeholders
7. Use automation where possible
8. Keep deployments small and frequent
9. Separate database and code deployments when possible
10. Never deploy on Fridays

DEPLOYMENT CHECKLIST:
------------------------------------------------------------
Before Deployment:
    [ ] All tests passing
    [ ] Code reviewed and approved
    [ ] Staging deployment successful
    [ ] Performance validated
    [ ] Security scan clean
    [ ] Documentation updated
    [ ] Rollback plan prepared
    [ ] Team assembled
    [ ] Stakeholders notified

During Deployment:
    [ ] Follow procedure exactly
    [ ] Verify each step
    [ ] Monitor continuously
    [ ] Document any deviations
    [ ] Communicate status

After Deployment:
    [ ] Verify deployment successful
    [ ] Run smoke tests
    [ ] Monitor for 1 hour minimum
    [ ] Generate deployment report
    [ ] Update documentation
    [ ] Notify stakeholders

CONTINUOUS IMPROVEMENT:
------------------------------------------------------------
After each deployment:
    - Conduct retrospective
    - Document lessons learned
    - Identify improvements
    - Update procedures
    - Automate repetitive tasks

Track metrics:
    - Deployment frequency
    - Deployment duration
    - Success rate
    - Rollback rate
    - Time to recovery

================================================================================
END OF CODE DEPLOYMENT GUIDE
================================================================================

For questions or suggestions, contact:
    Bob Johnson: bob.johnson@hftsystem.local
    DevOps Team: devops@hftsystem.local
