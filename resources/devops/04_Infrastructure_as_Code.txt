================================================================================
INFRASTRUCTURE AS CODE (IaC) FOR HFT SYSTEMS
================================================================================
Complete Terraform and Ansible configurations for provisioning and managing
infrastructure for high-frequency trading systems.

Last Updated: 2025-11-25
================================================================================

TABLE OF CONTENTS
================================================================================
1. Terraform AWS Infrastructure
2. Terraform GCP Infrastructure
3. Terraform Azure Infrastructure
4. Terraform Modules
5. Ansible Playbooks
6. Ansible Roles
7. Configuration Management
8. State Management
9. Security and Secrets

================================================================================
1. TERRAFORM AWS INFRASTRUCTURE
================================================================================

# terraform/aws/main.tf
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.11"
    }
  }

  backend "s3" {
    bucket         = "hft-terraform-state"
    key            = "production/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
    kms_key_id     = "arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012"
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Environment = var.environment
      Project     = "HFT-Trading"
      ManagedBy   = "Terraform"
      Team        = "Trading-Platform"
    }
  }
}

# Data sources
data "aws_availability_zones" "available" {
  state = "available"
}

data "aws_caller_identity" "current" {}

# Local variables
locals {
  cluster_name = "hft-trading-${var.environment}"
  common_tags = {
    Environment = var.environment
    Terraform   = "true"
  }
}

# VPC Configuration
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~> 5.0"

  name = "${local.cluster_name}-vpc"
  cidr = var.vpc_cidr

  azs             = slice(data.aws_availability_zones.available.names, 0, 3)
  private_subnets = var.private_subnet_cidrs
  public_subnets  = var.public_subnet_cidrs

  enable_nat_gateway   = true
  single_nat_gateway   = false
  enable_dns_hostnames = true
  enable_dns_support   = true

  # VPC Flow Logs
  enable_flow_log                      = true
  create_flow_log_cloudwatch_iam_role  = true
  create_flow_log_cloudwatch_log_group = true
  flow_log_retention_in_days           = 30

  # Network optimization for low latency
  enable_dhcp_options      = true
  dhcp_options_domain_name = "hft-trading.local"

  tags = merge(
    local.common_tags,
    {
      "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    }
  )

  public_subnet_tags = {
    "kubernetes.io/role/elb" = "1"
  }

  private_subnet_tags = {
    "kubernetes.io/role/internal-elb" = "1"
  }
}

# EKS Cluster
module "eks" {
  source  = "terraform-aws-modules/eks/aws"
  version = "~> 19.0"

  cluster_name    = local.cluster_name
  cluster_version = var.kubernetes_version

  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets

  # Control plane logging
  cluster_enabled_log_types = [
    "api",
    "audit",
    "authenticator",
    "controllerManager",
    "scheduler"
  ]

  # Cluster encryption
  cluster_encryption_config = {
    provider_key_arn = aws_kms_key.eks.arn
    resources        = ["secrets"]
  }

  # Node groups for trading engines
  eks_managed_node_groups = {
    # High-performance nodes for trading engines
    trading_engine = {
      name           = "trading-engine"
      instance_types = ["c6i.4xlarge", "c6i.8xlarge"]
      capacity_type  = "ON_DEMAND"

      min_size     = 3
      max_size     = 10
      desired_size = 3

      # Use latest EKS optimized AMI
      ami_type = "AL2_x86_64"

      # Disk configuration
      block_device_mappings = {
        xvda = {
          device_name = "/dev/xvda"
          ebs = {
            volume_size           = 200
            volume_type           = "gp3"
            iops                  = 16000
            throughput            = 1000
            encrypted             = true
            kms_key_id            = aws_kms_key.eks.arn
            delete_on_termination = true
          }
        }
      }

      # Placement group for low latency
      placement_group_strategy = "cluster"

      # Labels and taints
      labels = {
        node-type = "high-performance"
        cpu-type  = "intel-xeon"
      }

      # User data for system tuning
      pre_bootstrap_user_data = <<-EOT
        #!/bin/bash
        # Kernel parameter tuning for low latency
        cat <<EOF >> /etc/sysctl.conf
        net.core.somaxconn=4096
        net.core.netdev_max_backlog=8192
        net.ipv4.tcp_max_syn_backlog=8192
        net.core.rmem_max=16777216
        net.core.wmem_max=16777216
        net.ipv4.tcp_rmem=4096 87380 16777216
        net.ipv4.tcp_wmem=4096 87380 16777216
        net.ipv4.tcp_congestion_control=bbr
        net.core.default_qdisc=fq
        net.ipv4.tcp_slow_start_after_idle=0
        vm.swappiness=1
        EOF
        sysctl -p

        # Huge pages configuration
        echo 'vm.nr_hugepages=1024' >> /etc/sysctl.conf
        sysctl -p

        # CPU governor performance mode
        echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

        # Disable transparent huge pages
        echo never > /sys/kernel/mm/transparent_hugepage/enabled
        echo never > /sys/kernel/mm/transparent_hugepage/defrag
      EOT

      tags = {
        NodeGroup = "trading-engine"
      }
    }

    # General purpose nodes
    general = {
      name           = "general"
      instance_types = ["t3.xlarge"]
      capacity_type  = "SPOT"

      min_size     = 2
      max_size     = 5
      desired_size = 2

      labels = {
        node-type = "general"
      }

      tags = {
        NodeGroup = "general"
      }
    }
  }

  # Cluster access
  manage_aws_auth_configmap = true
  aws_auth_roles = [
    {
      rolearn  = aws_iam_role.cluster_admin.arn
      username = "cluster-admin"
      groups   = ["system:masters"]
    }
  ]

  # Add-ons
  cluster_addons = {
    coredns = {
      most_recent = true
    }
    kube-proxy = {
      most_recent = true
    }
    vpc-cni = {
      most_recent = true
      configuration_values = jsonencode({
        env = {
          ENABLE_PREFIX_DELEGATION = "true"
          WARM_PREFIX_TARGET       = "1"
        }
      })
    }
    aws-ebs-csi-driver = {
      most_recent              = true
      service_account_role_arn = aws_iam_role.ebs_csi_driver.arn
    }
  }

  tags = local.common_tags
}

# KMS Key for EKS encryption
resource "aws_kms_key" "eks" {
  description             = "EKS Secret Encryption Key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-eks-encryption"
    }
  )
}

resource "aws_kms_alias" "eks" {
  name          = "alias/${local.cluster_name}-eks"
  target_key_id = aws_kms_key.eks.key_id
}

# RDS PostgreSQL for persistent storage
module "rds" {
  source  = "terraform-aws-modules/rds/aws"
  version = "~> 6.0"

  identifier = "${local.cluster_name}-postgres"

  engine               = "postgres"
  engine_version       = "15.4"
  family               = "postgres15"
  major_engine_version = "15"
  instance_class       = "db.r6i.2xlarge"

  allocated_storage     = 500
  max_allocated_storage = 2000
  storage_type          = "io2"
  iops                  = 32000
  storage_encrypted     = true
  kms_key_id            = aws_kms_key.rds.arn

  db_name  = "hft_trading"
  username = "hftadmin"
  port     = 5432

  # High availability
  multi_az               = true
  db_subnet_group_name   = module.vpc.database_subnet_group
  vpc_security_group_ids = [aws_security_group.rds.id]

  # Performance tuning
  parameters = [
    {
      name  = "shared_buffers"
      value = "8192MB"
    },
    {
      name  = "effective_cache_size"
      value = "24GB"
    },
    {
      name  = "maintenance_work_mem"
      value = "2GB"
    },
    {
      name  = "checkpoint_completion_target"
      value = "0.9"
    },
    {
      name  = "wal_buffers"
      value = "16MB"
    },
    {
      name  = "default_statistics_target"
      value = "100"
    },
    {
      name  = "random_page_cost"
      value = "1.1"
    },
    {
      name  = "effective_io_concurrency"
      value = "200"
    },
    {
      name  = "work_mem"
      value = "10485kB"
    },
    {
      name  = "min_wal_size"
      value = "1GB"
    },
    {
      name  = "max_wal_size"
      value = "4GB"
    }
  ]

  # Backups
  backup_retention_period = 30
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"

  # Enhanced monitoring
  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]
  monitoring_interval             = 1
  monitoring_role_arn             = aws_iam_role.rds_monitoring.arn

  # Performance Insights
  performance_insights_enabled    = true
  performance_insights_kms_key_id = aws_kms_key.rds.arn

  tags = local.common_tags
}

# ElastiCache Redis for caching
module "redis" {
  source  = "terraform-aws-modules/elasticache/aws"
  version = "~> 1.0"

  cluster_id           = "${local.cluster_name}-redis"
  engine               = "redis"
  engine_version       = "7.0"
  node_type            = "cache.r6g.xlarge"
  num_cache_nodes      = 3
  parameter_group_name = aws_elasticache_parameter_group.redis.name

  subnet_ids         = module.vpc.private_subnets
  security_group_ids = [aws_security_group.redis.id]

  # High availability
  automatic_failover_enabled = true
  multi_az_enabled          = true

  # At-rest encryption
  at_rest_encryption_enabled = true
  kms_key_id                = aws_kms_key.redis.arn

  # In-transit encryption
  transit_encryption_enabled = true
  auth_token                = random_password.redis_auth_token.result

  # Backup
  snapshot_retention_limit = 5
  snapshot_window         = "03:00-05:00"

  tags = local.common_tags
}

# ElastiCache Parameter Group
resource "aws_elasticache_parameter_group" "redis" {
  name   = "${local.cluster_name}-redis-params"
  family = "redis7"

  parameter {
    name  = "maxmemory-policy"
    value = "allkeys-lru"
  }

  parameter {
    name  = "timeout"
    value = "300"
  }

  parameter {
    name  = "tcp-keepalive"
    value = "60"
  }
}

# S3 Buckets for data storage
resource "aws_s3_bucket" "market_data" {
  bucket = "${local.cluster_name}-market-data"

  tags = merge(
    local.common_tags,
    {
      Name = "Market Data Storage"
    }
  )
}

resource "aws_s3_bucket_versioning" "market_data" {
  bucket = aws_s3_bucket.market_data.id

  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "market_data" {
  bucket = aws_s3_bucket.market_data.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.s3.arn
    }
  }
}

resource "aws_s3_bucket_lifecycle_configuration" "market_data" {
  bucket = aws_s3_bucket.market_data.id

  rule {
    id     = "archive-old-data"
    status = "Enabled"

    transition {
      days          = 30
      storage_class = "STANDARD_IA"
    }

    transition {
      days          = 90
      storage_class = "GLACIER_IR"
    }

    transition {
      days          = 180
      storage_class = "DEEP_ARCHIVE"
    }
  }
}

# CloudWatch Log Groups
resource "aws_cloudwatch_log_group" "trading_engine" {
  name              = "/aws/eks/${local.cluster_name}/trading-engine"
  retention_in_days = 30
  kms_key_id        = aws_kms_key.cloudwatch.arn

  tags = local.common_tags
}

# CloudWatch Alarms
resource "aws_cloudwatch_metric_alarm" "high_latency" {
  alarm_name          = "${local.cluster_name}-high-latency"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "latency_p99"
  namespace           = "HFT/Trading"
  period              = 60
  statistic           = "Average"
  threshold           = 1.0
  alarm_description   = "P99 latency exceeded threshold"
  alarm_actions       = [aws_sns_topic.alerts.arn]

  dimensions = {
    ClusterName = local.cluster_name
  }
}

resource "aws_cloudwatch_metric_alarm" "high_error_rate" {
  alarm_name          = "${local.cluster_name}-high-error-rate"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "error_rate"
  namespace           = "HFT/Trading"
  period              = 300
  statistic           = "Sum"
  threshold           = 100
  alarm_description   = "Error rate exceeded threshold"
  alarm_actions       = [aws_sns_topic.alerts.arn]

  dimensions = {
    ClusterName = local.cluster_name
  }
}

# SNS Topic for alerts
resource "aws_sns_topic" "alerts" {
  name              = "${local.cluster_name}-alerts"
  kms_master_key_id = aws_kms_key.sns.arn

  tags = local.common_tags
}

resource "aws_sns_topic_subscription" "alerts_email" {
  topic_arn = aws_sns_topic.alerts.arn
  protocol  = "email"
  endpoint  = var.alert_email
}

# Security Groups
resource "aws_security_group" "rds" {
  name_prefix = "${local.cluster_name}-rds-"
  vpc_id      = module.vpc.vpc_id
  description = "Security group for RDS PostgreSQL"

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [module.eks.node_security_group_id]
    description     = "Allow PostgreSQL from EKS nodes"
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    description = "Allow all outbound"
  }

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-rds"
    }
  )
}

resource "aws_security_group" "redis" {
  name_prefix = "${local.cluster_name}-redis-"
  vpc_id      = module.vpc.vpc_id
  description = "Security group for ElastiCache Redis"

  ingress {
    from_port       = 6379
    to_port         = 6379
    protocol        = "tcp"
    security_groups = [module.eks.node_security_group_id]
    description     = "Allow Redis from EKS nodes"
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    description = "Allow all outbound"
  }

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-redis"
    }
  )
}

# IAM Roles
resource "aws_iam_role" "cluster_admin" {
  name = "${local.cluster_name}-cluster-admin"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          AWS = data.aws_caller_identity.current.arn
        }
      }
    ]
  })

  tags = local.common_tags
}

resource "aws_iam_role" "ebs_csi_driver" {
  name = "${local.cluster_name}-ebs-csi-driver"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRoleWithWebIdentity"
        Effect = "Allow"
        Principal = {
          Federated = module.eks.oidc_provider_arn
        }
        Condition = {
          StringEquals = {
            "${replace(module.eks.cluster_oidc_issuer_url, "https://", "")}:sub" = "system:serviceaccount:kube-system:ebs-csi-controller-sa"
          }
        }
      }
    ]
  })

  tags = local.common_tags
}

resource "aws_iam_role_policy_attachment" "ebs_csi_driver" {
  role       = aws_iam_role.ebs_csi_driver.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy"
}

resource "aws_iam_role" "rds_monitoring" {
  name = "${local.cluster_name}-rds-monitoring"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "monitoring.rds.amazonaws.com"
        }
      }
    ]
  })

  tags = local.common_tags
}

resource "aws_iam_role_policy_attachment" "rds_monitoring" {
  role       = aws_iam_role.rds_monitoring.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole"
}

# KMS Keys
resource "aws_kms_key" "rds" {
  description             = "RDS encryption key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-rds"
    }
  )
}

resource "aws_kms_key" "redis" {
  description             = "Redis encryption key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-redis"
    }
  )
}

resource "aws_kms_key" "s3" {
  description             = "S3 encryption key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-s3"
    }
  )
}

resource "aws_kms_key" "cloudwatch" {
  description             = "CloudWatch Logs encryption key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-cloudwatch"
    }
  )
}

resource "aws_kms_key" "sns" {
  description             = "SNS encryption key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(
    local.common_tags,
    {
      Name = "${local.cluster_name}-sns"
    }
  )
}

# Random password for Redis
resource "random_password" "redis_auth_token" {
  length  = 32
  special = true
}

# Store Redis password in Secrets Manager
resource "aws_secretsmanager_secret" "redis_password" {
  name                    = "${local.cluster_name}-redis-password"
  recovery_window_in_days = 7
  kms_key_id             = aws_kms_key.eks.arn

  tags = local.common_tags
}

resource "aws_secretsmanager_secret_version" "redis_password" {
  secret_id     = aws_secretsmanager_secret.redis_password.id
  secret_string = random_password.redis_auth_token.result
}

---
# terraform/aws/variables.tf
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "environment" {
  description = "Environment name"
  type        = string
}

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
  default     = "10.0.0.0/16"
}

variable "private_subnet_cidrs" {
  description = "Private subnet CIDR blocks"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
}

variable "public_subnet_cidrs" {
  description = "Public subnet CIDR blocks"
  type        = list(string)
  default     = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]
}

variable "kubernetes_version" {
  description = "Kubernetes version"
  type        = string
  default     = "1.28"
}

variable "alert_email" {
  description = "Email for CloudWatch alerts"
  type        = string
}

---
# terraform/aws/outputs.tf
output "cluster_endpoint" {
  description = "EKS cluster endpoint"
  value       = module.eks.cluster_endpoint
  sensitive   = true
}

output "cluster_name" {
  description = "EKS cluster name"
  value       = module.eks.cluster_name
}

output "rds_endpoint" {
  description = "RDS endpoint"
  value       = module.rds.db_instance_endpoint
  sensitive   = true
}

output "redis_endpoint" {
  description = "Redis endpoint"
  value       = module.redis.cluster_address
  sensitive   = true
}

output "s3_bucket_market_data" {
  description = "S3 bucket for market data"
  value       = aws_s3_bucket.market_data.id
}

output "vpc_id" {
  description = "VPC ID"
  value       = module.vpc.vpc_id
}

================================================================================
2. TERRAFORM GCP INFRASTRUCTURE
================================================================================

# terraform/gcp/main.tf
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }

  backend "gcs" {
    bucket = "hft-terraform-state"
    prefix = "production"
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
}

locals {
  cluster_name = "hft-trading-${var.environment}"
}

# VPC Network
resource "google_compute_network" "vpc" {
  name                    = "${local.cluster_name}-vpc"
  auto_create_subnetworks = false
  routing_mode            = "REGIONAL"
}

# Subnets
resource "google_compute_subnetwork" "private" {
  name          = "${local.cluster_name}-private"
  ip_cidr_range = "10.0.0.0/20"
  region        = var.region
  network       = google_compute_network.vpc.id

  secondary_ip_range {
    range_name    = "pods"
    ip_cidr_range = "10.1.0.0/16"
  }

  secondary_ip_range {
    range_name    = "services"
    ip_cidr_range = "10.2.0.0/16"
  }

  private_ip_google_access = true
}

# GKE Cluster
resource "google_container_cluster" "primary" {
  name     = local.cluster_name
  location = var.region

  network    = google_compute_network.vpc.name
  subnetwork = google_compute_subnetwork.private.name

  # Minimum version
  min_master_version = var.kubernetes_version

  # Remove default node pool
  remove_default_node_pool = true
  initial_node_count       = 1

  # IP allocation for pods and services
  ip_allocation_policy {
    cluster_secondary_range_name  = "pods"
    services_secondary_range_name = "services"
  }

  # Workload Identity
  workload_identity_config {
    workload_pool = "${var.project_id}.svc.id.goog"
  }

  # Master authorized networks
  master_authorized_networks_config {
    cidr_blocks {
      cidr_block   = "0.0.0.0/0"
      display_name = "All networks"
    }
  }

  # Maintenance window
  maintenance_policy {
    daily_maintenance_window {
      start_time = "03:00"
    }
  }

  # Logging and monitoring
  logging_config {
    enable_components = ["SYSTEM_COMPONENTS", "WORKLOADS"]
  }

  monitoring_config {
    enable_components = ["SYSTEM_COMPONENTS"]
    managed_prometheus {
      enabled = true
    }
  }

  # Binary authorization
  binary_authorization {
    evaluation_mode = "PROJECT_SINGLETON_POLICY_ENFORCE"
  }
}

# Node Pool for Trading Engines
resource "google_container_node_pool" "trading_engine" {
  name       = "trading-engine"
  cluster    = google_container_cluster.primary.id
  location   = var.region
  node_count = 3

  autoscaling {
    min_node_count = 3
    max_node_count = 10
  }

  node_config {
    machine_type = "c2-standard-16"
    disk_size_gb = 200
    disk_type    = "pd-ssd"

    labels = {
      node-type = "high-performance"
    }

    metadata = {
      disable-legacy-endpoints = "true"
    }

    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform"
    ]

    workload_metadata_config {
      mode = "GKE_METADATA"
    }

    shielded_instance_config {
      enable_secure_boot          = true
      enable_integrity_monitoring = true
    }
  }

  management {
    auto_repair  = true
    auto_upgrade = true
  }
}

# Cloud SQL PostgreSQL
resource "google_sql_database_instance" "postgres" {
  name             = "${local.cluster_name}-postgres"
  database_version = "POSTGRES_15"
  region           = var.region

  settings {
    tier              = "db-custom-8-32768"
    availability_type = "REGIONAL"
    disk_size         = 500
    disk_type         = "PD_SSD"
    disk_autoresize   = true

    backup_configuration {
      enabled                        = true
      point_in_time_recovery_enabled = true
      start_time                     = "03:00"
      transaction_log_retention_days = 7
    }

    ip_configuration {
      ipv4_enabled    = false
      private_network = google_compute_network.vpc.id
    }

    database_flags {
      name  = "max_connections"
      value = "1000"
    }

    database_flags {
      name  = "shared_buffers"
      value = "8388608"
    }

    insights_config {
      query_insights_enabled  = true
      query_string_length     = 1024
      record_application_tags = true
      record_client_address   = true
    }
  }

  deletion_protection = true
}

# Cloud Memorystore (Redis)
resource "google_redis_instance" "cache" {
  name           = "${local.cluster_name}-redis"
  memory_size_gb = 16
  tier           = "STANDARD_HA"
  region         = var.region

  redis_version     = "REDIS_7_0"
  authorized_network = google_compute_network.vpc.id

  redis_configs = {
    maxmemory-policy = "allkeys-lru"
  }

  transit_encryption_mode = "SERVER_AUTHENTICATION"
  auth_enabled            = true
}

# Cloud Storage for market data
resource "google_storage_bucket" "market_data" {
  name          = "${local.cluster_name}-market-data"
  location      = var.region
  force_destroy = false

  uniform_bucket_level_access = true

  versioning {
    enabled = true
  }

  lifecycle_rule {
    action {
      type          = "SetStorageClass"
      storage_class = "NEARLINE"
    }
    condition {
      age = 30
    }
  }

  lifecycle_rule {
    action {
      type          = "SetStorageClass"
      storage_class = "COLDLINE"
    }
    condition {
      age = 90
    }
  }

  lifecycle_rule {
    action {
      type          = "SetStorageClass"
      storage_class = "ARCHIVE"
    }
    condition {
      age = 180
    }
  }
}

================================================================================
3. ANSIBLE PLAYBOOKS
================================================================================

# ansible/playbooks/setup-cluster.yml
---
- name: Setup HFT Trading Cluster
  hosts: all
  become: yes
  gather_facts: yes

  vars:
    kubernetes_version: "1.28.0"
    docker_version: "24.0.0"
    containerd_version: "1.7.0"

  pre_tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

  roles:
    - role: system-tuning
    - role: docker
    - role: kubernetes
    - role: monitoring
    - role: security

  tasks:
    - name: Install required packages
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - software-properties-common
        state: present

    - name: Configure kernel parameters
      sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        reload: yes
      loop:
        - { name: 'net.core.somaxconn', value: '4096' }
        - { name: 'net.core.netdev_max_backlog', value: '8192' }
        - { name: 'net.ipv4.tcp_max_syn_backlog', value: '8192' }
        - { name: 'net.core.rmem_max', value: '16777216' }
        - { name: 'net.core.wmem_max', value: '16777216' }
        - { name: 'vm.swappiness', value: '1' }
        - { name: 'vm.nr_hugepages', value: '1024' }

    - name: Disable transparent huge pages
      shell: |
        echo never > /sys/kernel/mm/transparent_hugepage/enabled
        echo never > /sys/kernel/mm/transparent_hugepage/defrag

    - name: Configure CPU governor to performance
      shell: |
        echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

---
# ansible/playbooks/deploy-application.yml
- name: Deploy HFT Trading Application
  hosts: kubernetes_master
  gather_facts: no

  vars:
    namespace: hft-trading
    image_tag: "{{ lookup('env', 'IMAGE_TAG') | default('latest', true) }}"

  tasks:
    - name: Create namespace
      kubernetes.core.k8s:
        name: "{{ namespace }}"
        api_version: v1
        kind: Namespace
        state: present

    - name: Deploy ConfigMap
      kubernetes.core.k8s:
        state: present
        definition: "{{ lookup('file', '../k8s/configmap.yaml') }}"

    - name: Deploy Secrets
      kubernetes.core.k8s:
        state: present
        definition: "{{ lookup('file', '../k8s/secrets.yaml') }}"

    - name: Deploy StatefulSet
      kubernetes.core.k8s:
        state: present
        definition: "{{ lookup('template', '../k8s/statefulset.yaml.j2') }}"
      vars:
        replicas: 3

    - name: Deploy Services
      kubernetes.core.k8s:
        state: present
        definition: "{{ lookup('file', '../k8s/service.yaml') }}"

    - name: Wait for deployment
      kubernetes.core.k8s_info:
        kind: StatefulSet
        name: trading-engine
        namespace: "{{ namespace }}"
        wait: yes
        wait_timeout: 600

================================================================================
4. ANSIBLE ROLES
================================================================================

# ansible/roles/system-tuning/tasks/main.yml
---
- name: Install performance tools
  apt:
    name:
      - sysstat
      - numactl
      - htop
      - iotop
      - perf-tools-unstable
    state: present

- name: Configure system limits
  template:
    src: limits.conf.j2
    dest: /etc/security/limits.conf
    owner: root
    group: root
    mode: '0644'

- name: Configure sysctl parameters
  template:
    src: sysctl.conf.j2
    dest: /etc/sysctl.d/99-hft-tuning.conf
    owner: root
    group: root
    mode: '0644'
  notify: reload sysctl

- name: Configure CPU isolation
  lineinfile:
    path: /etc/default/grub
    regexp: '^GRUB_CMDLINE_LINUX='
    line: 'GRUB_CMDLINE_LINUX="isolcpus=2-7 nohz_full=2-7 rcu_nocbs=2-7"'
  notify: update grub

- name: Configure IRQ affinity
  template:
    src: irq-affinity.sh.j2
    dest: /usr/local/bin/irq-affinity.sh
    owner: root
    group: root
    mode: '0755'

- name: Setup systemd service for IRQ affinity
  template:
    src: irq-affinity.service.j2
    dest: /etc/systemd/system/irq-affinity.service
    owner: root
    group: root
    mode: '0644'
  notify: reload systemd

# ansible/roles/system-tuning/templates/sysctl.conf.j2
# Network tuning for low latency
net.core.somaxconn = 4096
net.core.netdev_max_backlog = 8192
net.ipv4.tcp_max_syn_backlog = 8192
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 87380 16777216
net.ipv4.tcp_congestion_control = bbr
net.core.default_qdisc = fq
net.ipv4.tcp_slow_start_after_idle = 0

# Memory tuning
vm.swappiness = 1
vm.nr_hugepages = 1024
vm.overcommit_memory = 1

# File descriptor limits
fs.file-max = 2097152
fs.nr_open = 2097152

================================================================================
5. DEPLOYMENT SCRIPTS
================================================================================

# scripts/terraform-apply.sh
#!/bin/bash
set -e

ENVIRONMENT=${1:-production}
TERRAFORM_DIR="terraform/aws"

echo "Deploying infrastructure for environment: ${ENVIRONMENT}"

cd ${TERRAFORM_DIR}

# Initialize Terraform
terraform init -upgrade

# Validate configuration
terraform validate

# Plan changes
terraform plan \
  -var-file="environments/${ENVIRONMENT}.tfvars" \
  -out=tfplan

# Apply changes
terraform apply tfplan

# Output important values
terraform output -json > ../../outputs/${ENVIRONMENT}-outputs.json

echo "Infrastructure deployment completed"

# scripts/ansible-deploy.sh
#!/bin/bash
set -e

ENVIRONMENT=${1:-production}
PLAYBOOK=${2:-deploy-application.yml}

echo "Running Ansible playbook: ${PLAYBOOK}"

ansible-playbook \
  -i inventory/${ENVIRONMENT} \
  playbooks/${PLAYBOOK} \
  --extra-vars "environment=${ENVIRONMENT}"

echo "Ansible deployment completed"

================================================================================
END OF INFRASTRUCTURE AS CODE GUIDE
================================================================================
