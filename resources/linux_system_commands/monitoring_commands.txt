================================================================================
                    LINUX MONITORING COMMANDS REFERENCE
                    Real-Time System Observability for HFT
================================================================================

TABLE OF CONTENTS
-----------------
1. System Overview Tools
2. CPU Monitoring
3. Memory Monitoring
4. Disk I/O Monitoring
5. Network Monitoring
6. Process Monitoring
7. Real-Time Monitoring
8. Performance Profiling
9. Log Analysis
10. Alerting and Automation

================================================================================
1. SYSTEM OVERVIEW TOOLS
================================================================================

1.1 TOP / HTOP
--------------

# Interactive process viewer
top

# Key shortcuts in top:
# 1 - Show individual CPU cores
# P - Sort by CPU usage
# M - Sort by memory usage
# c - Show full command line
# k - Kill process
# r - Renice process
# f - Select display fields
# W - Save configuration

# Batch mode for logging
top -b -n 1 > system_snapshot.txt

# Monitor specific user
top -u trading

# Show threads
top -H -p $(pidof trading_engine)

# HTOP (enhanced version)
htop

# HTOP with custom columns
htop -d 10 -C  # Update every 1s, no color

HFT USE CASE: Quick identification of CPU-bound trading processes
PERFORMANCE IMPACT: Minimal (<0.1% CPU overhead)
OUTPUT INTERPRETATION:
  - load average < #CPUs = good
  - %wa (iowait) > 10% = disk bottleneck
  - %st (steal) > 0 = virtualization issues


1.2 VMSTAT (Virtual Memory Statistics)
---------------------------------------

# Display system statistics
vmstat 1

# Extended statistics
vmstat -w 1 10

# Display in MB
vmstat -S M 1

# Show disk statistics
vmstat -d

# Display slab allocator statistics
vmstat -m

OUTPUT FORMAT:
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0      0 142652  15368  89420    0    0     5    15  125  210  1  0 99  0  0

KEY METRICS:
  r  - Processes waiting for CPU (should be < #CPUs)
  b  - Processes in uninterruptible sleep
  si - Swap in (should be 0)
  so - Swap out (should be 0)
  in - Interrupts per second
  cs - Context switches per second (lower is better for HFT)
  us - User CPU time
  sy - System CPU time
  wa - IO wait time (should be < 10%)

HFT USE CASE: Detect context switch storms and memory pressure
ONE-LINER: Watch context switches: vmstat 1 | awk '{print $12}'


1.3 SAR (System Activity Reporter)
-----------------------------------

# Collect all statistics (run as daemon)
sar -A 1 10

# CPU utilization
sar -u 1 10

# Per-CPU statistics
sar -P ALL 1 10

# Memory utilization
sar -r 1 10

# Swap activity
sar -S 1 10

# I/O statistics
sar -b 1 10

# Network statistics
sar -n DEV 1 10

# Context switches and interrupts
sar -w 1 10

# Historical data (from /var/log/sa/)
sar -u -f /var/log/sa/sa25

# Generate daily report
sar -A -f /var/log/sa/sa25 > daily_report.txt

HFT USE CASE: Historical analysis of latency spikes
BEST PRACTICE: Enable sysstat service for 24/7 collection


1.4 GLANCES (Comprehensive Monitor)
------------------------------------

# All-in-one monitoring tool
glances

# Web interface
glances -w

# Export to CSV
glances --export-csv /tmp/glances.csv

# Remote monitoring
glances -s
glances -c 192.168.1.100  # client mode

# Alert thresholds
glances --careful 50 --warning 70 --critical 90

HFT USE CASE: Quick visual overview of all system metrics
PERFORMANCE IMPACT: Higher overhead (~1-2% CPU), avoid on prod


================================================================================
2. CPU MONITORING
================================================================================

2.1 MPSTAT (Multi-Processor Statistics)
----------------------------------------

# All CPU statistics
mpstat -P ALL 1

# JSON output for parsing
mpstat -P ALL -o JSON 1 5

# Specific CPU
mpstat -P 0,1,2 1

OUTPUT INTERPRETATION:
CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
  0    25.00    0.00    5.00    0.00    0.00    1.00    0.00    0.00    0.00   69.00

KEY METRICS:
  %usr  - User space CPU (trading application)
  %sys  - Kernel space CPU (should be < 20%)
  %irq  - Hardware interrupts
  %soft - Software interrupts (network processing)
  %steal - CPU stolen by hypervisor (should be 0)

HFT USE CASE: Per-core CPU utilization for isolated cores
ONE-LINER: Monitor core 2: mpstat -P 2 1 | tail -1


2.2 TURBOSTAT (Intel CPU Performance)
--------------------------------------

# Detailed CPU frequency and power states
turbostat --interval 1

# Show package C-states
turbostat --show Package,Core,CPU,Avg_MHz,Busy%,Bzy_MHz,TSC_MHz

# Monitor specific CPUs
turbostat --cpu 2,3,4,5

OUTPUT SHOWS:
  - Actual CPU frequency
  - C-state residency (should be C0 for trading cores)
  - Turbo boost status
  - Temperature

HFT USE CASE: Verify CPU frequency locked at maximum
SAFETY WARNING: Requires root access


2.3 PERF STAT (Performance Counters)
-------------------------------------

# CPU performance counters
perf stat -a sleep 10

# Specific process
perf stat -p $(pidof trading_engine)

# Detailed CPU events
perf stat -e cycles,instructions,cache-references,cache-misses ./app

# All cache events
perf stat -e L1-dcache-loads,L1-dcache-load-misses,LLC-loads,LLC-load-misses ./app

# Branch prediction
perf stat -e branches,branch-misses ./app

# Context switches
perf stat -e context-switches,cpu-migrations ./app

OUTPUT INTERPRETATION:
 Performance counter stats for './trading_engine':
      15,234,567,890      cycles              # 3.500 GHz
      25,123,456,789      instructions        # 1.65  insn per cycle
         123,456,789      cache-references
           1,234,567      cache-misses        # 1.00% of all cache refs

HFT USE CASE: Identify cache misses and branch mispredictions
BEST PRACTICE: Cache miss rate should be < 3%


2.4 PIDSTAT (Process Statistics)
---------------------------------

# CPU usage by process
pidstat 1

# Specific process
pidstat -p $(pidof trading_engine) 1

# Thread-level statistics
pidstat -t -p $(pidof trading_engine) 1

# Context switches per process
pidstat -w 1

# Page faults
pidstat -r 1

# I/O statistics
pidstat -d 1

# All statistics
pidstat -u -r -d -w 1

HFT USE CASE: Per-thread CPU utilization analysis
ONE-LINER: Top CPU threads: pidstat -t | sort -k 8 -rn | head -10


================================================================================
3. MEMORY MONITORING
================================================================================

3.1 FREE (Memory Overview)
---------------------------

# Display memory usage
free -h

# Update every second
free -h -s 1

# Show high/low memory split
free -l

# Wide output
free -w

OUTPUT:
              total        used        free      shared  buff/cache   available
Mem:           62Gi       15Gi       32Gi       256Mi       14Gi       45Gi
Swap:         8.0Gi          0       8.0Gi

KEY METRICS:
  available - Memory available for applications (most important)
  buff/cache - Memory used for caching (automatically freed when needed)
  swap used - Should be 0 for HFT systems

HFT USE CASE: Quick memory availability check
ONE-LINER: Available memory: free -m | awk 'NR==2{print $7}'


3.2 SMEM (Memory Reporting Tool)
---------------------------------

# Process memory usage
smem -r

# Sort by PSS (Proportional Set Size)
smem -s pss -r

# Per-user summary
smem -u

# Show percentages
smem -p

# Detailed output
smem -t -k

OUTPUT INTERPRETATION:
  USS - Unique Set Size (private memory)
  PSS - Proportional Set Size (shared memory divided)
  RSS - Resident Set Size (total including shared)

HFT USE CASE: Accurate memory usage including shared libraries


3.3 SLABTOP (Kernel Slab Cache)
--------------------------------

# Interactive slab memory monitor
slabtop

# Sort by cache size
slabtop -s c

# One-time display
slabtop -o

# Display in bytes
slabtop -s s

HFT USE CASE: Identify kernel memory leaks
BEST PRACTICE: Monitor dentry and inode cache growth


3.4 NUMASTAT (NUMA Memory Statistics)
--------------------------------------

# Display NUMA hit/miss statistics
numastat

# Per-process NUMA distribution
numastat -p $(pidof trading_engine)

# Memory usage by NUMA node
numastat -m

OUTPUT INTERPRETATION:
                           node0           node1
numa_hit             12345678901       9876543210
numa_miss                 123456          234567
numa_foreign              234567          123456

numa_miss should be < 1% of numa_hit

HFT USE CASE: Verify memory locality for NUMA-bound processes
PERFORMANCE IMPACT: Remote NUMA access adds 40% latency


================================================================================
4. DISK I/O MONITORING
================================================================================

4.1 IOSTAT (I/O Statistics)
----------------------------

# Basic I/O statistics
iostat -x 1

# Device utilization
iostat -xz 1

# Extended statistics with MB
iostat -xm 1

# CPU and I/O combined
iostat -xzc 1

# Specific device
iostat -x sda 1

OUTPUT:
Device  r/s  w/s  rMB/s  wMB/s  avgrq-sz  avgqu-sz  await  r_await  w_await  %util
sda     5.0  10.0  0.50   1.00      307.2      0.05   5.2      4.1      5.8    2.5

KEY METRICS:
  %util   - Device utilization (>80% = bottleneck)
  await   - Average wait time in ms
  avgqu-sz - Average queue size
  r/s, w/s - Read/write operations per second

HFT USE CASE: Identify disk bottlenecks for logging
ONE-LINER: Disk utilization: iostat -x 1 | awk '/sda/{print $NF}'


4.2 IOTOP (I/O by Process)
---------------------------

# Interactive I/O monitor
iotop

# Batch mode
iotop -b -n 3

# Only show active I/O
iotop -o

# Show accumulated I/O
iotop -a

# Processes only (no threads)
iotop -P

# Specific user
iotop -u trading

HFT USE CASE: Identify which process is causing I/O spikes
PERFORMANCE IMPACT: Can add overhead, use sparingly


4.3 BLKTRACE (Block Layer Tracing)
-----------------------------------

# Trace block device activity
blktrace -d /dev/sda -o trace

# View trace
blkparse -i trace

# Real-time monitoring
btrace /dev/sda

# Seek analysis
btt -i trace.blktrace.0

HFT USE CASE: Deep dive into I/O latency issues
SAFETY WARNING: High overhead, development only


================================================================================
5. NETWORK MONITORING
================================================================================

5.1 NETHOGS (Network by Process)
---------------------------------

# Monitor network per process
nethogs

# Specific interface
nethogs eth0

# Trace mode (no refresh)
nethogs -t

# Update interval
nethogs -d 5

HFT USE CASE: Identify which process is using network bandwidth


5.2 IFTOP (Network Interface Monitor)
--------------------------------------

# Interactive network traffic
iftop

# Specific interface
iftop -i eth0

# No hostname resolution
iftop -n

# Show ports
iftop -P

# Filter by network
iftop -F 192.168.1.0/24

HFT USE CASE: Real-time market data feed monitoring
ONE-LINER: Top bandwidth: iftop -t -s 10 -n


5.3 NLOAD (Network Load Monitor)
---------------------------------

# Visual network load
nload

# Specific interface
nload eth0

# Multiple interfaces
nload eth0 eth1

# Set units
nload -u M  # MB/s

HFT USE CASE: Visual representation of network utilization


5.4 NICSTAT (Network Interface Statistics)
-------------------------------------------

# Network interface statistics
nicstat 1

# Show utilization percentage
nicstat -U 1

# Specific interface
nicstat -i eth0 1

OUTPUT:
    Time      Int   rKB/s   wKB/s   rPk/s   wPk/s    rAvs    wAvs   %Util
    10:30:01  eth0  1234.5  567.8   5000    2000     252     290     5.2

HFT USE CASE: Track network utilization vs. capacity


================================================================================
6. PROCESS MONITORING
================================================================================

6.1 PS (Process Status)
------------------------

# All processes with details
ps aux

# Custom format
ps -eo pid,ppid,cmd,pri,ni,rtprio,%cpu,%mem,stat

# Process tree
ps auxf

# Threads for specific process
ps -T -p $(pidof trading_engine)

# Sort by CPU
ps aux --sort=-%cpu | head -20

# Sort by memory
ps aux --sort=-%mem | head -20

# Real-time priority processes
ps -eo pid,cls,rtprio,pri,nice,cmd | grep -E 'FF|RR'

HFT USE CASE: Verify real-time scheduling of trading threads
ONE-LINER: RT processes: ps -eo pid,rtprio,cmd | grep -v ' - '


6.2 PMAP (Process Memory Map)
------------------------------

# Memory map of process
pmap $(pidof trading_engine)

# Extended format
pmap -x $(pidof trading_engine)

# Show device format
pmap -d $(pidof trading_engine)

# Total memory only
pmap -X $(pidof trading_engine) | tail -1

HFT USE CASE: Analyze memory layout and huge page usage
OUTPUT INTERPRETATION: Look for [anon] regions using huge pages


6.3 LSOF (List Open Files)
---------------------------

# All open files
lsof

# By process
lsof -p $(pidof trading_engine)

# Network connections
lsof -i

# Specific port
lsof -i :8080

# Files opened by user
lsof -u trading

# Files in directory
lsof +D /var/log/trading

# Deleted but open files (memory leak indicator)
lsof | grep deleted

HFT USE CASE: Track FIX connections and file descriptors
ONE-LINER: Connection count: lsof -i -a -p $(pidof app) | wc -l


6.4 STRACE (System Call Trace)
-------------------------------

# Trace system calls
strace -p $(pidof trading_engine)

# Summary statistics
strace -c -p $(pidof trading_engine)

# Time each syscall
strace -T -p $(pidof trading_engine)

# Trace specific syscalls
strace -e trace=open,read,write -p $(pidof app)

# Trace network syscalls
strace -e trace=network -p $(pidof app)

# Output to file
strace -o trace.log -p $(pidof app)

HFT USE CASE: Debug unexpected latency spikes
SAFETY WARNING: Very high overhead (10-100x slowdown)


================================================================================
7. REAL-TIME MONITORING DASHBOARDS
================================================================================

7.1 DSTAT (Versatile Resource Statistics)
------------------------------------------

# Comprehensive system stats
dstat

# Custom columns
dstat -cdngy

# Network on specific interface
dstat -N eth0

# Top CPU process
dstat --top-cpu

# Top memory process
dstat --top-mem

# Output to CSV
dstat --output system_stats.csv 1

HFT USE CASE: Single-line comprehensive monitoring
ONE-LINER: dstat -cdnm --top-cpu --top-mem


7.2 NMON (Performance Monitor)
-------------------------------

# Interactive monitoring
nmon

# Key shortcuts:
# c - CPU
# m - Memory
# n - Network
# d - Disk
# t - Top processes
# r - Resources
# q - Quit

# Record mode
nmon -f -s 1 -c 3600  # Record 1 hour

# Generate HTML report
nmonchart nmon_file.nmon output.html

HFT USE CASE: Long-term performance recording and analysis


7.3 ATOP (Advanced System Monitor)
-----------------------------------

# Interactive monitoring
atop

# Store performance data
atop -w /var/log/atop/atop_$(date +%Y%m%d) 10

# Replay stored data
atop -r /var/log/atop/atop_20250125

# Show specific time
atop -r logfile -b 14:30 -e 14:45

HFT USE CASE: Post-mortem analysis of production incidents
BEST PRACTICE: Enable atop service for continuous recording


================================================================================
8. MONITORING SCRIPTS
================================================================================

8.1 COMPREHENSIVE MONITORING SCRIPT
------------------------------------

#!/bin/bash
# HFT System Monitor - Collect all metrics
# Usage: ./hft_monitor.sh [duration_seconds] [interval]

DURATION=${1:-60}
INTERVAL=${2:-1}
OUTPUT_DIR="/var/log/hft_monitoring/$(date +%Y%m%d_%H%M%S)"

mkdir -p $OUTPUT_DIR

echo "Starting HFT system monitoring for ${DURATION}s..."

# CPU monitoring
mpstat -P ALL $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/cpu.log 2>&1 &

# Memory monitoring
vmstat $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/memory.log 2>&1 &

# Disk I/O
iostat -xz $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/io.log 2>&1 &

# Network
sar -n DEV $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/network.log 2>&1 &

# Context switches
pidstat -w $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/context_switches.log 2>&1 &

# Process stats
while [ $SECONDS -lt $DURATION ]; do
    ps -eo pid,ppid,cmd,pri,rtprio,%cpu,%mem >> $OUTPUT_DIR/processes.log
    sleep $INTERVAL
done &

# Trading engine specific (if running)
TRADING_PID=$(pidof trading_engine)
if [ ! -z "$TRADING_PID" ]; then
    pidstat -t -p $TRADING_PID $INTERVAL $((DURATION/INTERVAL)) > $OUTPUT_DIR/trading_threads.log 2>&1 &
fi

wait
echo "Monitoring complete. Data saved to: $OUTPUT_DIR"

# Generate summary
cat > $OUTPUT_DIR/summary.txt <<EOF
Monitoring Summary
==================
Duration: ${DURATION}s
Interval: ${INTERVAL}s
Timestamp: $(date)

Average CPU Usage: $(awk '/all/{sum+=$3; count++} END {print sum/count}' $OUTPUT_DIR/cpu.log)%
Average Context Switches: $(awk '{sum+=$5; count++} END {print int(sum/count)}' $OUTPUT_DIR/memory.log)
Peak Memory Usage: $(awk '{if($3>max) max=$3} END {print max}' $OUTPUT_DIR/memory.log) MB

Files:
$(ls -lh $OUTPUT_DIR)
EOF

cat $OUTPUT_DIR/summary.txt


8.2 LATENCY MONITORING SCRIPT
------------------------------

#!/bin/bash
# Monitor system latency indicators

echo "System Latency Check - $(date)"
echo "================================"

# CPU frequency
echo "CPU Frequencies:"
cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq | awk '{sum+=$1; count++} END {print "Average:", sum/count/1000, "MHz"}'

# Context switches
echo -e "\nContext Switches (per second):"
vmstat 1 2 | tail -1 | awk '{print $12}'

# Interrupts
echo -e "\nInterrupts (per second):"
vmstat 1 2 | tail -1 | awk '{print $11}'

# Network drops
echo -e "\nNetwork Packet Drops:"
netstat -i | awk 'NR>2 {print $1, "RX-DRP:", $4, "TX-DRP:", $8}'

# Swap usage
echo -e "\nSwap Usage:"
free -h | grep Swap

# Isolated CPUs
echo -e "\nIsolated CPUs:"
cat /sys/devices/system/cpu/isolated 2>/dev/null || echo "None"

# Real-time throttling
echo -e "\nRT Throttling:"
cat /proc/sys/kernel/sched_rt_runtime_us

# Huge pages
echo -e "\nHuge Pages:"
grep HugePages /proc/meminfo

# IRQ affinity for eth0
echo -e "\nNIC IRQ Affinity:"
for irq in $(grep eth0 /proc/interrupts | awk -F: '{print $1}'); do
    echo "IRQ $irq: $(cat /proc/irq/$irq/smp_affinity_list 2>/dev/null)"
done


================================================================================
9. ALERTING ONE-LINERS
================================================================================

# Alert if CPU usage > 80%
top -bn1 | awk '/Cpu/ {if ($2 > 80) print "HIGH CPU:", $2}'

# Alert if memory < 1GB free
free -m | awk '/Mem/ {if ($4 < 1024) print "LOW MEMORY:", $4, "MB"}'

# Alert if context switches > 100k/s
vmstat 1 2 | tail -1 | awk '{if ($12 > 100000) print "HIGH CS:", $12}'

# Alert if swap being used
free -m | awk '/Swap/ {if ($3 > 0) print "SWAP USED:", $3, "MB"}'

# Alert if network drops
netstat -i | awk 'NR>2 {if ($4+$8 > 0) print $1, "has drops"}'

# Alert if disk utilization > 80%
iostat -x 1 2 | awk 'NF==12 {if ($NF > 80) print $1, "disk util:", $NF"%"}'

# Alert if load average > CPU count
uptime | awk -F'load average:' '{split($2,a,","); if (a[1] > 16) print "HIGH LOAD:", a[1]}'


================================================================================
BEST PRACTICES
================================================================================

1. Continuous Monitoring
   - Enable sysstat for historical data
   - Use atop for process accounting
   - Set up log rotation for monitoring data

2. Low-Overhead Monitoring
   - Avoid strace in production
   - Use perf sampling mode instead of counting
   - Minimize monitoring interval on production

3. Baseline Establishment
   - Record metrics during normal operation
   - Document expected ranges for all metrics
   - Set alert thresholds based on baselines

4. Incident Response
   - Have monitoring scripts ready
   - Practice data collection procedures
   - Store monitoring data for post-mortems

5. Integration
   - Export metrics to time-series DB (Prometheus/InfluxDB)
   - Create dashboards (Grafana)
   - Automate alerting

================================================================================
PERFORMANCE IMPACT SUMMARY
================================================================================

Tool          Overhead    Use Case
-------------------------------------------------
vmstat        < 0.1%      Continuous monitoring
iostat        < 0.1%      Continuous monitoring
mpstat        < 0.1%      Continuous monitoring
sar           0.1-0.5%    Continuous monitoring
pidstat       0.1-0.5%    Continuous monitoring
top/htop      0.5-1%      Interactive use
perf stat     1-3%        Profiling sessions
strace        10-100x     Debug only
blktrace      5-10%       Debug only

================================================================================
Last Updated: 2025-01-25
Version: 2.0
Maintainer: HFT Engineering Team
================================================================================
