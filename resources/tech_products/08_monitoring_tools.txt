================================================================================
MONITORING AND OBSERVABILITY TOOLS FOR HIGH-FREQUENCY TRADING SYSTEMS
================================================================================
Last Updated: November 2025
Document Version: 1.0
Classification: Technical Reference

================================================================================
TABLE OF CONTENTS
================================================================================
1. Executive Summary
2. DataDog
3. New Relic
4. Splunk
5. Comparative Analysis
6. Setup and Configuration Guides
7. Monthly Costs and Pricing
8. Integration with HFT Systems
9. Alerting and Incident Management
10. Best Practices and Recommendations

================================================================================
1. EXECUTIVE SUMMARY
================================================================================

Comprehensive monitoring and observability are critical for HFT operations,
enabling:
- Real-time system health visibility (servers, network, applications)
- Performance metrics tracking (latency, throughput, order execution)
- Proactive issue detection and alerting
- Historical analysis and trending
- Incident response and troubleshooting
- Capacity planning and optimization
- Compliance and audit logging

Key Monitoring Requirements for HFT:

Infrastructure Monitoring:
  - CPU, memory, disk, network utilization
  - Server hardware health (temperature, fans, power)
  - Network switch port statistics
  - Storage IOPS and latency
  - Power consumption and environmental conditions

Application Performance Monitoring (APM):
  - Order placement latency (microseconds precision)
  - Market data processing speed
  - Strategy execution time
  - Database query performance
  - API response times

Business Metrics:
  - Orders placed per second
  - Fill rates and slippage
  - P&L real-time and cumulative
  - Position tracking
  - Risk metrics (VaR, exposure)

Log Management:
  - Application logs (errors, warnings, info)
  - System logs (syslog, kernel messages)
  - Audit logs (access, changes, compliance)
  - Security logs (authentication, authorization)
  - Log retention (7+ years for regulatory compliance)

Market Overview (2025):
- DataDog: Leading APM, strong infrastructure monitoring, $15-31/host/month
- New Relic: Excellent APM, real-user monitoring, consumption-based pricing
- Splunk: Best log management, SIEM capabilities, $150-200/GB/day
- Industry trend: Shift to unified observability platforms
- Average monitoring spend: 2-5% of infrastructure budget

================================================================================
2. DATADOG
================================================================================

2.1 OVERVIEW
--------------------------------------------------------------------------------
DataDog is a cloud-based monitoring and analytics platform that provides
unified observability across infrastructure, applications, and logs.

Founded: 2010
Headquarters: New York, NY
Market Position: Leading APM vendor (Gartner Leader)
Customer Base: 27,000+ customers including financial services
Deployment: SaaS (cloud-hosted)

Key Strengths for HFT:
  ✓ Real-time metrics (1-second granularity)
  ✓ Excellent API and integration ecosystem (500+ integrations)
  ✓ Custom metrics (essential for trading-specific metrics)
  ✓ Advanced alerting with anomaly detection
  ✓ Beautiful dashboards and visualization
  ✓ Strong APM with distributed tracing
  ✓ Log management and SIEM capabilities

Key Limitations:
  ✗ Cost scales with hosts and custom metrics
  ✗ Cloud-only (no on-premises option for sensitive data)
  ✗ Limited sub-millisecond precision (1-second minimum)
  ✗ Data retention limited (15 months max)

2.2 DATADOG PRODUCTS AND FEATURES
--------------------------------------------------------------------------------
Infrastructure Monitoring:

Agent-Based Monitoring:
  - Lightweight agent (< 1% CPU overhead)
  - Supports: Linux, Windows, containers (Docker, Kubernetes)
  - Metrics collected: CPU, memory, disk, network, processes
  - Collection interval: 10-second default (configurable to 1-second)
  - Agent version: Always use latest (auto-updates available)

Integrations (500+):
  - Linux: sysstat, systemd, network
  - Databases: PostgreSQL, MySQL, TimescaleDB, MongoDB
  - Message Queues: Kafka, RabbitMQ, ZeroMQ
  - Network: SNMP (switches, routers), NetFlow
  - Cloud: AWS, GCP, Azure
  - Custom: StatsD, DogStatsD (UDP metrics)

Features:
  - Live container monitoring
  - Network performance monitoring (NPM)
  - Process monitoring (per-process metrics)
  - Real-time topology maps
  - Service dependencies visualization

Application Performance Monitoring (APM):

Distributed Tracing:
  - Trace application requests end-to-end
  - Identify bottlenecks in microsecond precision
  - Flame graphs for performance analysis
  - Support for C++, Python, Java, Go, Rust

Instrumentation:
  - Automatic (via dd-trace library)
  - Manual (custom spans for critical code paths)
  - Overhead: < 1% typical
  - Sampling: Configurable (100% or intelligent sampling)

Metrics:
  - Request rate (requests per second)
  - Error rate (errors per second)
  - Latency (p50, p75, p95, p99, max)
  - Apdex score (application performance index)

Database Monitoring:
  - Query performance tracking
  - Explain plans for slow queries
  - Lock contention analysis
  - Connection pool monitoring

Log Management:

Log Ingestion:
  - Agent-based collection (files, syslog, journald)
  - Direct API ingestion
  - Cloud integration (CloudWatch, Stackdriver)
  - Formats: JSON, text, structured logs

Log Processing:
  - Parsing and enrichment
  - Filtering and sampling (reduce ingestion costs)
  - Sensitive data scrubbing (PCI, PII)
  - Archival to S3/GCS (long-term retention)

Log Analytics:
  - Full-text search (Lucene syntax)
  - Pattern detection
  - Log-based metrics (count, rate, percentiles)
  - Correlation with metrics and traces

Alerting:

Alert Types:
  - Metric alerts (threshold, anomaly, forecast, outlier)
  - APM alerts (error rate, latency spikes)
  - Log alerts (pattern matching, count)
  - Composite alerts (multi-condition)
  - Synthetic monitoring alerts (API/website uptime)

Anomaly Detection:
  - Machine learning-based
  - Automatic baseline establishment
  - Seasonal pattern recognition
  - Reduces false positives

Alert Routing:
  - Email, SMS, PagerDuty, Slack, OpsGenie
  - Escalation policies
  - On-call schedules
  - Alert de-duplication and grouping

Dashboards:

Pre-Built Dashboards:
  - 500+ integration dashboards
  - Infrastructure overview
  - APM service maps
  - Log analytics

Custom Dashboards:
  - Drag-and-drop widget builder
  - Time series graphs, heatmaps, top lists
  - SLO tracking widgets
  - Embeddable (for NOC screens)
  - API-driven (infrastructure as code)

Templates:
  - Clone and customize existing dashboards
  - Version control (track changes)
  - Role-based access control (RBAC)

Real User Monitoring (RUM):
  - Frontend performance monitoring
  - Not typically used in HFT (no web UI for trading)
  - Useful for internal dashboards and tools

Synthetic Monitoring:
  - API monitoring (uptime and latency)
  - Useful for exchange connectivity checks
  - Pricing: $5 per 10,000 tests

Network Performance Monitoring (NPM):
  - Flow data analysis (NetFlow, sFlow)
  - TCP connection tracking
  - DNS monitoring
  - Latency between services
  - Pricing: $5 per host per month (add-on)

Security Monitoring:
  - SIEM capabilities (Security Information and Event Management)
  - Threat detection
  - Compliance monitoring
  - Pricing: Separate product, $0.20 per GB ingested

2.3 DATADOG PRICING
--------------------------------------------------------------------------------
Pricing Model:
  - Per-host pricing (billed monthly)
  - Host = unique entity with DataDog agent
  - Containers: Count as fractional hosts (based on hours run)
  - Custom metrics: Additional charges
  - Log ingestion: Per GB ingested
  - APM: Included in Pro/Enterprise, add-on for Infrastructure

Infrastructure Monitoring Plans:

Free Tier:
  Price: $0
  Hosts: Up to 5 hosts
  Metrics: 1-day retention
  Integrations: 500+ integrations
  Alerting: Basic alerts
  Limitations: No APM, no logs
  Use Case: Testing, small personal projects

Pro Plan:
  Price: $15 per host per month (annual commitment)
  Price: $18 per host per month (monthly billing)
  
  Features:
    - Unlimited metrics
    - 15-month metric retention
    - Unlimited dashboards
    - Advanced alerting
    - API access
    - 100 custom metrics per host (included)
    - Additional custom metrics: $0.05 per 100 metrics per month
  
  Use Case: Small to medium teams

Enterprise Plan:
  Price: $23 per host per month (annual commitment)
  Price: $31 per host per month (monthly billing)
  
  Features:
    - Everything in Pro
    - 200 custom metrics per host (included)
    - SAML/SSO authentication
    - Audit logs
    - Role-based access control (RBAC)
    - Premium support (1-hour SLA)
    - Custom training
  
  Use Case: Large teams, compliance requirements

Volume Discounts:
  100+ hosts: 5-10% discount
  500+ hosts: 10-20% discount
  1,000+ hosts: 20-30% discount
  Custom pricing for >5,000 hosts

Application Performance Monitoring (APM):

APM Pro:
  Price: $31 per host per month (annual)
  Price: $40 per host per month (monthly)
  
  Features:
    - Distributed tracing
    - Service map
    - Latency breakdown
    - Error tracking
    - 15-day trace retention
    - Indexed spans: 1M per month included
    - Additional indexed spans: $1.70 per million
  
  Note: Requires Infrastructure Pro or Enterprise

APM Enterprise:
  Price: $40 per host per month (annual)
  
  Features:
    - Everything in APM Pro
    - 15-month trace retention
    - Indexed spans: 2M per month included
    - Profiling (CPU, memory)
    - Extended trace retention

Log Management:

Log Ingestion:
  Price: $0.10 per GB ingested (after 150 GB/month minimum)
  Minimum: $150/month
  
  Features:
    - 15-day online retention (searchable)
    - Unlimited archival to S3/GCS (at storage cost)
    - Log-based metrics (count, rate, percentiles)
    - Full-text search
    - Pattern analysis

Indexed Logs (Extended Retention):
  Price: $1.27 per million log events per month
  Retention: 15 days to 15 months (configurable)
  Use Case: Compliance, long-term analysis

Log Archival:
  Price: S3/GCS storage costs only
  Rehydration: $0.10 per GB (bring back into searchable)

Custom Metrics:

Standard Custom Metrics:
  Included: 100 per host (Pro), 200 per host (Enterprise)
  Additional: $0.05 per 100 custom metrics per month
  
  Definition: Any metric not from standard integration
  Examples for HFT:
    - Order placement latency (per venue)
    - Fill rate percentage
    - Strategy P&L
    - Market data message rate
    - Custom risk metrics

High-Cardinality Metrics:
  Price: Higher (contact sales for pricing)
  Use Case: Metrics with many unique tag combinations
  Example: Per-symbol order latency (thousands of symbols)

Pricing Example - Medium HFT Firm:

Configuration:
  - 20 trading servers (Pro plan)
  - 10 trading servers with APM (Pro plan)
  - 500 custom metrics (order latency, P&L, etc.)
  - 100 GB logs per month
  - Annual commitment

Monthly Costs:

Infrastructure Monitoring:
  20 hosts x $15 = $300/month

APM:
  10 hosts x $31 = $310/month

Custom Metrics:
  500 metrics - 100 included = 400 additional
  400 / 100 x $0.05 = $0.20/month (negligible)

Log Management:
  100 GB x $0.10 = $10/month (first 150 GB free)
  Effectively: $0/month (under minimum)

Total Monthly: $610/month
Total Annual: $7,320

Cost per Host: $30.50/month (all-in)

Pricing Example - Large HFT Firm:

Configuration:
  - 100 trading servers (Enterprise plan)
  - 50 servers with APM (Enterprise)
  - 2,000 custom metrics
  - 1 TB logs per month
  - 3-year commitment (15% discount)

Monthly Costs:

Infrastructure Monitoring:
  100 hosts x $23 x 0.85 (discount) = $1,955/month

APM:
  50 hosts x $40 x 0.85 = $1,700/month

Custom Metrics:
  2,000 - 200 included x 100 = 1,800 additional
  1,800 / 100 x $0.05 = $0.90/month

Log Management:
  1,000 GB x $0.10 = $100/month

Network Performance Monitoring:
  100 hosts x $5 = $500/month

Total Monthly: $4,256/month
Total Annual: $51,072

Cost per Host: $42.56/month (all-in)

2.4 DATADOG SETUP GUIDE FOR HFT
--------------------------------------------------------------------------------
Phase 1: Account Setup (Day 1)

1. Sign Up:
   - Choose region (US1, US3, EU, etc.)
   - For HFT: US1 (lowest latency from US colos)
   - Create organization

2. Configure Organization:
   - Set up teams (trading, research, operations)
   - Invite users with appropriate roles
   - Enable SSO (SAML) if using Enterprise
   - Configure two-factor authentication (2FA)

3. API Keys:
   - Generate API key (for agent installation)
   - Generate application keys (for API access)
   - Store securely (vault or secrets manager)

Phase 2: Agent Deployment (Days 2-3)

1. Install DataDog Agent on Servers:

Linux (Ubuntu/Debian):
```bash
DD_API_KEY=<your_api_key> DD_SITE="datadoghq.com" bash -c "$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)"
```

CentOS/RHEL:
```bash
DD_API_KEY=<your_api_key> DD_SITE="datadoghq.com" bash -c "$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script_agent7.sh)"
```

2. Configure Agent:
   - Edit /etc/datadog-agent/datadog.yaml
   - Set hostname (use FQDN or static name)
   - Enable integrations (PostgreSQL, system, network)
   - Set tags (env:prod, role:trading, strategy:alpha)

3. Enable Integrations:

PostgreSQL Example:
   - Edit /etc/datadog-agent/conf.d/postgres.d/conf.yaml
   - Configure database credentials
   - Enable extended metrics (query performance)

System Metrics:
   - Enabled by default
   - Customize collection interval if needed

Network Metrics:
   - Enable conntrack module
   - Requires kernel support

4. Start Agent:
```bash
sudo systemctl start datadog-agent
sudo systemctl enable datadog-agent
sudo datadog-agent status
```

Phase 3: APM Configuration (Days 3-4)

1. Install APM Libraries:

C++ (dd-trace-cpp):
```bash
git clone https://github.com/DataDog/dd-trace-cpp.git
cd dd-trace-cpp
mkdir build && cd build
cmake ..
make && sudo make install
```

Python (ddtrace):
```bash
pip install ddtrace
```

2. Instrument Application:

C++ Example:
```cpp
#include <datadog/tracer.h>

int main() {
    datadog::TracerOptions options;
    options.service_name = "trading-engine";
    options.environment = "production";
    auto tracer = datadog::Tracer(options);
    
    // Trace order placement
    auto span = tracer->StartSpan("place_order");
    span->SetTag("symbol", "AAPL");
    span->SetTag("side", "BUY");
    // ... order logic ...
    span->Finish();
    
    return 0;
}
```

Python Example:
```python
from ddtrace import tracer

@tracer.wrap('place_order')
def place_order(symbol, side, quantity):
    span = tracer.current_span()
    span.set_tag('symbol', symbol)
    span.set_tag('side', side)
    # ... order logic ...
```

3. Configure APM:
   - Set DD_ENV, DD_SERVICE, DD_VERSION environment variables
   - Enable profiling (optional, for deep performance analysis)
   - Configure sampling rate (100% for low volume, intelligent for high)

Phase 4: Custom Metrics (Days 4-5)

1. Install DogStatsD Client:

Python Example:
```python
from datadog import initialize, statsd

options = {
    'statsd_host': '127.0.0.1',
    'statsd_port': 8125
}
initialize(**options)

# Emit custom metrics
statsd.gauge('trading.order.latency', latency_us, tags=['venue:NYSE', 'symbol:AAPL'])
statsd.increment('trading.order.placed', tags=['venue:NYSE'])
statsd.histogram('trading.fill.slippage', slippage_bps)
```

C++ Example (using DogStatsD UDP):
```cpp
#include <sys/socket.h>
#include <netinet/in.h>

void send_metric(const std::string& metric, double value, const std::string& tags) {
    int sock = socket(AF_INET, SOCK_DGRAM, 0);
    struct sockaddr_in addr;
    addr.sin_family = AF_INET;
    addr.sin_port = htons(8125);
    inet_pton(AF_INET, "127.0.0.1", &addr.sin_addr);
    
    std::string msg = metric + ":" + std::to_string(value) + "|g|#" + tags;
    sendto(sock, msg.c_str(), msg.length(), 0, (struct sockaddr*)&addr, sizeof(addr));
    close(sock);
}

// Usage
send_metric("trading.order.latency", latency_us, "venue:NYSE,symbol:AAPL");
```

2. Define Key HFT Metrics:
   - Order latency: Time from signal to order placed (microseconds)
   - Fill latency: Time from order to fill (milliseconds)
   - Market data latency: Time from exchange to system (microseconds)
   - Strategy P&L: Real-time profit/loss per strategy
   - Position: Current positions by symbol
   - Order rate: Orders per second
   - Fill rate: Percentage of orders filled
   - Slippage: Price difference from expected

Phase 5: Log Collection (Days 5-6)

1. Configure Log Collection:
   - Edit /etc/datadog-agent/datadog.yaml
   - Set logs_enabled: true

2. Configure Log Sources:

Application Logs:
```yaml
logs:
  - type: file
    path: /var/log/trading/*.log
    service: trading-engine
    source: cpp
    tags:
      - env:production
      - role:trading
```

Syslog:
```yaml
logs:
  - type: tcp
    port: 10514
    service: system
    source: syslog
```

3. Log Format:
   - Prefer JSON for structured logs
   - Include timestamp, level, message, context
   - Scrub sensitive data (account numbers, PII)

Example JSON Log:
```json
{
  "timestamp": "2025-11-25T12:34:56.789Z",
  "level": "INFO",
  "service": "trading-engine",
  "message": "Order placed successfully",
  "context": {
    "order_id": "ABC123",
    "symbol": "AAPL",
    "side": "BUY",
    "quantity": 100,
    "latency_us": 342
  }
}
```

Phase 6: Dashboards and Alerts (Days 6-7)

1. Create Trading Dashboard:
   - Add widgets for key metrics
   - Order latency time series (by venue)
   - Fill rate gauge
   - P&L cumulative graph
   - Order rate (orders per second)
   - Market data latency heatmap

2. Create Infrastructure Dashboard:
   - CPU utilization by host
   - Memory usage
   - Network throughput
   - Disk I/O
   - Temperature and power (if available via IPMI)

3. Set Up Alerts:

Critical Alerts:
   - Order latency > 5ms for 2 minutes
   - Fill rate < 80% for 5 minutes
   - Market data lag > 1s for 1 minute
   - Server CPU > 95% for 5 minutes
   - Trading application down

High Priority:
   - Order latency > 2ms (p99) for 10 minutes
   - Memory > 85% for 10 minutes
   - Disk > 80% full

Medium Priority:
   - Unusual order rate (anomaly detection)
   - Strategy P&L exceeds expected range
   - Disk I/O saturation

4. Configure Alert Routing:
   - Critical: PagerDuty to on-call engineer
   - High: Slack channel + email
   - Medium: Email only

Phase 7: Validation and Tuning (Days 7-10)

1. Validate Metrics:
   - Verify all hosts reporting
   - Check custom metrics appearing
   - Validate APM traces
   - Confirm logs being ingested

2. Performance Tuning:
   - Adjust agent collection interval (if overhead too high)
   - Configure log sampling (reduce ingestion cost)
   - Tune APM sampling rate
   - Optimize custom metric cardinality

3. Alert Tuning:
   - Review alerts over first week
   - Reduce false positives (adjust thresholds)
   - Add missing alerts
   - Refine escalation policies

2.5 DATADOG BEST PRACTICES FOR HFT
--------------------------------------------------------------------------------
Tagging Strategy:

Required Tags:
  - env: production, staging, development
  - role: trading, research, infrastructure
  - strategy: alpha, beta, gamma (for multi-strategy)
  - venue: NYSE, NASDAQ, CME (for venue-specific metrics)
  - region: us-east, us-central, europe (for multi-region)

Example:
```python
statsd.gauge('order.latency', latency, tags=[
    'env:production',
    'role:trading',
    'strategy:alpha',
    'venue:NYSE',
    'symbol:AAPL'
])
```

Benefits:
  - Filter dashboards by tag
  - Alert on specific subsets (e.g., only production)
  - Chargeback by team/strategy

Metric Naming Convention:

Format: namespace.metric_name
  - trading.order.latency
  - trading.fill.rate
  - trading.pnl.realized
  - market_data.latency
  - strategy.alpha.pnl

Avoid:
  - Inconsistent naming (OrderLatency vs order_latency)
  - Too generic (latency)
  - Too specific (aapl_nyse_buy_order_latency_in_microseconds)

Alert Fatigue Prevention:

Strategies:
  - Use anomaly detection (vs. static thresholds)
  - Require sustained condition (e.g., "for 5 minutes")
  - Implement alert de-duplication
  - Schedule maintenance windows (suppress alerts)
  - Review and refine alerts monthly

Alert Prioritization:
  - Critical: Immediate response required (trading down)
  - High: Response within 1 hour (degraded performance)
  - Medium: Response within 4 hours (potential issue)
  - Low: Review next business day

Cost Optimization:

Reduce Custom Metrics:
  - Avoid high-cardinality tags (e.g., per-order-ID metrics)
  - Use histograms/distributions instead of gauges for every data point
  - Aggregate before sending (e.g., per-minute vs. per-second)

Log Sampling:
  - Sample INFO logs (e.g., 10%)
  - Keep all ERROR and WARN logs (100%)
  - Use log-based metrics for counting (cheaper than indexing)

APM Sampling:
  - Use intelligent sampling for high-volume services
  - Keep 100% of errors
  - Sample 1-10% of successful requests

Security:

Data Scrubbing:
  - Configure agent to scrub sensitive data
  - Use obfuscation for SQL queries (remove values)
  - Never log credentials or API keys
  - Mask PII (personally identifiable information)

Access Control:
  - Use role-based access (RBAC)
  - Limit production access to authorized personnel
  - Audit log reviews quarterly
  - Rotate API keys annually

Network Security:
  - Use TLS for agent communication (default)
  - Whitelist DataDog IPs if firewalled
  - Consider using DataDog private link (AWS/Azure)

================================================================================
3. NEW RELIC
================================================================================

3.1 OVERVIEW
--------------------------------------------------------------------------------
New Relic is a unified observability platform that provides APM, infrastructure
monitoring, and log management with a consumption-based pricing model.

Founded: 2008
Headquarters: San Francisco, CA
Market Position: Leader in APM (Gartner)
Customer Base: 15,000+ customers
Deployment: SaaS (cloud-hosted)

Key Strengths for HFT:
  ✓ Generous free tier (100 GB ingest per month)
  ✓ Consumption-based pricing (predictable costs)
  ✓ Excellent APM (distributed tracing, profiling)
  ✓ Powerful query language (NRQL - SQL-like)
  ✓ Real-time streaming (sub-second data)
  ✓ Unlimited users (no per-seat pricing)
  ✓ Strong ML-powered insights

Key Limitations:
  ✗ Less mature infrastructure monitoring vs. DataDog
  ✗ Fewer integrations (200+ vs. DataDog's 500+)
  ✗ Steeper learning curve for NRQL
  ✗ Data retention limited (8 days default, up to 13 months)

3.2 NEW RELIC PRODUCTS AND FEATURES
--------------------------------------------------------------------------------
Application Performance Monitoring (APM):

Language Support:
  - C/C++, Java, .NET, Python, Ruby, Go, Node.js, PHP
  - Auto-instrumentation for supported frameworks
  - Manual instrumentation for custom code

Distributed Tracing:
  - End-to-end request tracking
  - Cross-service visibility
  - Latency breakdown by component
  - Error tracking and analysis

Transaction Tracing:
  - Detailed timing for slow transactions
  - Database query analysis
  - External service calls
  - Custom attribute tracking

Profiling:
  - Thread profiling (identify CPU bottlenecks)
  - Memory profiling (find memory leaks)
  - Low overhead (< 3% typical)

Infrastructure Monitoring:

Agent-Based:
  - New Relic Infrastructure agent
  - Lightweight (< 1% CPU, < 100 MB RAM)
  - Metrics: CPU, memory, disk, network, processes
  - Collection: 10-second default interval

Integrations (200+):
  - Cloud: AWS, Azure, GCP
  - Databases: PostgreSQL, MySQL, MongoDB, Redis
  - Message Queues: Kafka, RabbitMQ
  - Containers: Docker, Kubernetes
  - Network: SNMP

Host Metrics:
  - Per-process CPU and memory
  - Disk I/O per mount point
  - Network per interface
  - Custom attributes

Log Management:

Log Ingestion:
  - Infrastructure agent (file tailing)
  - Fluent Bit / Fluentd
  - Logstash
  - Direct API (JSON over HTTPS)
  - Cloud integrations (CloudWatch, Stackdriver)

Log Processing:
  - Parsing (Grok, regex)
  - Enrichment (add context from APM)
  - Filtering and dropping (cost control)
  - Obfuscation (sensitive data)

Log Analysis:
  - NRQL queries (SQL-like syntax)
  - Pattern analysis
  - Log-based metrics
  - Correlation with APM and infrastructure

Alerts and Applied Intelligence:

Alert Conditions:
  - Static thresholds
  - Anomaly detection (baseline and outlier)
  - NRQL alerts (custom queries)
  - Composite conditions (multi-signal)

Applied Intelligence:
  - Machine learning for anomaly detection
  - Incident correlation (group related alerts)
  - Root cause analysis
  - Proactive detection (predict issues)

Alert Routing:
  - Email, Slack, PagerDuty, OpsGenie, webhooks
  - Workflows (multi-step notification)
  - Muting rules (suppress during maintenance)

Dashboards and Visualization:

Pre-Built Dashboards:
  - APM service dashboards
  - Infrastructure host dashboards
  - Integration-specific dashboards

Custom Dashboards:
  - NRQL-based widgets
  - Time series charts, billboard metrics, tables
  - Markdown for documentation
  - Template variables
  - TV mode (full-screen for NOC)

Querying:
  - NRQL (New Relic Query Language)
  - Similar to SQL with time-series extensions
  - Powerful aggregation and filtering
  - Example: `SELECT average(duration) FROM Transaction WHERE appName='trading-engine' FACET name SINCE 1 hour ago`

Synthetic Monitoring:
  - API monitoring (uptime and response time)
  - Scripted browser tests
  - Private locations (run from your infrastructure)
  - Pricing: Included in consumption

Browser Monitoring (RUM):
  - Real user monitoring for web applications
  - Not typically used in HFT
  - Useful for internal tools and dashboards

Mobile Monitoring:
  - iOS and Android app monitoring
  - Not applicable to HFT systems

3.3 NEW RELIC PRICING
--------------------------------------------------------------------------------
Pricing Model (Consumption-Based):

New Relic One Pricing (Introduced 2020):
  - Pay for data ingested (GB per month)
  - Unlimited users (no per-seat fees)
  - Unlimited hosts (no per-host fees)
  - Flat rate per GB ingested

Pricing Tiers:

Free Tier:
  Price: $0
  Data Ingest: 100 GB per month (included)
  Users: 1 full platform user, unlimited basic users
  Data Retention: 8 days
  Features: Full platform access
  Use Case: Small teams, evaluation, development

Standard Tier (Pay-As-You-Go):
  Price: $0.30 per GB ingested (after free 100 GB)
  Users: Pay per user
    - Full Platform User: $99 per user per month
    - Core User: $49 per user per month (limited features)
  Data Retention: 8 days (extended retention available)
  Features: Full platform, no commitments
  Use Case: Variable workloads, growing teams

Pro Tier (Annual Commitment):
  Price: $0.30 per GB ingested (estimate, volume discounts apply)
  Users: Included
    - Full Platform Users: Included based on commit level
    - Example: 10 users included with $300/month commit
  Data Retention: 30 days (default), up to 13 months (configurable)
  Features:
    - Advanced security features
    - SAML/SSO
    - Vulnerability Management
    - Errors Inbox
  Commitment: Annual, with overages billed monthly
  Use Case: Predictable workloads, larger teams

Enterprise Tier:
  Price: Custom (volume discounts)
  Users: Unlimited full platform users
  Data Retention: Up to 13 months
  Features:
    - Everything in Pro
    - Streaming data export
    - Advanced data governance
    - Priority support (1-hour SLA)
    - Custom training
  Commitment: Annual, minimum $50,000/year
  Use Case: Large enterprises, high data volumes

Data Ingest Rates:

What Counts as "Data Ingested":
  - APM traces and spans
  - Infrastructure metrics
  - Logs
  - Custom events
  - Browser and mobile data (if used)
  - Synthetic monitoring results

Typical Ingest Rates (HFT Context):

Per Host:
  - Infrastructure agent: 1-2 GB/month (default metrics)
  - APM (high-volume service): 10-50 GB/month
  - Logs (moderate): 10-30 GB/month
  - Custom events: 1-10 GB/month
  - Total per host: 20-90 GB/month typical

Cost Optimization:
  - Drop unnecessary logs (sampling)
  - Reduce APM sampling rate
  - Limit custom event attributes
  - Use drop rules for redundant data

Extended Data Retention:

Default:
  - Free tier: 8 days
  - Standard/Pro: 30 days (default)

Extended Retention (Add-On):
  - Up to 13 months: $0.05 per GB per month
  - Example: 1 TB retained for 13 months = $50/month

Use Cases:
  - Compliance (require logs for 7+ years)
  - Historical analysis (long-term trending)
  - Note: Consider exporting to cheaper storage (S3) for > 13 months

Volume Discounts:

Data Ingest:
  - 0-100 GB: Free
  - 100-1,000 GB: $0.30/GB
  - 1-10 TB: ~$0.25/GB (negotiate)
  - 10-100 TB: ~$0.20/GB (negotiate)
  - 100+ TB: Custom pricing (often < $0.15/GB)

Commitment Discounts:
  - Annual commitment: 5-15% discount
  - Multi-year: 15-25% discount

Pricing Example - Medium HFT Firm:

Configuration:
  - 20 trading servers
  - APM on all 20 servers
  - Moderate log volume
  - 5 full platform users
  - Standard tier (pay-as-you-go)

Monthly Data Ingest:
  Infrastructure (20 hosts x 2 GB): 40 GB
  APM (20 hosts x 30 GB): 600 GB
  Logs (20 hosts x 20 GB): 400 GB
  Custom events (10 GB): 10 GB
  Total: 1,050 GB

Monthly Costs:
  Data Ingest: (1,050 GB - 100 GB free) x $0.30 = $285
  Users: 5 x $99 = $495
  Total: $780/month

Annual Cost: $9,360

Cost per Host: $39/month

Pricing Example - Large HFT Firm:

Configuration:
  - 100 trading servers
  - APM on all servers
  - High log volume
  - 20 full platform users
  - Pro tier (annual commitment)
  - Volume discount (15%)

Monthly Data Ingest:
  Infrastructure: 100 x 2 GB = 200 GB
  APM: 100 x 40 GB = 4,000 GB
  Logs: 100 x 30 GB = 3,000 GB
  Custom events: 100 GB
  Total: 7,300 GB

Monthly Costs:
  Data Ingest: 7,300 GB x $0.30 x 0.85 (discount) = $1,862
  Users: 20 included (with commit level)
  Extended Retention (3 months): 7,300 GB x 2 months x $0.05 = $730
  Total: $2,592/month

Annual Cost: $31,104

Cost per Host: $25.92/month

3.4 NEW RELIC SETUP GUIDE FOR HFT
--------------------------------------------------------------------------------
Phase 1: Account Setup (Day 1)

1. Sign Up:
   - Create New Relic account (choose region: US or EU)
   - Select pricing tier (Free to start, upgrade later)
   - Set up organization

2. User Management:
   - Add team members
   - Assign roles (Admin, Standard, Read-only)
   - Enable SSO (SAML) if using Pro/Enterprise

3. API Keys:
   - Generate License Key (for agent installation)
   - Generate User API Key (for API access)
   - Store securely

Phase 2: Infrastructure Agent Deployment (Days 2-3)

1. Install Infrastructure Agent:

Linux (Ubuntu/Debian):
```bash
curl -Ls https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add -
echo "deb https://download.newrelic.com/infrastructure_agent/linux/apt $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/newrelic-infra.list
sudo apt-get update
sudo apt-get install newrelic-infra -y
```

2. Configure Agent:
   - Edit /etc/newrelic-infra.yml
   - Set license_key
   - Set display_name (hostname)
   - Add custom_attributes (tags)

Example Configuration:
```yaml
license_key: YOUR_LICENSE_KEY
display_name: trading-server-01
custom_attributes:
  environment: production
  role: trading
  strategy: alpha
  region: us-east
```

3. Enable Integrations:

PostgreSQL:
```bash
sudo apt-get install nri-postgresql
```

Configure /etc/newrelic-infra/integrations.d/postgresql-config.yml:
```yaml
integrations:
  - name: nri-postgresql
    env:
      USERNAME: newrelic
      PASSWORD: <password>
      HOSTNAME: localhost
      PORT: 5432
      DATABASE: trading_db
      COLLECT_DB_LOCK_METRICS: true
      COLLECT_BLOAT_METRICS: true
```

4. Start Agent:
```bash
sudo systemctl restart newrelic-infra
sudo systemctl enable newrelic-infra
```

Phase 3: APM Instrumentation (Days 3-5)

1. Install APM Agent:

C/C++ (requires manual instrumentation):
   - Use New Relic C SDK
   - Link against libnewrelic.so

Python:
```bash
pip install newrelic
```

2. Configure APM:

Python:
   - Generate config: `newrelic-admin generate-config YOUR_LICENSE_KEY newrelic.ini`
   - Edit newrelic.ini (set app_name, environment)

C++:
```cpp
#include "libnewrelic.h"

int main() {
    newrelic_init("trading-engine", "YOUR_LICENSE_KEY");
    
    // Create transaction
    newrelic_txn_t* txn = newrelic_start_transaction("place_order");
    
    // Add custom attributes
    newrelic_add_attribute_string(txn, "symbol", "AAPL");
    newrelic_add_attribute_string(txn, "venue", "NYSE");
    
    // ... order placement logic ...
    
    // End transaction
    newrelic_end_transaction(&txn);
    
    return 0;
}
```

3. Deploy Instrumented Application:
   - Test in staging first
   - Monitor overhead (< 3% expected)
   - Roll out to production gradually

Phase 4: Log Forwarding (Days 5-6)

1. Option 1: Infrastructure Agent (File Tailing):

Edit /etc/newrelic-infra/logging.d/logs.yml:
```yaml
logs:
  - name: trading-logs
    file: /var/log/trading/*.log
    attributes:
      application: trading-engine
      environment: production
```

2. Option 2: Fluent Bit (More Flexible):

Install Fluent Bit:
```bash
curl https://raw.githubusercontent.com/fluent/fluent-bit/master/install.sh | sh
```

Configure Fluent Bit to forward to New Relic:
```conf
[OUTPUT]
    Name  newrelic
    Match *
    licenseKey YOUR_LICENSE_KEY
```

3. Log Format:
   - JSON preferred for structured parsing
   - Include context (service, environment, trace ID)

Phase 5: Custom Events and Metrics (Days 6-7)

1. Install Telemetry SDK:

Python:
```bash
pip install newrelic-telemetry-sdk
```

2. Send Custom Events:

Python Example:
```python
from newrelic_telemetry_sdk import Event, EventClient

event_client = EventClient(insert_key="YOUR_INSERT_KEY")

# Send order placement event
event = Event(
    "OrderPlaced",
    {
        "symbol": "AAPL",
        "venue": "NYSE",
        "latency_us": 342,
        "strategy": "alpha"
    }
)
event_client.send(event)
```

C++ Example (using HTTP API):
```cpp
#include <curl/curl.h>
#include <json.hpp>

void send_event(const std::string& event_type, const nlohmann::json& attributes) {
    nlohmann::json payload = {
        {"eventType", event_type},
        {"timestamp", std::time(nullptr) * 1000},
        {"attributes", attributes}
    };
    
    CURL* curl = curl_easy_init();
    curl_easy_setopt(curl, CURLOPT_URL, "https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events");
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, {"X-Insert-Key: YOUR_INSERT_KEY", "Content-Type: application/json"});
    curl_easy_setopt(curl, CURLOPT_POSTFIELDS, payload.dump().c_str());
    curl_easy_perform(curl);
    curl_easy_cleanup(curl);
}

// Usage
send_event("OrderPlaced", {{"symbol", "AAPL"}, {"latency_us", 342}});
```

3. Define Key HFT Events:
   - OrderPlaced (symbol, venue, latency)
   - OrderFilled (symbol, price, slippage)
   - StrategySignal (strategy, symbol, signal)
   - MarketDataReceived (symbol, latency)
   - PositionChange (symbol, quantity, value)

Phase 6: Dashboards and Alerts (Days 7-10)

1. Create Custom Dashboard:
   - Navigate to Dashboards → Create Dashboard
   - Add widgets using NRQL queries

Example NRQL Queries:

Average Order Latency:
```sql
SELECT average(latency_us) FROM OrderPlaced 
WHERE venue='NYSE' 
FACET symbol 
SINCE 1 hour ago 
TIMESERIES
```

Orders Per Second:
```sql
SELECT count(*) FROM OrderPlaced 
SINCE 1 hour ago 
TIMESERIES AUTO
```

Fill Rate:
```sql
SELECT (count(*) FROM OrderFilled) / (count(*) FROM OrderPlaced) * 100 
AS 'Fill Rate %' 
SINCE 1 hour ago
```

P&L by Strategy:
```sql
SELECT sum(pnl) FROM Trade 
FACET strategy 
SINCE 1 day ago
```

2. Set Up Alert Conditions:

NRQL Alert Example (High Latency):
```sql
SELECT average(latency_us) FROM OrderPlaced 
WHERE venue='NYSE'
```
- Condition: Above 5,000 for at least 5 minutes
- Severity: Critical
- Notification: PagerDuty

Anomaly Alert Example:
- Use Applied Intelligence to detect unusual order rates
- Automatically baseline and alert on deviations

3. Configure Notification Channels:
   - Email
   - Slack
   - PagerDuty
   - Webhooks (custom integrations)

Phase 7: Optimization (Days 10-14)

1. Data Ingest Optimization:
   - Review data ingest by source
   - Drop unnecessary logs (use drop rules)
   - Sample high-volume events (if not critical)
   - Reduce APM sample rate (if very high volume)

2. Query Optimization:
   - Optimize NRQL queries (use WHERE clauses, limit FACET cardinality)
   - Cache dashboard results (use auto-refresh sparingly)

3. Alert Tuning:
   - Review alert history (reduce false positives)
   - Adjust thresholds based on baseline
   - Implement muting rules for known maintenance

3.5 NEW RELIC BEST PRACTICES FOR HFT
--------------------------------------------------------------------------------
Data Modeling:

Event Types:
  - Use specific event types (OrderPlaced vs. generic Event)
  - Consistent naming (PascalCase recommended)
  - Include essential attributes (timestamp, strategy, venue, symbol)

Attributes:
  - Keep attributes lean (only necessary data)
  - Use consistent data types (numbers as numbers, not strings)
  - Tag with context (environment, strategy, host)

Example Event Model:
```json
{
  "eventType": "OrderPlaced",
  "timestamp": 1700000000000,
  "symbol": "AAPL",
  "venue": "NYSE",
  "strategy": "alpha",
  "latency_us": 342,
  "order_id": "ABC123",
  "side": "BUY",
  "quantity": 100
}
```

Query Optimization:

Best Practices:
  - Use WHERE clauses to filter early
  - Limit FACET cardinality (< 1,000 unique values)
  - Use TIMESERIES for trend visualization
  - Avoid SELECT * (specify attributes)
  - Use SINCE/UNTIL for time ranges (vs. querying all data)

Example Optimized Query:
```sql
SELECT average(latency_us) AS 'Avg Latency (us)'
FROM OrderPlaced
WHERE venue='NYSE' AND strategy='alpha'
FACET symbol
SINCE 1 hour ago
LIMIT 10
```

Cost Management:

Monitor Data Ingest:
  - Dashboard widget: `SELECT bytecountestimate() FROM Event SINCE 1 day ago FACET eventType`
  - Set up alerts for unusual ingest spikes
  - Review monthly ingest reports

Reduce Ingest:
  - Drop logs: Use drop rules in log forwarder
  - Sample events: Sample non-critical events (e.g., 10%)
  - Limit attributes: Only include necessary attributes
  - Aggregate: Send aggregated metrics instead of raw events (where appropriate)

Security:

API Key Management:
  - Rotate API keys annually
  - Use separate keys for prod/dev
  - Store keys in secrets manager (not code)

Data Obfuscation:
  - Obfuscate SQL queries (remove sensitive values)
  - Drop sensitive log lines (credit cards, SSNs)
  - Use obfuscation rules in agent config

Access Control:
  - Use RBAC (role-based access control)
  - Limit production access (read-only for most users)
  - Audit user activity quarterly

================================================================================
4. SPLUNK
================================================================================

4.1 OVERVIEW
--------------------------------------------------------------------------------
Splunk is the leading log management and SIEM (Security Information and Event
Management) platform, known for its powerful search and analysis capabilities.

Founded: 2003
Headquarters: San Francisco, CA
Market Position: Leader in Log Management and SIEM
Customer Base: 20,000+ customers (many in financial services)
Deployment: On-Premises, Cloud (Splunk Cloud Platform), Hybrid

Key Strengths for HFT:
  ✓ Best-in-class log management and search
  ✓ Powerful Search Processing Language (SPL)
  ✓ Excellent for security and compliance
  ✓ On-premises option (for sensitive data)
  ✓ Mature product (20+ years)
  ✓ Strong in regulated industries (finance, healthcare)
  ✓ Extensive third-party integrations

Key Limitations:
  ✗ Expensive (highest cost of three providers)
  ✗ Complex licensing (many SKUs)
  ✗ Infrastructure monitoring less mature (vs. DataDog)
  ✗ APM less competitive (vs. New Relic, DataDog)
  ✗ Steeper learning curve

4.2 SPLUNK PRODUCTS AND FEATURES
--------------------------------------------------------------------------------
Splunk Enterprise (Core Platform):

Log Ingestion:
  - Universal Forwarder (lightweight agent)
  - Heavy Forwarder (parsing and filtering)
  - HTTP Event Collector (API ingestion)
  - Syslog input
  - File monitoring (tail files)
  - Cloud integrations (CloudWatch, Stackdriver)

Search and Analysis:
  - Search Processing Language (SPL)
  - Real-time search (as data arrives)
  - Historical search (indexed data)
  - Regex and field extraction
  - Statistical commands (stats, chart, timechart)

Indexing:
  - Distributed indexing (scale horizontally)
  - Index replication (data redundancy)
  - Retention policies (time-based, size-based)
  - Acceleration (summary indexes, data models)

Dashboards and Visualization:
  - Pre-built dashboards
  - Custom dashboards (XML or UI builder)
  - Forms (user inputs, filters)
  - Chart types: line, area, bar, pie, maps, gauges
  - Drill-downs (interactive)

Alerting:
  - Scheduled searches (run periodically, alert on results)
  - Real-time alerts (continuous search)
  - Throttling (prevent alert fatigue)
  - Alert actions: email, webhook, script, PagerDuty

Splunk Enterprise Security (ES):

SIEM Capabilities:
  - Security monitoring and threat detection
  - Correlation searches (multi-source alerts)
  - Risk-based alerting (assign risk scores)
  - Incident response (case management)
  - Compliance reporting (PCI-DSS, HIPAA, SOX)

Use Cases for HFT:
  - Detect unauthorized access to trading systems
  - Monitor for insider threats
  - Audit trading activity (regulatory compliance)
  - Alert on suspicious patterns

Pricing:
  - Separate license from Splunk Enterprise
  - Based on indexed data volume (similar to Enterprise)
  - Typically 2-3x cost of base Splunk Enterprise

Splunk IT Service Intelligence (ITSI):

Service-Centric Monitoring:
  - Define business services (e.g., "Trading System")
  - Monitor health of services (KPIs)
  - Dependency mapping (service dependencies)
  - Predictive analytics (forecast issues)

Use Cases for HFT:
  - Monitor overall trading system health
  - Track KPIs (order latency, fill rate, uptime)
  - Alert on service degradation

Pricing:
  - Workload-based pricing (different from data volume)
  - Typically $10,000-50,000/year for small-medium deployments

Splunk Infrastructure Monitoring (formerly SignalFx):

Real-Time Metrics:
  - Time-series metrics (not logs)
  - Sub-second data (high resolution)
  - Auto-discovery of infrastructure
  - OpenTelemetry support

Pricing:
  - Per-host pricing (similar to DataDog)
  - $15-50 per host per month depending on tier

Note: Acquired by Splunk in 2019, still operates somewhat independently

Splunk APM:

Application Tracing:
  - Distributed tracing (end-to-end)
  - Service map
  - Error tracking
  - Code profiling

Pricing:
  - Per-host pricing
  - ~$55-100 per host per month

Note: Also from SignalFx acquisition, less mature than DataDog/New Relic APM

Splunk Cloud Platform:

SaaS Version:
  - Fully managed Splunk Enterprise
  - No infrastructure to manage
  - Same features as on-premises
  - Automatic upgrades

Pricing:
  - Workload-based (ingest, search, storage)
  - Often more expensive than self-hosted
  - Predictable costs (no hardware capex)

4.3 SPLUNK PRICING
--------------------------------------------------------------------------------
Pricing Models:

Splunk offers multiple pricing models, which can be confusing:

1. Term License (Traditional):
   - Pay for daily indexing volume
   - Perpetual or annual term
   - Peak daily volume (not average)

2. Ingest Pricing:
   - Pay for data ingested (GB per day)
   - Predictable for consistent workloads

3. Workload Pricing (Splunk Cloud):
   - Pay for ingest, search, and storage separately
   - More granular control

4. Infrastructure Monitoring:
   - Per-host pricing (separate from log management)

Splunk Enterprise - Term License:

Pricing (Annual):

$150 per GB per day:
  100 GB/day: $15,000/year
  500 GB/day: $75,000/year
  1 TB/day: $150,000/year

Volume Discounts:
  - 100-500 GB/day: ~$150/GB/day
  - 500 GB-1 TB/day: ~$125/GB/day
  - 1-5 TB/day: ~$100/GB/day
  - 5+ TB/day: Custom pricing (~$75-90/GB/day)

Key Considerations:
  - "Per day" means peak daily volume (not average)
  - If you spike to 1 TB one day, you pay for 1 TB/day license
  - Overage fees if you exceed licensed volume (up to 5%, then blocked)

Splunk Enterprise - Perpetual License:

One-Time Cost:
  - Typically 3x annual term license
  - Example: 100 GB/day = $45,000 (perpetual)
  - Plus annual maintenance (20% of license): $9,000/year

Total 3-Year Cost:
  - Perpetual: $45,000 + ($9,000 x 3) = $72,000
  - Term (annual): $15,000 x 3 = $45,000

Verdict: Term license usually more economical for HFT (infrastructure changes)

Splunk Cloud Platform - Workload Pricing:

Ingest:
  $200 per GB per day (annual commitment)

Search:
  Splunk Virtual Compute (SVC)
  - Small: $540/month per SVC
  - Medium: $1,080/month per SVC
  - Large: $2,160/month per SVC

Storage:
  $0.11 per GB per month (searchable)
  $0.035 per GB per month (archived)

Example Cost (100 GB/day):
  Ingest: 100 GB/day x $200 = $20,000/year ($1,667/month)
  Search (2 medium SVCs): $1,080 x 2 = $2,160/month
  Storage (searchable, 30 days): 100 GB x 30 days x $0.11 = $330/month
  Total: $4,157/month or $49,884/year

Compare to On-Premises:
  - Splunk Enterprise (100 GB/day): $15,000/year
  - Splunk Cloud: $49,884/year
  - Cloud is 3.3x more expensive
  - But: No hardware, no management overhead

Splunk Infrastructure Monitoring:

Host-Based Pricing:

$18 per host per month (Infrastructure Monitoring only)
$25 per host per month (Infrastructure + Custom Metrics)

Enterprise:
  $50 per host per month (includes advanced features)

Splunk APM:

$55 per host per month (APM Pro)
$100 per host per month (APM Enterprise)

Note: Separate from log management; can be bundled for discounts

Total Cost Example - Medium HFT Firm:

Configuration:
  - 20 trading servers
  - Log volume: 200 GB per day average (300 GB peak)
  - Splunk Enterprise (on-premises)
  - Splunk Infrastructure Monitoring (20 hosts)
  - Splunk APM (10 hosts)
  - Annual term

Annual Costs:

Splunk Enterprise:
  300 GB/day x $150 = $45,000/year

Infrastructure Monitoring:
  20 hosts x $18 x 12 = $4,320/year

APM:
  10 hosts x $55 x 12 = $6,600/year

Total Annual: $55,920

Monthly Equivalent: $4,660

Cost per Host: $233/month

Note: This is 5-7x more expensive than DataDog or New Relic for equivalent monitoring

Total Cost Example - Large HFT Firm:

Configuration:
  - 100 trading servers
  - Log volume: 1 TB per day average (1.5 TB peak)
  - Splunk Enterprise (on-premises cluster)
  - Splunk Infrastructure Monitoring (100 hosts)
  - Splunk APM (50 hosts)
  - Splunk Enterprise Security (SIEM)
  - Multi-year commitment (20% discount)

Annual Costs:

Splunk Enterprise:
  1.5 TB/day x $100 (volume discount) x 0.8 (commitment) = $120,000/year

Infrastructure Monitoring:
  100 hosts x $18 x 12 x 0.8 = $17,280/year

APM:
  50 hosts x $55 x 12 x 0.8 = $26,400/year

Enterprise Security (ES):
  ~2.5x base license: $300,000/year

Total Annual: $463,680

Monthly Equivalent: $38,640

Cost per Host: $386/month

Note: Extremely expensive, but comprehensive (especially for compliance)

4.4 SPLUNK SETUP GUIDE FOR HFT
--------------------------------------------------------------------------------
Phase 1: Splunk Enterprise Deployment (Week 1-2)

1. Architecture Design:

Small Deployment (< 100 GB/day):
  - Single Splunk instance (all-in-one)
  - Indexer, Search Head, Deployment Server on one machine

Medium Deployment (100-500 GB/day):
  - Distributed architecture:
    - 1-2 Search Heads (user interface)
    - 3-5 Indexers (data storage and search)
    - 1 Deployment Server (manage forwarders)
    - 1 License Master

Large Deployment (500 GB+/day):
  - Full clustering:
    - Search Head Cluster (3+ nodes)
    - Indexer Cluster (6+ nodes, replication factor 3)
    - Cluster Master
    - Deployment Server
    - License Master

2. Install Splunk Enterprise:

Linux (Ubuntu/CentOS):
```bash
wget -O splunk.tgz 'https://download.splunk.com/products/splunk/releases/9.1.0/linux/splunk-9.1.0-linux-x86_64.tgz'
tar xvzf splunk.tgz -C /opt
/opt/splunk/bin/splunk start --accept-license
```

Initial Setup:
  - Access web UI: http://server:8000
  - Set admin password
  - Configure licensing (upload license file)

3. Configure Indexers:

Create Indexes (data segregation):
  - trading_logs (trading application logs)
  - system_logs (OS logs)
  - security_logs (auth, audit logs)
  - market_data (market data logs)

Index Settings:
  - Retention: 30-90 days online, archive to S3 for long-term
  - Replication: Factor 3 (for clustered indexers)
  - Max size: Monitor disk space (alert at 80% full)

4. Configure Search Heads:
  - Install apps (Splunk App for Infrastructure, etc.)
  - Configure user roles and permissions
  - Set up search head clustering (if using)

Phase 2: Forwarder Deployment (Week 2-3)

1. Install Universal Forwarder on Servers:

Linux:
```bash
wget -O splunkforwarder.tgz 'https://download.splunk.com/products/universalforwarder/releases/9.1.0/linux/splunkforwarder-9.1.0-linux-x86_64.tgz'
tar xvzf splunkforwarder.tgz -C /opt
/opt/splunkforwarder/bin/splunk start --accept-license --answer-yes --no-prompt --seed-passwd <password>
```

2. Configure Forwarder:

Edit /opt/splunkforwarder/etc/system/local/outputs.conf:
```conf
[tcpout]
defaultGroup = indexers

[tcpout:indexers]
server = indexer1:9997, indexer2:9997, indexer3:9997
```

3. Add Data Inputs:

Monitor Files:
Edit /opt/splunkforwarder/etc/system/local/inputs.conf:
```conf
[monitor:///var/log/trading/*.log]
disabled = false
index = trading_logs
sourcetype = trading_app

[monitor:///var/log/syslog]
disabled = false
index = system_logs
sourcetype = syslog
```

Monitor Application Logs:
```conf
[monitor:///opt/trading/logs/orders.log]
index = trading_logs
sourcetype = order_log
```

4. Deploy Configuration at Scale:
   - Use Deployment Server to push configs to all forwarders
   - Group forwarders by role (trading, infrastructure, dev)
   - Automatically deploy to new servers

Phase 3: Data Onboarding and Parsing (Week 3-4)

1. Define Source Types:

Create props.conf for custom log parsing:
```conf
[trading_app]
SHOULD_LINEMERGE = false
LINE_BREAKER = ([\r\n]+)\d{4}-\d{2}-\d{2}
TRUNCATE = 10000
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S.%3N
MAX_TIMESTAMP_LOOKAHEAD = 23
```

2. Field Extraction:

Create transforms.conf for field extraction:
```conf
[extract_order_fields]
REGEX = symbol=(\w+)\s+venue=(\w+)\s+latency=(\d+)
FORMAT = symbol::$1 venue::$2 latency::$3
```

Apply in props.conf:
```conf
[trading_app]
TRANSFORMS-order = extract_order_fields
```

3. Validate Data:
   - Search for new data: `index=trading_logs`
   - Verify field extraction: `index=trading_logs | table _time, symbol, venue, latency`
   - Check data volume: `index=trading_logs | stats count by sourcetype`

Phase 4: Dashboards and Reports (Week 4-5)

1. Create Trading Dashboard:

Example SPL Queries:

Order Latency Over Time:
```spl
index=trading_logs sourcetype=order_log
| timechart avg(latency) by venue
```

Orders Per Second:
```spl
index=trading_logs sourcetype=order_log
| timechart count as orders span=1s
```

Fill Rate:
```spl
index=trading_logs
| stats count(eval(status="filled")) as filled, count as total
| eval fill_rate = (filled / total) * 100
```

P&L by Strategy:
```spl
index=trading_logs sourcetype=pnl_log
| stats sum(pnl) by strategy
| sort -sum(pnl)
```

Top Traded Symbols:
```spl
index=trading_logs sourcetype=order_log
| stats count by symbol
| sort -count
| head 20
```

2. Save as Dashboard:
   - Navigate to Dashboards → Create New Dashboard
   - Add panels with SPL queries
   - Configure visualizations (charts, gauges, tables)
   - Set refresh interval (real-time or periodic)

3. Schedule Reports:
   - Daily trading summary email (sent at market close)
   - Weekly performance report (P&L, fill rates, latency stats)
   - Monthly compliance report (audit trail, security events)

Phase 5: Alerting (Week 5-6)

1. Create Real-Time Alerts:

High Latency Alert:
```spl
index=trading_logs sourcetype=order_log latency>5000
| stats avg(latency) as avg_latency by venue
| where avg_latency > 5000
```
- Run: Real-time
- Trigger: Per result
- Action: Email, PagerDuty

Trading System Down:
```spl
index=trading_logs sourcetype=heartbeat
| stats count by host
| where count = 0
```
- Run: Every 1 minute
- Trigger: If no results in last 2 minutes
- Action: PagerDuty (critical)

Unusual Order Rate:
```spl
index=trading_logs sourcetype=order_log
| timechart count as orders span=1m
| where orders > 10000 OR orders < 10
```
- Trigger: Anomaly (too high or too low)
- Action: Slack notification

2. Configure Alert Actions:
   - Email: Configure SMTP settings
   - PagerDuty: Install PagerDuty app from Splunkbase
   - Slack: Install Slack app or use webhooks
   - Custom scripts: Run Python/bash scripts on alert

3. Throttling and Suppression:
   - Throttle: Suppress duplicate alerts (e.g., once per 10 minutes)
   - Maintenance windows: Suppress alerts during planned maintenance

Phase 6: Compliance and Security (Week 6-8)

1. Enable Audit Logging:
   - All user actions logged
   - Searchable in _audit index
   - Required for compliance (SOX, PCI-DSS)

2. Role-Based Access Control (RBAC):
   - Create roles: trader, risk_manager, compliance_officer, admin
   - Assign permissions (search, edit, admin)
   - Limit index access (e.g., traders can't see security logs)

3. Data Retention and Archival:
   - Online retention: 30-90 days (searchable)
   - Archive to S3: 7+ years (compliance requirement)
   - Use Splunk SmartStore for hybrid storage (hot/warm/cold tiers)

4. Security Monitoring (if using Splunk ES):
   - Enable correlation searches (pre-built security alerts)
   - Configure risk-based alerting
   - Create custom threat detection rules

4.5 SPLUNK BEST PRACTICES FOR HFT
--------------------------------------------------------------------------------
Search Optimization:

Best Practices:
  - Use index and sourcetype in every search (filter early)
  - Avoid wildcards at start of string (slow: `index=* source=*trading*`)
  - Use fields command to limit returned fields
  - Leverage summary indexes for frequently-run expensive searches
  - Use tstats for fast statistical searches (on indexed fields)

Example Optimized Search:
```spl
index=trading_logs sourcetype=order_log venue="NYSE"
| stats avg(latency) as avg_latency by symbol
| where avg_latency > 1000
| sort -avg_latency
| head 20
```

Data Onboarding:

Log Format:
  - Prefer structured logs (JSON, key-value)
  - Include timestamp at start of each log line
  - Consistent field names across services
  - Tag with context (env, host, strategy)

Example Structured Log:
```json
{"timestamp":"2025-11-25T12:34:56.789Z","level":"INFO","service":"trading-engine","message":"Order placed","symbol":"AAPL","venue":"NYSE","latency_us":342}
```

Field Extraction:
  - Extract fields at index time (if frequently searched)
  - Extract fields at search time (if occasionally searched)
  - Use data models for consistent field naming

Cost Management:

Reduce Indexing Volume:
  - Drop unnecessary logs (use null queue in transforms.conf)
  - Sample high-volume logs (e.g., debug logs 10%)
  - Compress logs before forwarding
  - Separate indexes (retain critical logs longer, drop debug logs sooner)

Example - Drop Debug Logs:
```conf
# props.conf
[trading_app]
TRANSFORMS-drop = drop_debug

# transforms.conf
[drop_debug]
REGEX = level=DEBUG
DEST_KEY = queue
FORMAT = nullQueue
```

Archive to Cheap Storage:
  - Use SmartStore (Splunk on S3/GCS)
  - Only keep hot data on expensive SSD
  - Archive old data to S3 (searchable but slower)

Security:

Network Security:
  - Use TLS for forwarder-to-indexer communication
  - Firewall: Only allow forwarders to reach indexers
  - VPN or private network (no public internet exposure)

Data Security:
  - Encrypt sensitive fields (credit cards, SSNs)
  - Implement data anonymization (where required)
  - Use Splunk Hashing for PCI compliance

Access Control:
  - Least privilege principle
  - Separate roles for prod and non-prod
  - Audit user searches (monitor for data exfiltration)

4.6 SPLUNK VS ALTERNATIVES FOR HFT
--------------------------------------------------------------------------------
When Splunk Makes Sense:
  ✓ Strong compliance requirements (PCI-DSS, SOX, GDPR)
  ✓ Need on-premises deployment (sensitive data)
  ✓ Heavy security and audit focus (SIEM required)
  ✓ Existing Splunk expertise in organization
  ✓ Log-heavy workloads (high volume logs critical)
  ✓ Budget allows (Splunk is most expensive)

When to Choose Alternatives:
  ✗ Cost-sensitive (DataDog/New Relic 3-5x cheaper)
  ✗ APM is priority (DataDog/New Relic better)
  ✗ Infrastructure monitoring focus (DataDog better)
  ✗ Modern cloud-native architecture (New Relic/DataDog better fit)
  ✗ Simplicity preferred (Splunk complex to manage)

Hybrid Approach (Common in HFT):
  - Splunk for logs and compliance (strength area)
  - DataDog for infrastructure and APM (better experience)
  - Total cost: Higher but best-of-breed

================================================================================
5. COMPARATIVE ANALYSIS
================================================================================

5.1 FEATURE COMPARISON
--------------------------------------------------------------------------------
Infrastructure Monitoring:

DataDog:
  Rating: 5/5 (best-in-class)
  Strengths: 500+ integrations, easy setup, beautiful UI
  Weaknesses: None significant

New Relic:
  Rating: 4/5 (good)
  Strengths: NRQL powerful, generous free tier
  Weaknesses: Fewer integrations than DataDog

Splunk:
  Rating: 3/5 (adequate)
  Strengths: Infrastructure Monitoring (SignalFx) is good
  Weaknesses: Not as mature as competitors, separate product/pricing

Winner: DataDog

Application Performance Monitoring (APM):

DataDog:
  Rating: 5/5 (excellent)
  Strengths: Distributed tracing, profiling, low overhead
  Weaknesses: Cost scales with hosts

New Relic:
  Rating: 5/5 (excellent)
  Strengths: Powerful APM, consumption pricing, unlimited users
  Weaknesses: Steeper learning curve

Splunk:
  Rating: 3/5 (growing)
  Strengths: Improving post-SignalFx acquisition
  Weaknesses: Less mature than competitors, expensive

Winner: Tie (DataDog and New Relic)

Log Management:

DataDog:
  Rating: 4/5 (very good)
  Strengths: Good integration with metrics and APM, searchable
  Weaknesses: Not as powerful as Splunk for log analysis

New Relic:
  Rating: 4/5 (very good)
  Strengths: NRQL for logs, unified platform
  Weaknesses: Less mature than Splunk

Splunk:
  Rating: 5/5 (industry leader)
  Strengths: Most powerful log search and analysis (SPL), 20+ years mature
  Weaknesses: Expensive, complex

Winner: Splunk (but at a premium cost)

Security and Compliance:

DataDog:
  Rating: 4/5 (good)
  Strengths: Security monitoring available, compliant (SOC 2, etc.)
  Weaknesses: Not a SIEM

New Relic:
  Rating: 3/5 (adequate)
  Strengths: Compliant, vulnerability management
  Weaknesses: Limited security-specific features

Splunk:
  Rating: 5/5 (leader)
  Strengths: Splunk ES (SIEM), deep compliance features, audit trails
  Weaknesses: Expensive add-on

Winner: Splunk (critical for highly regulated firms)

Alerting and Anomaly Detection:

DataDog:
  Rating: 5/5 (excellent)
  Strengths: ML-powered anomaly detection, flexible alerting
  Weaknesses: None significant

New Relic:
  Rating: 5/5 (excellent)
  Strengths: Applied Intelligence (ML), proactive detection
  Weaknesses: Complex to configure initially

Splunk:
  Rating: 4/5 (good)
  Strengths: Powerful SPL for alerting, ITSI for service monitoring
  Weaknesses: Less automated than DataDog/New Relic

Winner: Tie (DataDog and New Relic)

Ease of Use:

DataDog:
  Rating: 5/5 (easiest)
  Strengths: Intuitive UI, quick setup, great onboarding
  Weaknesses: None

New Relic:
  Rating: 4/5 (moderate)
  Strengths: Unified platform, good documentation
  Weaknesses: NRQL has learning curve

Splunk:
  Rating: 2/5 (complex)
  Strengths: Very powerful once learned
  Weaknesses: Steep learning curve, complex architecture

Winner: DataDog

5.2 PRICING COMPARISON
--------------------------------------------------------------------------------
Scenario: Medium HFT Firm (20 hosts, moderate data)

Configuration:
  - 20 trading servers
  - Infrastructure monitoring
  - APM on 10 hosts
  - 200 GB logs per day
  - 500 custom metrics

DataDog:
  Infrastructure (20 hosts x $15): $300/month
  APM (10 hosts x $31): $310/month
  Custom metrics: ~$1/month
  Logs (200 GB/day = 6 TB/month, free under minimum): $0/month
  Total: $611/month or $7,332/year

New Relic:
  Data ingest estimate:
    - Infrastructure: 20 hosts x 2 GB = 40 GB
    - APM: 10 hosts x 30 GB = 300 GB
    - Logs: 200 GB/day x 30 = 6,000 GB
    - Total: 6,340 GB/month
  
  Data: (6,340 GB - 100 GB free) x $0.30 = $1,872/month
  Users (5 full platform): 5 x $99 = $495/month
  Total: $2,367/month or $28,404/year

Splunk:
  Splunk Enterprise (200 GB/day peak x $150): $30,000/year
  Infrastructure Monitoring (20 hosts x $18 x 12): $4,320/year
  APM (10 hosts x $55 x 12): $6,600/year
  Total: $40,920/year or $3,410/month

Cost Comparison:
  DataDog: $7,332/year (cheapest, 1.0x)
  New Relic: $28,404/year (3.9x DataDog)
  Splunk: $40,920/year (5.6x DataDog)

Winner: DataDog (best value for HFT with this workload)

Why New Relic Higher:
  - High log volume (6 TB/month) drives cost
  - DataDog log minimum not reached, so effectively free
  - For lower log volumes, New Relic can be competitive

Why Splunk Highest:
  - Splunk charges per-day peak (not average)
  - Expensive per-GB pricing
  - Separate add-ons for infra and APM

Scenario: Large HFT Firm (100 hosts, high data volume)

Configuration:
  - 100 trading servers
  - Infrastructure monitoring all
  - APM on 50 hosts
  - 1 TB logs per day
  - 2,000 custom metrics

DataDog:
  Infrastructure (100 hosts x $15): $1,500/month
  APM (50 hosts x $31): $1,550/month
  Custom metrics (1,800 additional): $9/month
  Logs (1 TB/day = 30 TB/month x $0.10): $3,000/month
  Network Monitoring (100 hosts x $5): $500/month
  Total: $6,559/month or $78,708/year

New Relic:
  Data ingest estimate:
    - Infrastructure: 100 hosts x 2 GB = 200 GB
    - APM: 50 hosts x 40 GB = 2,000 GB
    - Logs: 1 TB/day x 30 = 30,000 GB
    - Total: 32,200 GB/month
  
  Data (with 15% volume discount): (32,200 GB - 100 GB) x $0.255 = $8,186/month
  Users (20 full platform): Included in Pro tier commit
  Total: $8,186/month or $98,232/year

Splunk:
  Splunk Enterprise (1.5 TB/day peak x $100): $150,000/year
  Infrastructure Monitoring (100 hosts x $18 x 12): $17,280/year
  APM (50 hosts x $55 x 12): $26,400/year
  Total: $193,680/year or $16,140/month

Cost Comparison:
  DataDog: $78,708/year (cheapest, 1.0x)
  New Relic: $98,232/year (1.25x DataDog)
  Splunk: $193,680/year (2.5x DataDog)

Winner: DataDog (best value, even at scale)

Key Insight:
  - DataDog cost-effective across workload sizes
  - New Relic competitive for elastic/variable workloads (free tier helps)
  - Splunk only makes sense if log analysis and compliance are critical

5.3 USE CASE RECOMMENDATIONS
--------------------------------------------------------------------------------
Choose DataDog If:
  ✓ Need comprehensive monitoring (infra + APM + logs)
  ✓ Want easiest setup and best user experience
  ✓ Cost-conscious (best value)
  ✓ Cloud-native architecture
  ✓ Strong integrations ecosystem important
  ✓ Modern HFT firm (< 10 years old)

Choose New Relic If:
  ✓ APM is top priority (excellent APM)
  ✓ Variable workloads (consumption pricing + free tier)
  ✓ Unlimited users desired (no per-seat fees)
  ✓ Powerful query language preferred (NRQL)
  ✓ Want single unified platform
  ✓ Lower log volumes (take advantage of 100 GB free tier)

Choose Splunk If:
  ✓ Heavy compliance requirements (PCI-DSS, SOX, HIPAA)
  ✓ Need SIEM capabilities (security monitoring)
  ✓ On-premises deployment required (sensitive data)
  ✓ Very high log volumes (need powerful log search)
  ✓ Existing Splunk investment and expertise
  ✓ Budget allows (most expensive but most comprehensive)
  ✓ Traditional financial services firm

Hybrid Approach (Best of Breed):
  - DataDog: Infrastructure + APM (best user experience)
  - Splunk: Logs + Compliance (best log analysis and SIEM)
  - Total cost: Higher, but optimized for each use case
  - Common in large banks and regulated HFT firms

================================================================================
6. SETUP AND CONFIGURATION GUIDES
================================================================================

See sections 2.4, 3.4, and 4.4 for detailed setup guides for DataDog, New Relic,
and Splunk respectively.

Key Setup Phases (All Providers):
  1. Account setup and licensing (Days 1-2)
  2. Agent deployment on servers (Days 2-4)
  3. APM instrumentation (Days 4-7)
  4. Custom metrics and events (Days 7-10)
  5. Log collection and parsing (Days 7-10)
  6. Dashboards creation (Days 10-14)
  7. Alerting configuration (Days 14-21)
  8. Optimization and tuning (Days 21-30)

Timeline: 3-4 weeks for initial deployment, 1-2 months for full optimization

================================================================================
7. MONTHLY COSTS AND PRICING
================================================================================

See sections 2.3, 3.3, and 4.3 for detailed pricing information.

Quick Reference (Medium HFT Firm - 20 Hosts):

DataDog: $611/month ($7,332/year)
New Relic: $2,367/month ($28,404/year)
Splunk: $3,410/month ($40,920/year)

Quick Reference (Large HFT Firm - 100 Hosts):

DataDog: $6,559/month ($78,708/year)
New Relic: $8,186/month ($98,232/year)
Splunk: $16,140/month ($193,680/year)

================================================================================
8. INTEGRATION WITH HFT SYSTEMS
================================================================================

8.1 MONITORING HFT-SPECIFIC METRICS
--------------------------------------------------------------------------------
Critical Metrics to Monitor:

Order Placement Latency:
  - Time from strategy signal to order sent
  - Target: < 100 microseconds (for ultra-low-latency)
  - Measurement: Timestamp before and after order placement
  - Tag by: venue, symbol, strategy

Market Data Latency:
  - Time from exchange timestamp to system receipt
  - Target: < 500 microseconds
  - Measurement: Exchange timestamp vs. system timestamp
  - Tag by: venue, symbol, feed type

Fill Latency:
  - Time from order placement to fill
  - Target: < 10 milliseconds
  - Measurement: Order timestamp vs. fill timestamp
  - Tag by: venue, symbol

Fill Rate:
  - Percentage of orders that get filled
  - Target: > 85%
  - Calculation: (Filled orders / Total orders) x 100
  - Tag by: venue, symbol, strategy

Slippage:
  - Difference between expected and actual fill price
  - Target: < 1 basis point
  - Calculation: (Actual price - Expected price) / Expected price x 10,000
  - Tag by: venue, symbol, side

P&L:
  - Real-time profit and loss
  - Calculation: Sum of trade P&L
  - Tag by: strategy, trader, symbol

Position:
  - Current holdings by symbol
  - Monitor: Real-time updates
  - Alert: If position exceeds limits

Order Rate:
  - Orders placed per second
  - Typical: 100-1,000 orders/sec for active HFT
  - Alert: If unusual (too high or too low)

8.2 INSTRUMENTING TRADING SYSTEMS
--------------------------------------------------------------------------------
C++ Trading System Example:

```cpp
#include <datadog/tracer.h>
#include <chrono>

class TradingEngine {
private:
    datadog::Tracer tracer;
    
public:
    void placeOrder(const std::string& symbol, const std::string& venue, int quantity) {
        auto start = std::chrono::high_resolution_clock::now();
        
        // Start APM span
        auto span = tracer.StartSpan("place_order");
        span->SetTag("symbol", symbol);
        span->SetTag("venue", venue);
        span->SetTag("quantity", quantity);
        
        try {
            // Order placement logic
            sendOrderToExchange(symbol, venue, quantity);
            
            auto end = std::chrono::high_resolution_clock::now();
            auto latency_us = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();
            
            // Emit custom metric (DogStatsD)
            sendMetric("trading.order.latency", latency_us, {
                {"venue", venue},
                {"symbol", symbol}
            });
            
            // Increment order counter
            sendCount("trading.order.placed", 1, {
                {"venue", venue},
                {"symbol", symbol}
            });
            
            span->Finish();
            
        } catch (const std::exception& e) {
            span->SetTag("error", true);
            span->SetTag("error.message", e.what());
            span->Finish();
            
            // Log error
            logError("Order placement failed", symbol, venue, e.what());
        }
    }
};
```

Python Trading System Example:

```python
from ddtrace import tracer
from datadog import statsd
import time

class TradingEngine:
    def place_order(self, symbol, venue, quantity):
        start = time.time()
        
        with tracer.trace("place_order") as span:
            span.set_tag("symbol", symbol)
            span.set_tag("venue", venue)
            span.set_tag("quantity", quantity)
            
            try:
                # Order placement logic
                self.send_order_to_exchange(symbol, venue, quantity)
                
                latency_us = (time.time() - start) * 1_000_000
                
                # Emit custom metric
                statsd.gauge(
                    'trading.order.latency',
                    latency_us,
                    tags=[f'venue:{venue}', f'symbol:{symbol}']
                )
                
                # Increment order counter
                statsd.increment(
                    'trading.order.placed',
                    tags=[f'venue:{venue}', f'symbol:{symbol}']
                )
                
            except Exception as e:
                span.set_tag("error", True)
                span.set_tag("error.message", str(e))
                
                # Log error
                log_error(f"Order placement failed: {symbol} {venue}", exc_info=True)
                raise
```

8.3 MONITORING INFRASTRUCTURE HEALTH
--------------------------------------------------------------------------------
Server Health Metrics:

CPU:
  - Overall utilization (alert if > 90% sustained)
  - Per-core utilization (identify imbalances)
  - Steal time (should be 0% in dedicated servers)
  - Context switches (high = inefficient)

Memory:
  - Used vs. Available
  - Swap usage (should be 0% for trading servers)
  - Cache and buffers
  - Memory leaks (monitor for growth trends)

Disk:
  - I/O wait percentage (alert if > 10%)
  - IOPS (read and write)
  - Throughput (MB/s)
  - Queue depth
  - Disk space (alert at 80% full)

Network:
  - Throughput (Mbps in/out)
  - Packet rate (packets/sec)
  - Errors and drops (should be 0)
  - Retransmits (TCP, should be minimal)
  - Latency to exchanges (monitor via ping/netcat)

Temperature and Power:
  - CPU temperature (alert if > 80°C)
  - Fan speeds (monitor for failures)
  - Power consumption (for capacity planning)
  - IPMI health checks

Exchange Connectivity:

Heartbeat Monitoring:
  - Send periodic heartbeats to exchanges
  - Monitor round-trip time
  - Alert if heartbeat missed or latency spikes

Order Connectivity:
  - Test order placement capability (test orders)
  - Monitor order acceptance time
  - Alert if orders rejected or connectivity down

Market Data:
  - Monitor market data feed latency
  - Detect sequence gaps (missing messages)
  - Alert if feed down or lagging

8.4 DASHBOARDS FOR HFT
--------------------------------------------------------------------------------
Executive Dashboard (High-Level Overview):

Widgets:
  - Daily P&L (gauge, green/red)
  - Order rate (time series, last hour)
  - Fill rate (percentage gauge)
  - System health (status indicators per host)
  - Alert count (critical/high/medium)

Trading Desk Dashboard (Operational):

Widgets:
  - Order latency by venue (time series, multi-line)
  - Market data latency (heatmap by symbol)
  - P&L by strategy (bar chart)
  - Top traded symbols (table)
  - Order flow (orders/fills/cancels per minute)
  - Position by symbol (table with alerts)

Infrastructure Dashboard (Engineering):

Widgets:
  - CPU utilization (time series per host)
  - Memory usage (time series per host)
  - Network throughput (time series)
  - Disk I/O (time series)
  - Host health (status indicators)
  - Alert history (table)

Compliance Dashboard (Regulatory):

Widgets:
  - Total orders placed (count by day)
  - Total trades executed (count by day)
  - Audit log events (count by type)
  - Unusual activity alerts (table)
  - Access logs (who accessed what)

================================================================================
9. ALERTING AND INCIDENT MANAGEMENT
================================================================================

9.1 ALERT HIERARCHY
--------------------------------------------------------------------------------
Critical (P1) - Immediate Response Required:
  - Trading system down
  - Exchange connectivity lost
  - Order latency > 10ms for 5+ minutes
  - Fill rate < 50% for 10+ minutes
  - Market data feed down
  - Server unreachable
  - Disk > 95% full

Response: PagerDuty, 5-minute SLA

High (P2) - Response Within 1 Hour:
  - Order latency > 5ms (p99) for 10+ minutes
  - Fill rate < 80% for 30+ minutes
  - CPU > 90% for 10+ minutes
  - Memory > 90% for 10+ minutes
  - Market data lag > 1 second
  - Network errors increasing

Response: Slack + Email, 1-hour SLA

Medium (P3) - Response Within 4 Hours:
  - Order latency elevated (p95 > 2ms)
  - CPU > 80% for 30+ minutes
  - Disk > 80% full
  - Unusual order patterns (anomaly)
  - Strategy P&L outside expected range

Response: Email, 4-hour SLA

Low (P4) - Review Next Business Day:
  - Certificate expiring in 30 days
  - Software update available
  - Non-critical service degraded

Response: Email or ticketing system

9.2 ALERT BEST PRACTICES
--------------------------------------------------------------------------------
Avoid Alert Fatigue:
  - Set appropriate thresholds (not too sensitive)
  - Require sustained condition (e.g., "for 5 minutes")
  - Use anomaly detection (vs. static thresholds)
  - Implement alert de-duplication
  - Schedule maintenance windows (suppress alerts)

Alert Quality Metrics:
  - Alert to Incident Ratio (target: < 10%)
  - Mean Time to Acknowledge (MTTA): < 5 minutes for critical
  - Mean Time to Resolution (MTTR): < 30 minutes for critical
  - False Positive Rate: < 5%

Review and Refine:
  - Weekly: Review P1/P2 alerts (post-mortems)
  - Monthly: Review all alert thresholds
  - Quarterly: Audit alert effectiveness

9.3 INCIDENT RESPONSE WORKFLOW
--------------------------------------------------------------------------------
1. Detection:
   - Alert triggered → PagerDuty/Slack notification
   - On-call engineer acknowledges within 5 minutes

2. Triage:
   - Assess severity (is trading impacted?)
   - Identify root cause (dashboards, logs, metrics)
   - Escalate if needed (engage additional engineers)

3. Resolution:
   - Implement fix (restart service, failover, etc.)
   - Verify resolution (metrics return to normal)
   - Document actions taken

4. Post-Incident:
   - Blameless post-mortem (within 48 hours)
   - Root cause analysis
   - Action items to prevent recurrence
   - Update runbooks

5. Prevention:
   - Implement fixes to prevent recurrence
   - Add monitoring to detect earlier next time
   - Update alerts based on learnings

================================================================================
10. BEST PRACTICES AND RECOMMENDATIONS
================================================================================

10.1 MONITORING STRATEGY FOR HFT
--------------------------------------------------------------------------------
Multi-Layer Monitoring:

Layer 1: Infrastructure (Servers, Network, Storage)
  - Tool: DataDog, New Relic, or Splunk Infrastructure Monitoring
  - Metrics: CPU, memory, disk, network, temperature
  - Alerts: Resource exhaustion, hardware failures

Layer 2: Application (Trading Systems, Strategies)
  - Tool: DataDog APM, New Relic APM, or custom instrumentation
  - Metrics: Order latency, fill rate, P&L, position
  - Alerts: Performance degradation, errors

Layer 3: Business (Trading Performance, Risk)
  - Tool: Custom dashboards combining data from multiple sources
  - Metrics: Daily P&L, Sharpe ratio, max drawdown, exposure
  - Alerts: Risk limit breaches, unusual trading patterns

Layer 4: Security and Compliance (Audit, Access)
  - Tool: Splunk ES, DataDog Security Monitoring
  - Metrics: Access logs, security events, compliance reports
  - Alerts: Unauthorized access, policy violations

10.2 COST OPTIMIZATION
--------------------------------------------------------------------------------
Right-Size Monitoring:
  - Start with essential metrics (don't monitor everything)
  - Add metrics as needs evolve
  - Review and prune unused metrics quarterly

Use Free Tiers:
  - New Relic: 100 GB/month free (good for small teams)
  - DataDog: 5 hosts free (testing and development)

Optimize Data Ingest:
  - Sample non-critical logs (e.g., debug logs 10%)
  - Drop redundant logs (duplicate information)
  - Compress data before sending
  - Use log-based metrics (cheaper than indexing all logs)

Commitment Discounts:
  - Annual commitments: 30-50% savings (DataDog, Splunk)
  - Multi-year: Additional 10-20% savings

10.3 SECURITY BEST PRACTICES
--------------------------------------------------------------------------------
Network Security:
  - Use TLS for all agent communication
  - Whitelist monitoring platform IPs (firewall)
  - Use private links (AWS PrivateLink, Azure Private Link)

Data Security:
  - Scrub sensitive data (credit cards, SSNs, passwords)
  - Encrypt data at rest (in monitoring platform)
  - Implement data retention policies (GDPR compliance)

Access Control:
  - Role-based access control (RBAC)
  - Least privilege principle
  - Multi-factor authentication (MFA)
  - Audit access logs quarterly

API Key Management:
  - Rotate API keys annually
  - Use separate keys for prod/dev
  - Store keys in secrets manager (not code)

10.4 FINAL RECOMMENDATIONS
--------------------------------------------------------------------------------
For Small HFT Startups (< 10 servers):
  - Recommended: New Relic (free tier, then consumption pricing)
  - Alternative: DataDog (easy setup, good value)
  - Avoid: Splunk (too expensive, too complex)

For Medium HFT Firms (10-50 servers):
  - Recommended: DataDog (best value, comprehensive)
  - Alternative: New Relic (if APM is priority)
  - Consider: Splunk for logs only (if compliance heavy)

For Large HFT Firms (50+ servers):
  - Recommended: DataDog (comprehensive, scalable, cost-effective)
  - Consider: Hybrid (DataDog + Splunk for compliance)
  - Alternative: New Relic (if prefer consumption model)

For Compliance-Heavy Firms:
  - Recommended: Splunk (best SIEM, audit capabilities)
  - Supplement: DataDog for infra/APM
  - Total cost: Higher, but necessary for compliance

Key Takeaway:
Monitoring is non-negotiable for HFT. Choose based on:
  1. Budget (DataDog most cost-effective)
  2. Compliance needs (Splunk if heavy compliance)
  3. APM priority (DataDog or New Relic)
  4. Existing expertise (leverage what you know)
  5. Ease of use (DataDog easiest, Splunk hardest)

Invest 2-5% of infrastructure budget in monitoring. It pays for itself through
faster incident response, better capacity planning, and improved trading
performance.

================================================================================
END OF DOCUMENT
================================================================================

Document prepared for: HFT System Technical Reference
Last Updated: November 2025
Version: 1.0

For questions or updates, consult monitoring platform documentation and your
DevOps team.
