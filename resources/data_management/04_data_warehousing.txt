================================================================================
DATA WAREHOUSING FOR HFT SYSTEMS
Historical Data Storage and Analytics
================================================================================

OVERVIEW
--------
This document covers comprehensive data warehousing solutions for storing
historical trading data, performing analytics, and generating reports for
high-frequency trading systems. Focus on efficient storage, fast queries,
and scalable architecture.

================================================================================
1. DATA WAREHOUSE ARCHITECTURE
================================================================================

1.1 STAR SCHEMA DESIGN
-----------------------

┌──────────────────────┐
│   Fact_Trades        │
├──────────────────────┤
│ trade_key (PK)       │
│ date_key (FK)        │◀───────┐
│ instrument_key (FK)  │◀─────┐ │
│ account_key (FK)     │◀───┐ │ │
│ strategy_key (FK)    │◀─┐ │ │ │
│ execution_timestamp  │  │ │ │ │
│ price                │  │ │ │ │
│ quantity             │  │ │ │ │
│ notional_value       │  │ │ │ │
│ commission           │  │ │ │ │
│ fees                 │  │ │ │ │
│ pnl                  │  │ │ │ │
└──────────────────────┘  │ │ │ │
                          │ │ │ │
┌────────────────────┐    │ │ │ │
│  Dim_Strategy      │────┘ │ │ │
├────────────────────┤      │ │ │
│ strategy_key (PK)  │      │ │ │
│ strategy_id        │      │ │ │
│ strategy_name      │      │ │ │
│ strategy_type      │      │ │ │
│ risk_tier          │      │ │ │
│ version            │      │ │ │
└────────────────────┘      │ │ │
                            │ │ │
┌────────────────────┐      │ │ │
│  Dim_Account       │──────┘ │ │
├────────────────────┤        │ │
│ account_key (PK)   │        │ │
│ account_id         │        │ │
│ account_number     │        │ │
│ account_type       │        │ │
│ broker             │        │ │
└────────────────────┘        │ │
                              │ │
┌────────────────────┐        │ │
│  Dim_Instrument    │────────┘ │
├────────────────────┤          │
│ instrument_key(PK) │          │
│ instrument_id      │          │
│ symbol             │          │
│ exchange           │          │
│ instrument_type    │          │
│ sector             │          │
│ market_cap         │          │
└────────────────────┘          │
                                │
┌────────────────────┐          │
│  Dim_Date          │──────────┘
├────────────────────┤
│ date_key (PK)      │
│ date               │
│ year               │
│ quarter            │
│ month              │
│ day_of_week        │
│ is_trading_day     │
│ is_holiday         │
└────────────────────┘

1.2 DDL FOR STAR SCHEMA
------------------------

-- Dimension: Date
CREATE TABLE dim_date (
    date_key INTEGER PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    year SMALLINT NOT NULL,
    quarter SMALLINT NOT NULL,
    month SMALLINT NOT NULL,
    month_name VARCHAR(20) NOT NULL,
    day_of_month SMALLINT NOT NULL,
    day_of_week SMALLINT NOT NULL,
    day_name VARCHAR(20) NOT NULL,
    week_of_year SMALLINT NOT NULL,
    is_weekend BOOLEAN NOT NULL,
    is_trading_day BOOLEAN NOT NULL,
    is_holiday BOOLEAN NOT NULL,
    holiday_name VARCHAR(100),
    fiscal_year SMALLINT,
    fiscal_quarter SMALLINT,
    fiscal_month SMALLINT
);

CREATE INDEX idx_dim_date_date ON dim_date(date);
CREATE INDEX idx_dim_date_year_month ON dim_date(year, month);

-- Dimension: Instrument
CREATE TABLE dim_instrument (
    instrument_key SERIAL PRIMARY KEY,
    instrument_id INTEGER NOT NULL,
    symbol VARCHAR(50) NOT NULL,
    exchange VARCHAR(50) NOT NULL,
    instrument_type VARCHAR(50) NOT NULL,
    full_name VARCHAR(255),
    sector VARCHAR(100),
    industry VARCHAR(100),
    market_cap_category VARCHAR(20),
    country VARCHAR(3),
    currency VARCHAR(3) NOT NULL,
    tick_size NUMERIC(20, 8),
    lot_size INTEGER,
    is_active BOOLEAN DEFAULT true,
    effective_date DATE NOT NULL,
    expiration_date DATE,
    UNIQUE(instrument_id, effective_date)
);

CREATE INDEX idx_dim_instrument_symbol ON dim_instrument(symbol, exchange);
CREATE INDEX idx_dim_instrument_type ON dim_instrument(instrument_type);
CREATE INDEX idx_dim_instrument_sector ON dim_instrument(sector);

-- Dimension: Account
CREATE TABLE dim_account (
    account_key SERIAL PRIMARY KEY,
    account_id INTEGER NOT NULL,
    account_number VARCHAR(50) NOT NULL,
    account_name VARCHAR(255),
    account_type VARCHAR(50) NOT NULL,
    broker VARCHAR(100) NOT NULL,
    currency VARCHAR(3) DEFAULT 'USD',
    risk_tier VARCHAR(20),
    is_active BOOLEAN DEFAULT true,
    effective_date DATE NOT NULL,
    expiration_date DATE,
    UNIQUE(account_id, effective_date)
);

CREATE INDEX idx_dim_account_number ON dim_account(account_number);
CREATE INDEX idx_dim_account_type ON dim_account(account_type);
CREATE INDEX idx_dim_account_broker ON dim_account(broker);

-- Dimension: Strategy
CREATE TABLE dim_strategy (
    strategy_key SERIAL PRIMARY KEY,
    strategy_id INTEGER NOT NULL,
    strategy_name VARCHAR(255) NOT NULL,
    strategy_type VARCHAR(50) NOT NULL,
    strategy_category VARCHAR(50),
    risk_tier VARCHAR(20),
    version INTEGER NOT NULL,
    is_active BOOLEAN DEFAULT true,
    effective_date DATE NOT NULL,
    expiration_date DATE,
    UNIQUE(strategy_id, version, effective_date)
);

CREATE INDEX idx_dim_strategy_name ON dim_strategy(strategy_name);
CREATE INDEX idx_dim_strategy_type ON dim_strategy(strategy_type);

-- Dimension: Time (for intraday analysis)
CREATE TABLE dim_time (
    time_key INTEGER PRIMARY KEY,
    time TIME NOT NULL UNIQUE,
    hour SMALLINT NOT NULL,
    minute SMALLINT NOT NULL,
    second SMALLINT NOT NULL,
    time_of_day VARCHAR(20) NOT NULL, -- 'Morning', 'Afternoon', 'Close'
    market_session VARCHAR(20) NOT NULL -- 'Pre-Market', 'Regular', 'After-Hours'
);

-- Fact: Trades
CREATE TABLE fact_trades (
    trade_key BIGSERIAL PRIMARY KEY,
    date_key INTEGER NOT NULL REFERENCES dim_date(date_key),
    time_key INTEGER NOT NULL REFERENCES dim_time(time_key),
    instrument_key INTEGER NOT NULL REFERENCES dim_instrument(instrument_key),
    account_key INTEGER NOT NULL REFERENCES dim_account(account_key),
    strategy_key INTEGER REFERENCES dim_strategy(strategy_key),
    execution_id BIGINT NOT NULL,
    order_id BIGINT NOT NULL,
    execution_timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    side VARCHAR(10) NOT NULL,
    quantity NUMERIC(20, 8) NOT NULL,
    price NUMERIC(20, 8) NOT NULL,
    notional_value NUMERIC(20, 2) NOT NULL,
    commission NUMERIC(20, 8) NOT NULL DEFAULT 0,
    fees NUMERIC(20, 8) NOT NULL DEFAULT 0,
    liquidity_flag VARCHAR(20),
    realized_pnl NUMERIC(20, 2),
    execution_venue VARCHAR(50),
    latency_ms INTEGER
);

CREATE INDEX idx_fact_trades_date ON fact_trades(date_key, time_key);
CREATE INDEX idx_fact_trades_instrument ON fact_trades(instrument_key);
CREATE INDEX idx_fact_trades_account ON fact_trades(account_key);
CREATE INDEX idx_fact_trades_strategy ON fact_trades(strategy_key);
CREATE INDEX idx_fact_trades_timestamp ON fact_trades(execution_timestamp);

-- Partition fact_trades by month
CREATE TABLE fact_trades_partitioned (LIKE fact_trades INCLUDING ALL)
PARTITION BY RANGE (date_key);

-- Fact: Daily Position Snapshots
CREATE TABLE fact_positions_daily (
    position_key BIGSERIAL PRIMARY KEY,
    date_key INTEGER NOT NULL REFERENCES dim_date(date_key),
    instrument_key INTEGER NOT NULL REFERENCES dim_instrument(instrument_key),
    account_key INTEGER NOT NULL REFERENCES dim_account(account_key),
    strategy_key INTEGER REFERENCES dim_strategy(strategy_key),
    quantity NUMERIC(20, 8) NOT NULL,
    side VARCHAR(10),
    avg_entry_price NUMERIC(20, 8),
    current_price NUMERIC(20, 8),
    market_value NUMERIC(20, 2),
    unrealized_pnl NUMERIC(20, 2),
    realized_pnl NUMERIC(20, 2),
    total_pnl NUMERIC(20, 2),
    UNIQUE(date_key, account_key, instrument_key)
);

CREATE INDEX idx_fact_positions_date ON fact_positions_daily(date_key);
CREATE INDEX idx_fact_positions_account ON fact_positions_daily(account_key);
CREATE INDEX idx_fact_positions_instrument ON fact_positions_daily(instrument_key);

-- Fact: Daily Performance
CREATE TABLE fact_performance_daily (
    performance_key BIGSERIAL PRIMARY KEY,
    date_key INTEGER NOT NULL REFERENCES dim_date(date_key),
    account_key INTEGER NOT NULL REFERENCES dim_account(account_key),
    strategy_key INTEGER REFERENCES dim_strategy(strategy_key),
    total_trades INTEGER NOT NULL DEFAULT 0,
    winning_trades INTEGER NOT NULL DEFAULT 0,
    losing_trades INTEGER NOT NULL DEFAULT 0,
    total_volume NUMERIC(20, 8) NOT NULL DEFAULT 0,
    total_notional NUMERIC(20, 2) NOT NULL DEFAULT 0,
    gross_profit NUMERIC(20, 2) NOT NULL DEFAULT 0,
    gross_loss NUMERIC(20, 2) NOT NULL DEFAULT 0,
    net_pnl NUMERIC(20, 2) NOT NULL DEFAULT 0,
    commissions NUMERIC(20, 2) NOT NULL DEFAULT 0,
    fees NUMERIC(20, 2) NOT NULL DEFAULT 0,
    win_rate NUMERIC(5, 4),
    profit_factor NUMERIC(10, 4),
    sharpe_ratio NUMERIC(10, 4),
    max_drawdown NUMERIC(20, 2),
    avg_win NUMERIC(20, 2),
    avg_loss NUMERIC(20, 2),
    largest_win NUMERIC(20, 2),
    largest_loss NUMERIC(20, 2),
    UNIQUE(date_key, account_key, strategy_key)
);

CREATE INDEX idx_fact_perf_date ON fact_performance_daily(date_key);
CREATE INDEX idx_fact_perf_account ON fact_performance_daily(account_key);
CREATE INDEX idx_fact_perf_strategy ON fact_performance_daily(strategy_key);

-- Aggregate: Monthly Performance
CREATE TABLE agg_performance_monthly (
    month_key INTEGER NOT NULL,
    account_key INTEGER NOT NULL REFERENCES dim_account(account_key),
    strategy_key INTEGER REFERENCES dim_strategy(strategy_key),
    year SMALLINT NOT NULL,
    month SMALLINT NOT NULL,
    total_trades INTEGER NOT NULL DEFAULT 0,
    winning_trades INTEGER NOT NULL DEFAULT 0,
    total_volume NUMERIC(20, 8) NOT NULL DEFAULT 0,
    net_pnl NUMERIC(20, 2) NOT NULL DEFAULT 0,
    commissions NUMERIC(20, 2) NOT NULL DEFAULT 0,
    win_rate NUMERIC(5, 4),
    sharpe_ratio NUMERIC(10, 4),
    max_drawdown NUMERIC(20, 2),
    best_day_pnl NUMERIC(20, 2),
    worst_day_pnl NUMERIC(20, 2),
    PRIMARY KEY (month_key, account_key, strategy_key)
);

================================================================================
2. ETL PROCESSES
================================================================================

2.1 ETL FROM OLTP TO WAREHOUSE
-------------------------------

-- ETL Procedure: Load Daily Trades
CREATE OR REPLACE FUNCTION etl_load_daily_trades(p_date DATE)
RETURNS void AS $$
DECLARE
    v_date_key INTEGER;
    v_rows_inserted INTEGER;
BEGIN
    -- Get date key
    SELECT date_key INTO v_date_key
    FROM dim_date
    WHERE date = p_date;

    IF v_date_key IS NULL THEN
        RAISE EXCEPTION 'Date key not found for date: %', p_date;
    END IF;

    -- Insert trades into fact table
    INSERT INTO fact_trades (
        date_key,
        time_key,
        instrument_key,
        account_key,
        strategy_key,
        execution_id,
        order_id,
        execution_timestamp,
        side,
        quantity,
        price,
        notional_value,
        commission,
        fees,
        liquidity_flag,
        execution_venue,
        latency_ms
    )
    SELECT
        v_date_key,
        t.time_key,
        di.instrument_key,
        da.account_key,
        ds.strategy_key,
        e.execution_id,
        e.order_id,
        e.executed_at,
        e.side,
        e.quantity,
        e.price,
        e.quantity * e.price AS notional_value,
        e.commission,
        e.fees,
        e.liquidity_flag,
        e.execution_venue,
        EXTRACT(EPOCH FROM (e.reported_at - e.executed_at)) * 1000 AS latency_ms
    FROM executions e
    INNER JOIN dim_instrument di ON e.instrument_id = di.instrument_id
        AND e.executed_at::DATE BETWEEN di.effective_date AND COALESCE(di.expiration_date, '9999-12-31')
    INNER JOIN dim_account da ON e.account_id = da.account_id
        AND e.executed_at::DATE BETWEEN da.effective_date AND COALESCE(da.expiration_date, '9999-12-31')
    LEFT JOIN orders o ON e.order_id = o.order_id
    LEFT JOIN dim_strategy ds ON o.strategy_id = ds.strategy_id
        AND e.executed_at::DATE BETWEEN ds.effective_date AND COALESCE(ds.expiration_date, '9999-12-31')
    LEFT JOIN dim_time t ON e.executed_at::TIME = t.time
    WHERE e.executed_at::DATE = p_date
    ON CONFLICT DO NOTHING;

    GET DIAGNOSTICS v_rows_inserted = ROW_COUNT;

    RAISE NOTICE 'Loaded % trades for date %', v_rows_inserted, p_date;
END;
$$ LANGUAGE plpgsql;

-- ETL Procedure: Calculate Daily Performance
CREATE OR REPLACE FUNCTION etl_calculate_daily_performance(p_date DATE)
RETURNS void AS $$
DECLARE
    v_date_key INTEGER;
BEGIN
    SELECT date_key INTO v_date_key
    FROM dim_date
    WHERE date = p_date;

    IF v_date_key IS NULL THEN
        RAISE EXCEPTION 'Date key not found for date: %', p_date;
    END IF;

    -- Calculate and insert daily performance
    INSERT INTO fact_performance_daily (
        date_key,
        account_key,
        strategy_key,
        total_trades,
        winning_trades,
        losing_trades,
        total_volume,
        total_notional,
        gross_profit,
        gross_loss,
        net_pnl,
        commissions,
        fees,
        win_rate,
        profit_factor,
        avg_win,
        avg_loss,
        largest_win,
        largest_loss
    )
    SELECT
        v_date_key,
        account_key,
        strategy_key,
        COUNT(*) AS total_trades,
        SUM(CASE WHEN realized_pnl > 0 THEN 1 ELSE 0 END) AS winning_trades,
        SUM(CASE WHEN realized_pnl < 0 THEN 1 ELSE 0 END) AS losing_trades,
        SUM(quantity) AS total_volume,
        SUM(notional_value) AS total_notional,
        SUM(CASE WHEN realized_pnl > 0 THEN realized_pnl ELSE 0 END) AS gross_profit,
        ABS(SUM(CASE WHEN realized_pnl < 0 THEN realized_pnl ELSE 0 END)) AS gross_loss,
        SUM(realized_pnl - commission - fees) AS net_pnl,
        SUM(commission) AS commissions,
        SUM(fees) AS fees,
        CASE WHEN COUNT(*) > 0
             THEN SUM(CASE WHEN realized_pnl > 0 THEN 1 ELSE 0 END)::NUMERIC / COUNT(*)
             ELSE NULL END AS win_rate,
        CASE WHEN SUM(CASE WHEN realized_pnl < 0 THEN realized_pnl ELSE 0 END) != 0
             THEN SUM(CASE WHEN realized_pnl > 0 THEN realized_pnl ELSE 0 END) /
                  ABS(SUM(CASE WHEN realized_pnl < 0 THEN realized_pnl ELSE 0 END))
             ELSE NULL END AS profit_factor,
        AVG(CASE WHEN realized_pnl > 0 THEN realized_pnl ELSE NULL END) AS avg_win,
        AVG(CASE WHEN realized_pnl < 0 THEN realized_pnl ELSE NULL END) AS avg_loss,
        MAX(realized_pnl) AS largest_win,
        MIN(realized_pnl) AS largest_loss
    FROM fact_trades
    WHERE date_key = v_date_key
    GROUP BY account_key, strategy_key
    ON CONFLICT (date_key, account_key, strategy_key)
    DO UPDATE SET
        total_trades = EXCLUDED.total_trades,
        winning_trades = EXCLUDED.winning_trades,
        losing_trades = EXCLUDED.losing_trades,
        total_volume = EXCLUDED.total_volume,
        total_notional = EXCLUDED.total_notional,
        gross_profit = EXCLUDED.gross_profit,
        gross_loss = EXCLUDED.gross_loss,
        net_pnl = EXCLUDED.net_pnl,
        commissions = EXCLUDED.commissions,
        fees = EXCLUDED.fees,
        win_rate = EXCLUDED.win_rate,
        profit_factor = EXCLUDED.profit_factor,
        avg_win = EXCLUDED.avg_win,
        avg_loss = EXCLUDED.avg_loss,
        largest_win = EXCLUDED.largest_win,
        largest_loss = EXCLUDED.largest_loss;

    RAISE NOTICE 'Calculated daily performance for date %', p_date;
END;
$$ LANGUAGE plpgsql;

-- ETL Procedure: Snapshot Daily Positions
CREATE OR REPLACE FUNCTION etl_snapshot_daily_positions(p_date DATE)
RETURNS void AS $$
DECLARE
    v_date_key INTEGER;
BEGIN
    SELECT date_key INTO v_date_key
    FROM dim_date
    WHERE date = p_date;

    IF v_date_key IS NULL THEN
        RAISE EXCEPTION 'Date key not found for date: %', p_date;
    END IF;

    -- Snapshot end-of-day positions
    INSERT INTO fact_positions_daily (
        date_key,
        instrument_key,
        account_key,
        strategy_key,
        quantity,
        side,
        avg_entry_price,
        current_price,
        market_value,
        unrealized_pnl,
        realized_pnl,
        total_pnl
    )
    SELECT
        v_date_key,
        di.instrument_key,
        da.account_key,
        NULL AS strategy_key, -- Aggregate across strategies
        p.quantity,
        p.side,
        p.avg_entry_price,
        p.current_price,
        p.market_value,
        p.unrealized_pnl,
        p.realized_pnl,
        p.unrealized_pnl + p.realized_pnl AS total_pnl
    FROM positions p
    INNER JOIN dim_instrument di ON p.instrument_id = di.instrument_id
        AND p_date BETWEEN di.effective_date AND COALESCE(di.expiration_date, '9999-12-31')
    INNER JOIN dim_account da ON p.account_id = da.account_id
        AND p_date BETWEEN da.effective_date AND COALESCE(da.expiration_date, '9999-12-31')
    WHERE p.closed_at IS NULL
       OR p.closed_at::DATE > p_date
    ON CONFLICT (date_key, account_key, instrument_key)
    DO UPDATE SET
        quantity = EXCLUDED.quantity,
        side = EXCLUDED.side,
        avg_entry_price = EXCLUDED.avg_entry_price,
        current_price = EXCLUDED.current_price,
        market_value = EXCLUDED.market_value,
        unrealized_pnl = EXCLUDED.unrealized_pnl,
        realized_pnl = EXCLUDED.realized_pnl,
        total_pnl = EXCLUDED.total_pnl;

    RAISE NOTICE 'Snapshotted positions for date %', p_date;
END;
$$ LANGUAGE plpgsql;

-- Master ETL Procedure
CREATE OR REPLACE FUNCTION etl_daily_load(p_date DATE)
RETURNS void AS $$
BEGIN
    RAISE NOTICE 'Starting ETL for date: %', p_date;

    -- Load trades
    PERFORM etl_load_daily_trades(p_date);

    -- Calculate performance
    PERFORM etl_calculate_daily_performance(p_date);

    -- Snapshot positions
    PERFORM etl_snapshot_daily_positions(p_date);

    -- Refresh materialized views
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_top_performing_strategies;
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_instrument_statistics;

    RAISE NOTICE 'ETL completed for date: %', p_date;
END;
$$ LANGUAGE plpgsql;

2.2 INCREMENTAL ETL WITH PYTHON
--------------------------------

import psycopg2
from datetime import datetime, timedelta
import logging

class DataWarehouseETL:
    def __init__(self, oltp_conn_string, warehouse_conn_string):
        self.oltp_conn = psycopg2.connect(oltp_conn_string)
        self.warehouse_conn = psycopg2.connect(warehouse_conn_string)
        self.logger = logging.getLogger(__name__)

    def extract_incremental_trades(self, start_time, end_time):
        """Extract new trades from OLTP database"""
        query = """
            SELECT
                e.execution_id,
                e.order_id,
                e.account_id,
                e.instrument_id,
                o.strategy_id,
                e.executed_at,
                e.side,
                e.quantity,
                e.price,
                e.commission,
                e.fees,
                e.liquidity_flag,
                e.execution_venue
            FROM executions e
            LEFT JOIN orders o ON e.order_id = o.order_id
            WHERE e.executed_at >= %s AND e.executed_at < %s
            ORDER BY e.executed_at
        """

        with self.oltp_conn.cursor() as cursor:
            cursor.execute(query, (start_time, end_time))
            return cursor.fetchall()

    def transform_trades(self, trades):
        """Transform trades with dimension lookups"""
        transformed = []

        for trade in trades:
            (execution_id, order_id, account_id, instrument_id, strategy_id,
             executed_at, side, quantity, price, commission, fees,
             liquidity_flag, execution_venue) = trade

            # Lookup dimension keys
            date_key = self.get_date_key(executed_at.date())
            time_key = self.get_time_key(executed_at.time())
            instrument_key = self.get_instrument_key(instrument_id, executed_at)
            account_key = self.get_account_key(account_id, executed_at)
            strategy_key = self.get_strategy_key(strategy_id, executed_at) if strategy_id else None

            notional_value = quantity * price

            transformed.append({
                'date_key': date_key,
                'time_key': time_key,
                'instrument_key': instrument_key,
                'account_key': account_key,
                'strategy_key': strategy_key,
                'execution_id': execution_id,
                'order_id': order_id,
                'execution_timestamp': executed_at,
                'side': side,
                'quantity': quantity,
                'price': price,
                'notional_value': notional_value,
                'commission': commission,
                'fees': fees,
                'liquidity_flag': liquidity_flag,
                'execution_venue': execution_venue
            })

        return transformed

    def load_trades(self, transformed_trades):
        """Load transformed trades into warehouse"""
        insert_query = """
            INSERT INTO fact_trades (
                date_key, time_key, instrument_key, account_key, strategy_key,
                execution_id, order_id, execution_timestamp, side, quantity,
                price, notional_value, commission, fees, liquidity_flag,
                execution_venue
            ) VALUES (
                %(date_key)s, %(time_key)s, %(instrument_key)s, %(account_key)s,
                %(strategy_key)s, %(execution_id)s, %(order_id)s,
                %(execution_timestamp)s, %(side)s, %(quantity)s, %(price)s,
                %(notional_value)s, %(commission)s, %(fees)s, %(liquidity_flag)s,
                %(execution_venue)s
            )
            ON CONFLICT DO NOTHING
        """

        with self.warehouse_conn.cursor() as cursor:
            cursor.executemany(insert_query, transformed_trades)
            self.warehouse_conn.commit()

        self.logger.info(f"Loaded {len(transformed_trades)} trades into warehouse")

    def run_incremental_etl(self, lookback_minutes=5):
        """Run incremental ETL for recent data"""
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=lookback_minutes)

        self.logger.info(f"Running ETL from {start_time} to {end_time}")

        # Extract
        trades = self.extract_incremental_trades(start_time, end_time)
        self.logger.info(f"Extracted {len(trades)} trades")

        if not trades:
            return

        # Transform
        transformed = self.transform_trades(trades)

        # Load
        self.load_trades(transformed)

        self.logger.info("Incremental ETL completed successfully")

    def get_date_key(self, date):
        """Get date dimension key"""
        query = "SELECT date_key FROM dim_date WHERE date = %s"
        with self.warehouse_conn.cursor() as cursor:
            cursor.execute(query, (date,))
            result = cursor.fetchone()
            return result[0] if result else None

    def get_time_key(self, time):
        """Get time dimension key"""
        query = "SELECT time_key FROM dim_time WHERE time = %s"
        with self.warehouse_conn.cursor() as cursor:
            cursor.execute(query, (time,))
            result = cursor.fetchone()
            return result[0] if result else None

    def get_instrument_key(self, instrument_id, effective_date):
        """Get instrument dimension key"""
        query = """
            SELECT instrument_key FROM dim_instrument
            WHERE instrument_id = %s
              AND effective_date <= %s
              AND (expiration_date IS NULL OR expiration_date >= %s)
            ORDER BY effective_date DESC
            LIMIT 1
        """
        with self.warehouse_conn.cursor() as cursor:
            cursor.execute(query, (instrument_id, effective_date, effective_date))
            result = cursor.fetchone()
            return result[0] if result else None

    def get_account_key(self, account_id, effective_date):
        """Get account dimension key"""
        query = """
            SELECT account_key FROM dim_account
            WHERE account_id = %s
              AND effective_date <= %s
              AND (expiration_date IS NULL OR expiration_date >= %s)
            ORDER BY effective_date DESC
            LIMIT 1
        """
        with self.warehouse_conn.cursor() as cursor:
            cursor.execute(query, (account_id, effective_date, effective_date))
            result = cursor.fetchone()
            return result[0] if result else None

    def get_strategy_key(self, strategy_id, effective_date):
        """Get strategy dimension key"""
        query = """
            SELECT strategy_key FROM dim_strategy
            WHERE strategy_id = %s
              AND effective_date <= %s
              AND (expiration_date IS NULL OR expiration_date >= %s)
            ORDER BY effective_date DESC, version DESC
            LIMIT 1
        """
        with self.warehouse_conn.cursor() as cursor:
            cursor.execute(query, (strategy_id, effective_date, effective_date))
            result = cursor.fetchone()
            return result[0] if result else None

================================================================================
3. ANALYTICAL QUERIES
================================================================================

3.1 PERFORMANCE ANALYSIS QUERIES
---------------------------------

-- Top performing strategies by PnL
SELECT
    ds.strategy_name,
    ds.strategy_type,
    SUM(fpd.net_pnl) AS total_pnl,
    AVG(fpd.win_rate) AS avg_win_rate,
    AVG(fpd.sharpe_ratio) AS avg_sharpe_ratio,
    SUM(fpd.total_trades) AS total_trades,
    SUM(fpd.commissions + fpd.fees) AS total_costs
FROM fact_performance_daily fpd
INNER JOIN dim_strategy ds ON fpd.strategy_key = ds.strategy_key
INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
WHERE dd.date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY ds.strategy_name, ds.strategy_type
ORDER BY total_pnl DESC
LIMIT 20;

-- Monthly PnL trend by account
SELECT
    dd.year,
    dd.month,
    dd.month_name,
    da.account_number,
    SUM(fpd.net_pnl) AS monthly_pnl,
    SUM(fpd.total_trades) AS trade_count,
    AVG(fpd.win_rate) AS avg_win_rate
FROM fact_performance_daily fpd
INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
INNER JOIN dim_account da ON fpd.account_key = da.account_key
WHERE dd.year = EXTRACT(YEAR FROM CURRENT_DATE)
GROUP BY dd.year, dd.month, dd.month_name, da.account_number
ORDER BY dd.month, monthly_pnl DESC;

-- Instrument profitability analysis
SELECT
    di.symbol,
    di.exchange,
    di.instrument_type,
    COUNT(DISTINCT ft.trade_key) AS trade_count,
    SUM(ft.quantity) AS total_volume,
    SUM(ft.notional_value) AS total_notional,
    AVG(ft.price) AS avg_price,
    SUM(ft.commission + ft.fees) AS total_costs,
    SUM(ft.realized_pnl) AS total_pnl,
    SUM(ft.realized_pnl) / NULLIF(SUM(ft.notional_value), 0) * 100 AS return_pct
FROM fact_trades ft
INNER JOIN dim_instrument di ON ft.instrument_key = di.instrument_key
INNER JOIN dim_date dd ON ft.date_key = dd.date_key
WHERE dd.date >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY di.symbol, di.exchange, di.instrument_type
HAVING COUNT(DISTINCT ft.trade_key) >= 10
ORDER BY total_pnl DESC
LIMIT 50;

-- Intraday performance patterns
SELECT
    dt.hour,
    dt.time_of_day,
    COUNT(*) AS trade_count,
    SUM(ft.notional_value) AS total_notional,
    SUM(ft.realized_pnl) AS total_pnl,
    AVG(ft.realized_pnl) AS avg_pnl_per_trade,
    SUM(CASE WHEN ft.realized_pnl > 0 THEN 1 ELSE 0 END)::NUMERIC / COUNT(*) AS win_rate
FROM fact_trades ft
INNER JOIN dim_time dt ON ft.time_key = dt.time_key
INNER JOIN dim_date dd ON ft.date_key = dd.date_key
WHERE dd.date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY dt.hour, dt.time_of_day
ORDER BY dt.hour;

-- Strategy comparison matrix
WITH strategy_metrics AS (
    SELECT
        ds.strategy_name,
        SUM(fpd.net_pnl) AS total_pnl,
        AVG(fpd.sharpe_ratio) AS avg_sharpe,
        AVG(fpd.win_rate) AS avg_win_rate,
        SUM(fpd.total_trades) AS total_trades,
        AVG(fpd.max_drawdown) AS avg_max_drawdown
    FROM fact_performance_daily fpd
    INNER JOIN dim_strategy ds ON fpd.strategy_key = ds.strategy_key
    INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
    WHERE dd.date >= CURRENT_DATE - INTERVAL '90 days'
    GROUP BY ds.strategy_name
)
SELECT
    strategy_name,
    total_pnl,
    avg_sharpe,
    avg_win_rate,
    total_trades,
    avg_max_drawdown,
    RANK() OVER (ORDER BY total_pnl DESC) AS pnl_rank,
    RANK() OVER (ORDER BY avg_sharpe DESC) AS sharpe_rank,
    RANK() OVER (ORDER BY avg_win_rate DESC) AS win_rate_rank
FROM strategy_metrics
ORDER BY total_pnl DESC;

3.2 RISK ANALYSIS QUERIES
--------------------------

-- Daily Value at Risk (VaR) calculation
WITH daily_returns AS (
    SELECT
        fpd.date_key,
        fpd.account_key,
        fpd.net_pnl,
        fpd.net_pnl / NULLIF(LAG(fpd.net_pnl) OVER (
            PARTITION BY fpd.account_key ORDER BY fpd.date_key
        ), 0) AS return_pct
    FROM fact_performance_daily fpd
    INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
    WHERE dd.date >= CURRENT_DATE - INTERVAL '252 days' -- 1 year trading days
)
SELECT
    da.account_number,
    PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY dr.return_pct) AS var_95,
    PERCENTILE_CONT(0.01) WITHIN GROUP (ORDER BY dr.return_pct) AS var_99,
    STDDEV(dr.return_pct) AS volatility,
    AVG(dr.return_pct) AS avg_return
FROM daily_returns dr
INNER JOIN dim_account da ON dr.account_key = da.account_key
WHERE dr.return_pct IS NOT NULL
GROUP BY da.account_number;

-- Maximum drawdown analysis
WITH cumulative_pnl AS (
    SELECT
        fpd.date_key,
        fpd.account_key,
        dd.date,
        fpd.net_pnl,
        SUM(fpd.net_pnl) OVER (
            PARTITION BY fpd.account_key
            ORDER BY fpd.date_key
        ) AS cumulative_pnl,
        MAX(SUM(fpd.net_pnl)) OVER (
            PARTITION BY fpd.account_key
            ORDER BY fpd.date_key
            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
        ) AS running_max
    FROM fact_performance_daily fpd
    INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
    WHERE dd.date >= CURRENT_DATE - INTERVAL '90 days'
),
drawdowns AS (
    SELECT
        account_key,
        date,
        cumulative_pnl,
        running_max,
        cumulative_pnl - running_max AS drawdown,
        (cumulative_pnl - running_max) / NULLIF(running_max, 0) * 100 AS drawdown_pct
    FROM cumulative_pnl
)
SELECT
    da.account_number,
    MIN(d.drawdown) AS max_drawdown_amount,
    MIN(d.drawdown_pct) AS max_drawdown_pct,
    (SELECT date FROM drawdowns WHERE account_key = d.account_key
     ORDER BY drawdown LIMIT 1) AS max_drawdown_date
FROM drawdowns d
INNER JOIN dim_account da ON d.account_key = da.account_key
GROUP BY da.account_number, d.account_key;

-- Concentration risk analysis
SELECT
    da.account_number,
    di.symbol,
    di.instrument_type,
    fpd.quantity,
    fpd.market_value,
    fpd.market_value / SUM(fpd.market_value) OVER (
        PARTITION BY da.account_number
    ) * 100 AS portfolio_weight_pct
FROM fact_positions_daily fpd
INNER JOIN dim_account da ON fpd.account_key = da.account_key
INNER JOIN dim_instrument di ON fpd.instrument_key = di.instrument_key
INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
WHERE dd.date = (SELECT MAX(date) FROM dim_date WHERE date <= CURRENT_DATE)
  AND fpd.quantity != 0
ORDER BY da.account_number, fpd.market_value DESC;

================================================================================
4. MATERIALIZED VIEWS FOR PERFORMANCE
================================================================================

-- Top performing strategies (refreshed daily)
CREATE MATERIALIZED VIEW mv_top_performing_strategies AS
SELECT
    ds.strategy_id,
    ds.strategy_name,
    ds.strategy_type,
    SUM(fpd.net_pnl) AS total_pnl,
    SUM(fpd.total_trades) AS total_trades,
    AVG(fpd.win_rate) AS avg_win_rate,
    AVG(fpd.sharpe_ratio) AS avg_sharpe_ratio,
    AVG(fpd.profit_factor) AS avg_profit_factor,
    MAX(dd.date) AS last_updated
FROM fact_performance_daily fpd
INNER JOIN dim_strategy ds ON fpd.strategy_key = ds.strategy_key
INNER JOIN dim_date dd ON fpd.date_key = dd.date_key
WHERE dd.date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY ds.strategy_id, ds.strategy_name, ds.strategy_type
ORDER BY total_pnl DESC;

CREATE UNIQUE INDEX idx_mv_top_strategies ON mv_top_performing_strategies(strategy_id);

-- Instrument trading statistics
CREATE MATERIALIZED VIEW mv_instrument_statistics AS
SELECT
    di.instrument_id,
    di.symbol,
    di.exchange,
    di.instrument_type,
    COUNT(DISTINCT ft.date_key) AS trading_days,
    COUNT(*) AS trade_count,
    SUM(ft.quantity) AS total_volume,
    AVG(ft.price) AS avg_price,
    MIN(ft.price) AS min_price,
    MAX(ft.price) AS max_price,
    STDDEV(ft.price) AS price_volatility,
    SUM(ft.notional_value) AS total_notional
FROM fact_trades ft
INNER JOIN dim_instrument di ON ft.instrument_key = di.instrument_key
INNER JOIN dim_date dd ON ft.date_key = dd.date_key
WHERE dd.date >= CURRENT_DATE - INTERVAL '90 days'
GROUP BY di.instrument_id, di.symbol, di.exchange, di.instrument_type;

CREATE UNIQUE INDEX idx_mv_instrument_stats ON mv_instrument_statistics(instrument_id);

================================================================================
5. DATA ARCHIVAL AND COMPRESSION
================================================================================

-- Archive old partitions to compressed storage
CREATE TABLE fact_trades_archive (LIKE fact_trades INCLUDING ALL)
WITH (
    compression = 'zstd',
    compression_level = 9
);

-- Archive procedure
CREATE OR REPLACE FUNCTION archive_old_trades(p_months_old INTEGER)
RETURNS void AS $$
DECLARE
    v_cutoff_date DATE;
BEGIN
    v_cutoff_date := CURRENT_DATE - (p_months_old || ' months')::INTERVAL;

    -- Move old data to archive
    WITH archived AS (
        DELETE FROM fact_trades
        WHERE date_key IN (
            SELECT date_key FROM dim_date WHERE date < v_cutoff_date
        )
        RETURNING *
    )
    INSERT INTO fact_trades_archive
    SELECT * FROM archived;

    RAISE NOTICE 'Archived trades older than %', v_cutoff_date;
END;
$$ LANGUAGE plpgsql;

================================================================================
END OF DATA WAREHOUSING DOCUMENT
================================================================================
